<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LeNet-5卷积神经网络---MINIST手写体 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LeNet-5卷积神经网络---MINIST手写体" />
<meta property="og:description" content="LeNet-5卷积神经网络 本次实验中，LeNet输入图像的尺寸统一归一化为3232，卷积使用1步长。
第一层卷积层：利用卷积核尺寸为5×5，形成6个特征图谱，每个特征图谱内参数共享，即每个特征图谱内只使用一个共同卷积核，卷积核有5x5个连接参数加上1个偏置共26个参数。卷积区域每次滑动一个像素，这样卷积层形成的每个特征图谱大小是(32-5)/1&#43;1=28x28。第一层共有26x6=156个训练参数，有(5x5&#43;1)x28x28x6=122304个连接。
第二层池化层：经过第一层卷积之后，卷积特征大小为2828。池化层用2x2大小的模板做最大池化，这样池化后得到6个1414大小的特征。（第二层这个pooling层是对第一层中的22区域内的像素求和乘以一个权值系数再加上一个偏置，然后将这个结果再做一次映射于是每个池化核有两个训练参数，所以共有2x6=12个训练参数，但是有5x14x14x6=5880个连接）
第三层卷积层：与第一层一样，卷积核大小也为5×5，是为了构建一个更深的网络，把几个类似的堆叠起来，不同的是第三层的每个节点与第二层中的多个图相连。第三层有16个10x10（14-5&#43;1）的图。前3个图相连的卷积结构见下图，这种不对称的组合连接的方式有利于提取多种组合特征。该层有(5x5x3&#43;1)x6 &#43; (5x5x4 &#43; 1) x 3 &#43; (5x5x4 &#43;1)x6 &#43; (5x5x6&#43;1)x1 = 1516个训练参数，共有1516x10x10=151600个连接。
第三层与第二层前三个图的连接方式：
第四层池化层：第三次层的16个10x10的图分别进行以2x2为单位的下抽样得到16个5x5的图。5x5x5x16=2000个连接。
第五次全连接层：加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量展开成一些向量，乘上权重矩阵，加上偏置，然后对其使用relu函数激活。由于第四层的16个图的大小为5x5，与卷积核的大小相同，所以卷积后形成的图的大小为1x1。这里形成120个卷积结果。每个都与上一层的16个图相连。所以共有(5x5x16&#43;1)x120 = 48120个参数，同样有48120个连接。
第六层全连接层：第六层全连接层有84个feature map，每个feature map只有一个神经元与第五层全相连。第六层有84个节点，对应于一个7x12的比特图，该层的训练参数和连接数都是(120 &#43; 1)x84=10164。
第七层：Output层，也是全连接层，共有10个节点，分别代表数字0到9，如果节点i的输出值为0，则网络识别的结果是数字i。采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：
yi的值由i的比特图编码（即参数Wij）确定。yi越接近于0，则标明输入越接近于i的比特图编码，表示当前网络输入的识别结果是字符i。该层有84x10=840个设定的参数和连接。连接的方式如上图。
卷积核的个数是自己设定的，可以增加卷积核数目提高分类精度，但是那样会增加更大参数，提高计算成本。
下图为LeNet-5识别数字3的过程：
MINIST手写数字图像识别 参数设置：
训练过程：
正确率：
测试结果：
运行过程要注意的地方：
1.要把图像进行灰度化变成8位，否则会出现以下错误
2.字体应尽量加粗，否则会识别出错：
细笔：有一半以上都会识别错误，如下图
粗笔：即使是虚线画出的数字，都可以正确识别
说明加粗可以更容易提取图像的特征，使数字更易识别。
3.学习率应在0.01-0.05之间为佳，下面是学习率为0.2时训练的过程：
正确率比 0.02时低很多。
LaNet-5的局限性 ：CNN能够得出原始图像的有效表征，这使得CNN能够直接从原始像素中，经过极少的预处理，识别视觉上面的规律。然而，由于当时缺乏大规模训练数据，计算机的计算能力也跟不上，LeNet-5 对于复杂问题的处理结果并不理想。
附代码：
训练代码：
# -*- coding: utf-8 -*- &#34;&#34;&#34; Created on Thu Oct 25 10:58:13 2018 @author: lenovo &#34;&#34;&#34; import os import numpy as np import tensorflow as tf from tensorflow." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/c3ddc17236372a8b02076043136eeea0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-06-03T00:04:53+08:00" />
<meta property="article:modified_time" content="2019-06-03T00:04:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LeNet-5卷积神经网络---MINIST手写体</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="LeNet5_0"></a>LeNet-5卷积神经网络</h2> 
<p><img src="https://images2.imgbox.com/cb/83/lkJW9hHc_o.png" alt="在这里插入图片描述"><br> 本次实验中，LeNet输入图像的尺寸统一归一化为32<em>32，卷积使用1步长。<br> 　　第一层卷积层：利用卷积核尺寸为5×5，形成6个特征图谱，每个特征图谱内参数共享，即每个特征图谱内只使用一个共同卷积核，卷积核有5x5个连接参数加上1个偏置共26个参数。卷积区域每次滑动一个像素，这样卷积层形成的每个特征图谱大小是(32-5)/1+1=28x28。第一层共有26x6=156个训练参数，有(5x5+1)x28x28x6=122304个连接。<br> 　　第二层池化层：经过第一层卷积之后，卷积特征大小为28</em>28。池化层用2x2大小的模板做最大池化，这样池化后得到6个14<em>14大小的特征。（第二层这个pooling层是对第一层中的2</em>2区域内的像素求和乘以一个权值系数再加上一个偏置，然后将这个结果再做一次映射于是每个池化核有两个训练参数，所以共有2x6=12个训练参数，但是有5x14x14x6=5880个连接）<br> 　　第三层卷积层：与第一层一样，卷积核大小也为5×5，是为了构建一个更深的网络，把几个类似的堆叠起来，不同的是第三层的每个节点与第二层中的多个图相连。第三层有16个10x10（14-5+1）的图。前3个图相连的卷积结构见下图，这种不对称的组合连接的方式有利于提取多种组合特征。该层有(5x5x3+1)x6 + (5x5x4 + 1) x 3 + (5x5x4 +1)x6 + (5x5x6+1)x1 = 1516个训练参数，共有1516x10x10=151600个连接。<br> 　　第三层与第二层前三个图的连接方式：</p> 
<p><img src="https://images2.imgbox.com/02/59/bApTATO3_o.png" alt="在这里插入图片描述"><br> 　　第四层池化层：第三次层的16个10x10的图分别进行以2x2为单位的下抽样得到16个5x5的图。5x5x5x16=2000个连接。<br> 　　第五次全连接层：加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量展开成一些向量，乘上权重矩阵，加上偏置，然后对其使用relu函数激活。由于第四层的16个图的大小为5x5，与卷积核的大小相同，所以卷积后形成的图的大小为1x1。这里形成120个卷积结果。每个都与上一层的16个图相连。所以共有(5x5x16+1)x120 = 48120个参数，同样有48120个连接。<br> 　　第六层全连接层：第六层全连接层有84个feature map，每个feature map只有一个神经元与第五层全相连。第六层有84个节点，对应于一个7x12的比特图，该层的训练参数和连接数都是(120 + 1)x84=10164。<br> 　　第七层：Output层，也是全连接层，共有10个节点，分别代表数字0到9，如果节点i的输出值为0，则网络识别的结果是数字i。采用的是径向基函数（RBF）的网络连接方式。假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：<br> 　　<br> <img src="https://images2.imgbox.com/36/0d/30Gmaeo5_o.png" alt="在这里插入图片描述"><br> yi的值由i的比特图编码（即参数Wij）确定。yi越接近于0，则标明输入越接近于i的比特图编码，表示当前网络输入的识别结果是字符i。该层有84x10=840个设定的参数和连接。连接的方式如上图。<br> 　　卷积核的个数是自己设定的，可以增加卷积核数目提高分类精度，但是那样会增加更大参数，提高计算成本。<br> 　　下图为LeNet-5识别数字3的过程：<br> <img src="https://images2.imgbox.com/f7/a9/0nT1ma4o_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="MINIST_19"></a>MINIST手写数字图像识别</h2> 
<p><strong>参数设置：</strong><br> <img src="https://images2.imgbox.com/de/b5/MMqSgEBU_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9d/69/dYWdXKSF_o.png" alt="在这里插入图片描述"><br> <strong>训练过程：</strong><br> <img src="https://images2.imgbox.com/a5/10/C3OjFhhM_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/de/85/entHbTTa_o.png" alt="在这里插入图片描述"><br> <strong>正确率：</strong><img src="https://images2.imgbox.com/53/06/TjxZTXmY_o.png" alt="在这里插入图片描述"><br> <strong>测试结果：</strong><br> <img src="https://images2.imgbox.com/6a/41/xjkuHmKR_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/bc/8a/GO8zm54S_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f2/2f/Nqbd3wXA_o.png" alt="在这里插入图片描述"></p> 
<p><strong>运行过程要注意的地方：</strong><br> 1.要把图像进行灰度化变成8位，否则会出现以下错误<br> <img src="https://images2.imgbox.com/5e/26/G3uJxebU_o.png" alt="在这里插入图片描述"><br> 2.字体应尽量加粗，否则会识别出错：<br> 细笔：有一半以上都会识别错误，如下图<br> <img src="https://images2.imgbox.com/da/40/W0E0GdfL_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/f2/1e/Jp3rPfSf_o.png" alt="在这里插入图片描述"></p> 
<p>粗笔：即使是虚线画出的数字，都可以正确识别<br> <img src="https://images2.imgbox.com/db/85/rt4KcEP2_o.png" alt="在这里插入图片描述"><br> 说明加粗可以更容易提取图像的特征，使数字更易识别。</p> 
<p>3.学习率应在0.01-0.05之间为佳，下面是学习率为0.2时训练的过程：<br> <img src="https://images2.imgbox.com/5c/52/PUXIiVdr_o.png" alt="在这里插入图片描述"><br> 正确率比 0.02时低很多。<br> LaNet-5的局限性 ：CNN能够得出原始图像的有效表征，这使得CNN能够直接从原始像素中，经过极少的预处理，识别视觉上面的规律。然而，由于当时缺乏大规模训练数据，计算机的计算能力也跟不上，LeNet-5 对于复杂问题的处理结果并不理想。</p> 
<p>附代码：<br> 训练代码：</p> 
<pre><code># -*- coding: utf-8 -*-
"""
Created on Thu Oct 25 10:58:13 2018

@author: lenovo
"""

import os
import numpy as np

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

# 加载mnist_inference.py中定义的常量和前向传播的函数
import mnist_inference

# 配置神经网络的参数
BATCH_SIZE = 100
LEARNING_RATE_BASE = 0.02
LEARNING_RATE_DECAY = 0.99
REGULARAZTION_RATE = 0.0001
TRAINING_STEPS = 30000
MOVING_AVERAGE_DECAY = 0.99
# 模型保存的路径和文件名
MODEL_SAVE_PATH = "model/"
MODEL_NAME = "model.ckpt"

def train(mnist):
    # 定义输入输出placeholder
    # 调整输入数据placeholder的格式，输入为一个四维矩阵
    x = tf.placeholder(tf.float32, [
        BATCH_SIZE,                             # 第一维表示一个batch中样例的个数
        mnist_inference.IMAGE_SIZE,             # 第二维和第三维表示图片的尺寸
        mnist_inference.IMAGE_SIZE,
        mnist_inference.NUM_CHANNELS],          # 第四维表示图片的深度，对于RBG格式的图片，深度为5
                       name='x-input')
    y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')

    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)
    # 直接使用mnist_inference.py中定义的前向传播过程
    y = mnist_inference.inference(x, True, regularizer)
    global_step = tf.Variable(0, trainable=False)

    #定义损失函数、学习率、滑动平均操作以及训练过程
    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)
    variable_averages_op = variable_averages.apply(tf.trainable_variables())
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))
    cross_entropy_mean = tf.reduce_mean(cross_entropy)
    loss = cross_entropy_mean + tf.add_n(tf.get_collection('losses'))
    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, mnist.train.num_examples/BATCH_SIZE, LEARNING_RATE_DECAY)
    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)
    with tf.control_dependencies([train_step, variable_averages_op]):
        train_op = tf.no_op(name='train')

    # 初始化Tensorflow持久化类
    saver = tf.train.Saver()
    with tf.Session() as sess:
        tf.global_variables_initializer().run()
        # 验证和测试的过程将会有一个独立的程序来完成
        for i in range(TRAINING_STEPS):
            xs, ys = mnist.train.next_batch(BATCH_SIZE)
            #类似地将输入的训练数据格式调整为一个四维矩阵，并将这个调整后的数据传入sess.run过程
            reshaped_xs = np.reshape(xs, (BATCH_SIZE, mnist_inference.IMAGE_SIZE, mnist_inference.IMAGE_SIZE, mnist_inference.NUM_CHANNELS))
            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict={x: reshaped_xs, y_: ys})
            #每1000轮保存一次模型。
            if i%1000 == 0:
                # 输出当前的训练情况。这里只输出了模型在当前训练batch上的损失函数大小。通过损失函数的大小可以大概了解训练的情况。
                # 在验证数据集上的正确率信息会有一个单独的程序来生成。
                print("After %d training step(s), loss on training batch is %f." % (step, loss_value))
                # 保存当前的模型。注意这里隔出了global_step参数，这样可以让每个被保存模型的文件名末尾加上训练的轮数，比如“model.ckpt-1000”表示训练1000轮后得到的模型
                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)


def main(argv=None):
    mnist = input_data.read_data_sets("dataset/", one_hot=True)
    train(mnist)


if __name__ == '__main__':
    tf.app.run()

</code></pre> 
<p>验证正确率：</p> 
<pre><code># -*- coding: utf-8 -*-
"""
Created on Thu Oct 25 10:45:36 2018

@author: lenovo
"""

import time
import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

# 加载mnist_inference.py 和 mnist_train.py中定义的常量和函数
import mnist_inference
import mmnist_train

# 每10秒加载一次最新的模型， 并在测试数据上测试最新模型的正确率
EVAL_INTERVAL_SECS = 10


def evaluate(mnist):
    with tf.Graph().as_default() as g:
        # 定义输入输出的格式
        x = tf.placeholder(tf.float32, [
            mnist.validation.num_examples,           # 第一维表示样例的个数
            mnist_inference.IMAGE_SIZE,             # 第二维和第三维表示图片的尺寸
            mnist_inference.IMAGE_SIZE,
            mnist_inference.NUM_CHANNELS],          # 第四维表示图片的深度，对于RBG格式的图片，深度为5
                       name='x-input')
        y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')

        validate_feed = {x: np.reshape(mnist.validation.images, (mnist.validation.num_examples, mnist_inference.IMAGE_SIZE, mnist_inference.IMAGE_SIZE, mnist_inference.NUM_CHANNELS)),
                         y_: mnist.validation.labels}
        # 直接通过调用封装好的函数来计算前向传播的结果。
        # 因为测试时不关注正则损失的值，所以这里用于计算正则化损失的函数被设置为None。
        y = mnist_inference.inference(x, False, None)

        # 使用前向传播的结果计算正确率。
        # 如果需要对未知的样例进行分类，那么使用tf.argmax(y, 1)就可以得到输入样例的预测类别了。
        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # 通过变量重命名的方式来加载模型，这样在前向传播的过程中就不需要调用求滑动平均的函数来获取平局值了。
        # 这样就可以完全共用mnist_inference.py中定义的前向传播过程
        variable_averages = tf.train.ExponentialMovingAverage(mmnist_train.MOVING_AVERAGE_DECAY)
        variable_to_restore = variable_averages.variables_to_restore()
        saver = tf.train.Saver(variable_to_restore)

        #每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化
        while True:
            with tf.Session() as sess:
                # tf.train.get_checkpoint_state函数会通过checkpoint文件自动找到目录中最新模型的文件名
                ckpt = tf.train.get_checkpoint_state(mmnist_train.MODEL_SAVE_PATH)
                if ckpt and ckpt.model_checkpoint_path:
                    # 加载模型
                    saver.restore(sess, ckpt.model_checkpoint_path)
                    # 通过文件名得到模型保存时迭代的轮数
                    global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
                    graph=tf.get_default_graph()

                    accuracy_score = sess.run(accuracy, feed_dict = validate_feed)
                    print("After %s training step(s), validation accuracy = %f" % (global_step, accuracy_score))
                else:
                    print("No checkpoint file found")
                    return
            time.sleep(EVAL_INTERVAL_SECS)


def main(argv=None):
    mnist = input_data.read_data_sets("dataset/", one_hot=True)
    evaluate(mnist)


if __name__ == '__main__':
    tf.app.run()

</code></pre> 
<p>可视化及测试：</p> 
<pre><code># -*- coding: utf-8 -*-
"""
Created on Thu Oct 25 10:45:36 2018

@author: lenovo
"""

import time
import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

# 加载mnist_inference.py 和 mnist_train.py中定义的常量和函数
import mnist_inference
import mmnist_train

# 每10秒加载一次最新的模型， 并在测试数据上测试最新模型的正确率
EVAL_INTERVAL_SECS = 10


def evaluate(mnist):
    with tf.Graph().as_default() as g:
        # 定义输入输出的格式
        x = tf.placeholder(tf.float32, [
            mnist.validation.num_examples,           # 第一维表示样例的个数
            mnist_inference.IMAGE_SIZE,             # 第二维和第三维表示图片的尺寸
            mnist_inference.IMAGE_SIZE,
            mnist_inference.NUM_CHANNELS],          # 第四维表示图片的深度，对于RBG格式的图片，深度为5
                       name='x-input')
        y_ = tf.placeholder(tf.float32, [None, mnist_inference.OUTPUT_NODE], name='y-input')

        validate_feed = {x: np.reshape(mnist.validation.images, (mnist.validation.num_examples, mnist_inference.IMAGE_SIZE, mnist_inference.IMAGE_SIZE, mnist_inference.NUM_CHANNELS)),
                         y_: mnist.validation.labels}
        # 直接通过调用封装好的函数来计算前向传播的结果。
        # 因为测试时不关注正则损失的值，所以这里用于计算正则化损失的函数被设置为None。
        y = mnist_inference.inference(x, False, None)

        # 使用前向传播的结果计算正确率。
        # 如果需要对未知的样例进行分类，那么使用tf.argmax(y, 1)就可以得到输入样例的预测类别了。
        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # 通过变量重命名的方式来加载模型，这样在前向传播的过程中就不需要调用求滑动平均的函数来获取平局值了。
        # 这样就可以完全共用mnist_inference.py中定义的前向传播过程
        variable_averages = tf.train.ExponentialMovingAverage(mmnist_train.MOVING_AVERAGE_DECAY)
        variable_to_restore = variable_averages.variables_to_restore()
        saver = tf.train.Saver(variable_to_restore)

        #每隔EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化
        while True:
            with tf.Session() as sess:
                # tf.train.get_checkpoint_state函数会通过checkpoint文件自动找到目录中最新模型的文件名
                ckpt = tf.train.get_checkpoint_state(mmnist_train.MODEL_SAVE_PATH)
                if ckpt and ckpt.model_checkpoint_path:
                    # 加载模型
                    saver.restore(sess, ckpt.model_checkpoint_path)
                    # 通过文件名得到模型保存时迭代的轮数
                    global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
                    graph=tf.get_default_graph()

                    accuracy_score = sess.run(accuracy, feed_dict = validate_feed)
                    print("After %s training step(s), validation accuracy = %f" % (global_step, accuracy_score))
                else:
                    print("No checkpoint file found")
                    return
            time.sleep(EVAL_INTERVAL_SECS)


def main(argv=None):
    mnist = input_data.read_data_sets("dataset/", one_hot=True)
    evaluate(mnist)


if __name__ == '__main__':
    tf.app.run()

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/177c443a14e90e943add56d772e1f5d0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JS处理json数据的方法总结，包括增、删、改、查、合并、去重的处理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/034690a8ae78d47dd7dd9becebf2230a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">职业发展能力图谱</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>