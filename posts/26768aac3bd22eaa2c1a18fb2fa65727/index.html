<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Chat GPT原理 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Chat GPT原理" />
<meta property="og:description" content=" ChatGPT一经发布就在科技圈火得不行，这两天也是被传得神乎其神，听说它写得了代码、改得了 Bug，小说、段子统统不再话下！那他到底是怎么训练成现在这样的呢？本文介绍李宏毅老师的分析。
那么接下来我们就来介绍Chat GPT是怎样练成的！ 1.找寻资料参考： 李老师在翻看OpenAI的博客发现，其目前并没有发表关于ChatGPT的论文。但是！在OpenAI官方博客介绍中，我们可以发现CharGPT有一个兄弟，InstructGPT，因此他决定依靠InstructGPT去寻找一些ChatGPT的训练逻辑。
当我们看到ChatGPT与InstructGPT的对比时，更加坚定的确定通过InstructGPT是可以找到ChatGPT模型的蛛丝马迹的。如下，上面为ChartGPT的训练流程下面为InstructGPT的流程图。可以说像的7788了，比较面明显的区别其实只有GPT的版本不同而已，前者是GPT3.5，后者是GPT3。所以李老师决定直接分析InstructGPT来推测Chat GPT是怎样练成的！
2.正式开始介绍Chat GPT的学习四阶段： 2.1 学习文字接龙 学习文字接龙，其实就是依据目前已有的信息，去推测下一个可能出现的字，以此类推。与我们在学习机器学习中的文字翻译Transformer架构很相似。
正如下面的例子所演示的，当我们有目前有：“你好”这一个不完整的句子的时候，程序可以基于在互联网上学习到的知识去预测下一个字，有可能是 “美” 这种学习的好处是，我们并不需要人工标注出机器需要训练的内容，只需要把他放到互联网上，看到文字就自我学习文字接龙即可。
但是，坏处也显而易见了，对于一个不完整的句子，我们后面的词可以是很多种多样的，比如说在 “你好” 后面，我们可以接上 “吗” 、 “高”、“美” 等，所以GPT返回的其实是一个概率分布，也就是说每次回答的内容其实都是随机的。这次说 “你好吗”，下次可能就说 “你好美了” 。
但是单单依靠文字接龙，其实GPT就已经可以回答问题了。比如下面的例子，我们问出“台湾最高的山是哪座？” 当GPT在网上看过这么多资料，它通过文字接龙的形式回答，可能可以直接回答出玉山，也可能给你出一道选择题（如果他读过的资料是这么连接起来的），也可能反问你 “谁来告诉我呀？”
2.2 人类老师引导文字接龙方向 经过了文字接龙，我们会发现GPT虽然能回答我们的问题，但是并不一定能回答出我们想要的答案。说白了就是人工来筛选哪些是我们需要的答案（还是逃离不了有多人工就有多智能呐！）
2.3 模仿人类老师的喜好 人类希望获得的答案就会被赋予更高的分数 2.4 使用增强向模拟老师学习 就是我们将每次GPT得到的答案都丢给TeacherModel来评判，如果是人类希望的答案就给高分，如果不是则给低分，这个模式被称为增强式学习种的“Reward”模块 3. 当然，ChatGPT目前并不是完美的... 目前ChatGPT模型已经很难再被找到错误了，但是根据上面的分析，我们只需要问出一些没有人问过的内容，他就回答不出来了。比如说：我问 “numbers”是由几个字母组成的，他会回答八个，这是八个吗？？？这明明就是七个！！！
4.总结 李宏毅老师认为本流程是GPT的社会化过程，从一开始的想说什么就说什么，一直到后面的人类引导他说出期望的答案。 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/26768aac3bd22eaa2c1a18fb2fa65727/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-11T22:59:44+08:00" />
<meta property="article:modified_time" content="2022-12-11T22:59:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Chat GPT原理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>ChatGPT一经发布就在科技圈火得不行，这两天也是被传得神乎其神，听说它写得了代码、改得了 Bug，小说、段子统统不再话下！那他到底是怎么训练成现在这样的呢？本文介绍李宏毅老师的分析。</p> 
<p></p> 
<h2 style="text-align:center;"><span style="color:#0d0016;"><strong><span style="background-color:#cccccc;">那么接下来我们就来介绍Chat GPT是怎样练成的！</span></strong></span></h2> 
<h3>1.找寻资料参考：</h3> 
<p>        李老师在翻看OpenAI的博客发现，其目前并没有发表关于ChatGPT的论文。但是！在OpenAI官方博客介绍中，我们可以发现CharGPT有一个兄弟，InstructGPT，因此他决定依靠InstructGPT去寻找一些ChatGPT的训练逻辑。</p> 
<blockquote> 
 <p class="img-center"><img alt="" height="425" src="https://images2.imgbox.com/7d/e3/x27R2Gze_o.png" width="696"></p> 
</blockquote> 
<p>        当我们看到ChatGPT与InstructGPT的对比时，更加坚定的确定通过InstructGPT是可以找到ChatGPT模型的蛛丝马迹的。如下，上面为ChartGPT的训练流程下面为InstructGPT的流程图。可以说像的7788了，比较面明显的区别其实只有GPT的版本不同而已，前者是GPT3.5，后者是GPT3。所以李老师决定直接分析InstructGPT来推测Chat GPT是怎样练成的！</p> 
<blockquote> 
 <p class="img-center"><img alt="" height="215" src="https://images2.imgbox.com/1c/d5/YIgxHNtk_o.png" width="500"></p> 
</blockquote> 
<blockquote> 
 <p class="img-center"><img alt="" height="295" src="https://images2.imgbox.com/3e/fc/dkeOrmiq_o.png" width="500"></p> 
</blockquote> 
<p></p> 
<h3>2.正式开始介绍Chat GPT的学习四阶段：</h3> 
<p class="img-center"><img alt="" height="331" src="https://images2.imgbox.com/75/4f/SYHnkGAZ_o.png" width="600"></p> 
<h4>2.1 学习文字接龙</h4> 
<p>        学习文字接龙，其实就是依据目前已有的信息，去推测下一个可能出现的字，以此类推。与我们在学习机器学习中的文字翻译Transformer架构很相似。</p> 
<p>        正如下面的例子所演示的，当我们有目前有：“你好”这一个不完整的句子的时候，程序可以基于在互联网上学习到的知识去预测下一个字，有可能是 “美” </p> 
<p class="img-center"><img alt="" height="167" src="https://images2.imgbox.com/d8/b7/VuIeys8W_o.png" width="500"></p> 
<p>         这种学习的好处是，我们并不需要人工标注出机器需要训练的内容，只需要把他放到互联网上，看到文字就自我学习文字接龙即可。</p> 
<p>        但是，坏处也显而易见了，对于一个不完整的句子，我们后面的词可以是很多种多样的，比如说在 “你好” 后面，我们可以接上 “吗” 、 “高”、“美” 等，所以GPT返回的其实是一个概率分布，也就是说每次回答的内容其实都是随机的。这次说 “你好吗”，下次可能就说 “你好美了” 。</p> 
<p class="img-center"><img alt="" height="111" src="https://images2.imgbox.com/9c/8d/8G18WUjj_o.png" width="500"></p> 
<p>        但是单单依靠文字接龙，其实GPT就已经可以回答问题了。比如下面的例子，我们问出“台湾最高的山是哪座？” 当GPT在网上看过这么多资料，它通过文字接龙的形式回答，可能可以直接回答出玉山，也可能给你出一道选择题（如果他读过的资料是这么连接起来的），也可能反问你 “谁来告诉我呀？”</p> 
<p class="img-center"><img alt="" height="185" src="https://images2.imgbox.com/27/8c/7ZzNLWuo_o.png" width="500"></p> 
<h4></h4> 
<h4>2.2 人类老师引导文字接龙方向</h4> 
<p>        经过了文字接龙，我们会发现GPT虽然能回答我们的问题，但是并不一定能回答出我们想要的答案。说白了就是人工来筛选哪些是我们需要的答案（还是逃离不了有多人工就有多智能呐！）</p> 
<p></p> 
<h4> 2.3 模仿人类老师的喜好</h4> 
<p>        人类希望获得的答案就会被赋予更高的分数 </p> 
<p class="img-center"><img alt="" height="836" src="https://images2.imgbox.com/45/4b/QoJaLqfY_o.png" width="1200"></p> 
<h4>2.4 使用增强向模拟老师学习</h4> 
<p>        就是我们将每次GPT得到的答案都丢给TeacherModel来评判，如果是人类希望的答案就给高分，如果不是则给低分，这个模式被称为增强式学习种的“Reward”模块 </p> 
<p><img alt="" height="755" src="https://images2.imgbox.com/85/f7/PsiZgpWE_o.png" width="1200"></p> 
<p></p> 
<p></p> 
<h3>3. 当然，ChatGPT目前并不是完美的...</h3> 
<p>        目前ChatGPT模型已经很难再被找到错误了，但是根据上面的分析，我们只需要问出一些没有人问过的内容，他就回答不出来了。比如说：我问 “numbers”是由几个字母组成的，他会回答八个，这是八个吗？？？这明明就是七个！！！</p> 
<p class="img-center"><img alt="" height="177" src="https://images2.imgbox.com/63/d9/9mZYItRE_o.png" width="871"></p> 
<p></p> 
<h3>4.总结 </h3> 
<p>        李宏毅老师认为本流程是GPT的社会化过程，从一开始的想说什么就说什么，一直到后面的人类引导他说出期望的答案。 </p> 
<p><img alt="" height="746" src="https://images2.imgbox.com/68/81/osIHVP8k_o.png" width="1200"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8eb518db48176052dfa95e1ac12f28a6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【大数据入门核心技术-Hadoop】（六）Hadoop3.2.1高可用集群搭建</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a7a45a7fde85b23487c0a69b30367ddb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">扩散模型的源码学习diffusion_model</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>