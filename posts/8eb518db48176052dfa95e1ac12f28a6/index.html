<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【大数据入门核心技术-Hadoop】（六）Hadoop3.2.1高可用集群搭建 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【大数据入门核心技术-Hadoop】（六）Hadoop3.2.1高可用集群搭建" />
<meta property="og:description" content="目录
一、Hadoop部署的三种方式
1、Standalone mode（独立模式）
2、Pseudo-Distributed mode（伪分布式模式）
3、Cluster mode（集群模式）
二、准备工作
1、先完成zk高可用搭建
2、/etc/hosts增加内容
3、各台服务器分别创建目录
4、关闭防火墙和禁用swap交换分区
5、三台机器间免密
6、安装jdk
7、下载好hadoop安装包
三、高可用配置
1、配置core-site.xml
2、配置hdfs-site.xml
3、配置yarn-site.xml文件
4、配置mapred-site.xml
5、配置workers
6、修改配置hadoop-env.sh
四、分发文件
五、启动服务
六、查看服务
七、常见问题解决
1、高可用下提示Operation category READ is not supported in state standby
一、Hadoop部署的三种方式 1、Standalone mode（独立模式） 独立模式又称为单机模式，仅1个机器运行1个java进程，主要用于调试。
2、Pseudo-Distributed mode（伪分布式模式） 伪分布模式也是在1个机器上运行HDFS的NameNode和DataNode、YARN的 ResourceManger和NodeManager，但分别启动单独的java进程，主要用于调试。
3、Cluster mode（集群模式） 单Namenode节点模式-高可用HA模式
集群模式主要用于生产环境部署。会使用N台主机组成一个Hadoop集群。这种部署模式下，主节点和从节点会分开部署在不同的机器上。
本教程主要安装 多Namenode 节点 高可用集群模式
二、准备工作 1、先完成zk高可用搭建 【大数据入门核心技术-Zookeeper】（五）ZooKeeper集群搭建
2、/etc/hosts增加内容 172.30.1.56 hadoop001
172.30.1.57 hadoop001
172.30.1.58 hadoop001
3、各台服务器分别创建目录 mkdir -p /data/bigdata/hadoop/tmp
mkdir -p /data/bigdata/hadoop/var" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/8eb518db48176052dfa95e1ac12f28a6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-11T21:03:27+08:00" />
<meta property="article:modified_time" content="2022-12-11T21:03:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【大数据入门核心技术-Hadoop】（六）Hadoop3.2.1高可用集群搭建</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81Hadoop%E9%83%A8%E7%BD%B2%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81Hadoop%E9%83%A8%E7%BD%B2%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F" rel="nofollow">一、Hadoop部署的三种方式</a></p> 
<p id="1%E3%80%81Standalone%20mode%EF%BC%88%E7%8B%AC%E7%AB%8B%E6%A8%A1%E5%BC%8F%EF%BC%89-toc" style="margin-left:40px;"><a href="#1%E3%80%81Standalone%20mode%EF%BC%88%E7%8B%AC%E7%AB%8B%E6%A8%A1%E5%BC%8F%EF%BC%89" rel="nofollow">1、Standalone mode（独立模式）</a></p> 
<p id="2%E3%80%81Pseudo-Distributed%20mode%EF%BC%88%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%EF%BC%89-toc" style="margin-left:40px;"><a href="#2%E3%80%81Pseudo-Distributed%20mode%EF%BC%88%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%EF%BC%89" rel="nofollow">2、Pseudo-Distributed mode（伪分布式模式）</a></p> 
<p id="3%E3%80%81Cluster%20mode%EF%BC%88%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%EF%BC%89-toc" style="margin-left:40px;"><a href="#3%E3%80%81Cluster%20mode%EF%BC%88%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%EF%BC%89" rel="nofollow">3、Cluster mode（集群模式）</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C" rel="nofollow">二、准备工作</a></p> 
<p id="1%E3%80%81%E5%85%88%E5%AE%8C%E6%88%90zk%E5%92%8C%E9%9D%9E%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E5%85%88%E5%AE%8C%E6%88%90zk%E5%92%8C%E9%9D%9E%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA" rel="nofollow">1、先完成zk高可用搭建</a></p> 
<p id="2%E3%80%81%2Fetc%2Fhosts%E5%A2%9E%E5%8A%A0%E5%86%85%E5%AE%B9-toc" style="margin-left:40px;"><a href="#2%E3%80%81%2Fetc%2Fhosts%E5%A2%9E%E5%8A%A0%E5%86%85%E5%AE%B9" rel="nofollow">2、/etc/hosts增加内容</a></p> 
<p id="3%E3%80%81%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95-toc" style="margin-left:40px;"><a href="#3%E3%80%81%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95" rel="nofollow">3、各台服务器分别创建目录</a></p> 
<p id="4%E3%80%81%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8C%E7%A6%81%E7%94%A8swap%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BA-toc" style="margin-left:40px;"><a href="#4%E3%80%81%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8C%E7%A6%81%E7%94%A8swap%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BA" rel="nofollow">4、关闭防火墙和禁用swap交换分区</a></p> 
<p id="5%E3%80%81%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E9%97%B4%E5%85%8D%E5%AF%86-toc" style="margin-left:40px;"><a href="#5%E3%80%81%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E9%97%B4%E5%85%8D%E5%AF%86" rel="nofollow">5、三台机器间免密</a></p> 
<p id="6%E3%80%81%E5%AE%89%E8%A3%85jdk-toc" style="margin-left:40px;"><a href="#6%E3%80%81%E5%AE%89%E8%A3%85jdk" rel="nofollow">6、安装jdk</a></p> 
<p id="7%E3%80%81%E4%B8%8B%E8%BD%BD%E5%A5%BDhadoop%E5%AE%89%E8%A3%85%E5%8C%85-toc" style="margin-left:40px;"><a href="#7%E3%80%81%E4%B8%8B%E8%BD%BD%E5%A5%BDhadoop%E5%AE%89%E8%A3%85%E5%8C%85" rel="nofollow">7、下载好hadoop安装包</a></p> 
<p id="%E4%B8%89%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE" rel="nofollow">三、高可用配置</a></p> 
<p id="1%E3%80%81%E9%85%8D%E7%BD%AEcore-site.xml-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E9%85%8D%E7%BD%AEcore-site.xml" rel="nofollow">1、配置core-site.xml</a></p> 
<p id="2%E3%80%81%E9%85%8D%E7%BD%AEhdfs-site.xml-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E9%85%8D%E7%BD%AEhdfs-site.xml" rel="nofollow">2、配置hdfs-site.xml</a></p> 
<p id="3%E3%80%81%E9%85%8D%E7%BD%AEyarn-site.xml%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><a href="#3%E3%80%81%E9%85%8D%E7%BD%AEyarn-site.xml%E6%96%87%E4%BB%B6" rel="nofollow">3、配置yarn-site.xml文件</a></p> 
<p id="4%E3%80%81%E9%85%8D%E7%BD%AEmapred-site.xml-toc" style="margin-left:40px;"><a href="#4%E3%80%81%E9%85%8D%E7%BD%AEmapred-site.xml" rel="nofollow">4、配置mapred-site.xml</a></p> 
<p id="5%E3%80%81%E9%85%8D%E7%BD%AEworkers-toc" style="margin-left:40px;"><a href="#5%E3%80%81%E9%85%8D%E7%BD%AEworkers" rel="nofollow">5、配置workers</a></p> 
<p id="6%E3%80%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AEhadoop-env.sh-toc" style="margin-left:40px;"><a href="#6%E3%80%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AEhadoop-env.sh" rel="nofollow">6、修改配置hadoop-env.sh</a></p> 
<p id="%E5%9B%9B%E3%80%81%E5%88%86%E5%8F%91%E6%96%87%E4%BB%B6-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E5%88%86%E5%8F%91%E6%96%87%E4%BB%B6" rel="nofollow">四、分发文件</a></p> 
<p id="%E4%BA%94%E3%80%81%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1" rel="nofollow">五、启动服务</a></p> 
<p id="%E5%85%AD%E3%80%81%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1-toc" style="margin-left:0px;"><a href="#%E5%85%AD%E3%80%81%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1" rel="nofollow">六、查看服务</a></p> 
<p id="%E4%B8%83%E3%80%81%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3-toc" style="margin-left:0px;"><a href="#%E4%B8%83%E3%80%81%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3" rel="nofollow">七、常见问题解决</a></p> 
<p id="1%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8B%E6%8F%90%E7%A4%BAOperation%20category%20READ%20is%20not%20supported%20in%20state%20standby-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8B%E6%8F%90%E7%A4%BAOperation%20category%20READ%20is%20not%20supported%20in%20state%20standby" rel="nofollow">1、高可用下提示Operation category READ is not supported in state standby</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81Hadoop%E9%83%A8%E7%BD%B2%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F">一、Hadoop部署的三种方式</h2> 
<h3 id="1%E3%80%81Standalone%20mode%EF%BC%88%E7%8B%AC%E7%AB%8B%E6%A8%A1%E5%BC%8F%EF%BC%89">1、Standalone mode（独立模式）</h3> 
<p>独立模式又称为单机模式，仅1个机器运行1个java进程，主要用于调试。</p> 
<h3 id="2%E3%80%81Pseudo-Distributed%20mode%EF%BC%88%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F%EF%BC%89">2、Pseudo-Distributed mode（伪分布式模式）</h3> 
<p>伪分布模式也是在1个机器上运行HDFS的NameNode和DataNode、YARN的 ResourceManger和NodeManager，但分别启动单独的java进程，主要用于调试。</p> 
<h3 id="3%E3%80%81Cluster%20mode%EF%BC%88%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%EF%BC%89">3、Cluster mode（集群模式）</h3> 
<p>单Namenode节点模式-高可用HA模式</p> 
<p>集群模式主要用于生产环境部署。会使用N台主机组成一个Hadoop集群。这种部署模式下，主节点和从节点会分开部署在不同的机器上。</p> 
<p></p> 
<p><span style="color:#fe2c24;"><strong>本教程主要安装 多Namenode 节点 高可用集群模式</strong></span></p> 
<p></p> 
<h2 id="%E4%BA%8C%E3%80%81%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">二、准备工作</h2> 
<h3 id="1%E3%80%81%E5%85%88%E5%AE%8C%E6%88%90zk%E5%92%8C%E9%9D%9E%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA">1、先完成zk高可用搭建</h3> 
<p><a href="https://blog.csdn.net/forest_long/article/details/128155528" title="​​​​​​​【大数据入门核心技术-Zookeeper】（五）ZooKeeper集群搭建">【大数据入门核心技术-Zookeeper】（五）ZooKeeper集群搭建</a></p> 
<p></p> 
<h3 id="2%E3%80%81%2Fetc%2Fhosts%E5%A2%9E%E5%8A%A0%E5%86%85%E5%AE%B9">2、/etc/hosts增加内容</h3> 
<blockquote> 
 <p>172.30.1.56 hadoop001</p> 
 <p>172.30.1.57 hadoop001</p> 
 <p>172.30.1.58 hadoop001</p> 
</blockquote> 
<p></p> 
<h3 id="3%E3%80%81%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95">3、各台服务器分别创建目录</h3> 
<blockquote> 
 <p>mkdir -p /data/bigdata/hadoop/tmp</p> 
 <p>mkdir -p /data/bigdata/hadoop/var</p> 
 <p>mkdir -p /data/bigdata/hadoop/dfs/name</p> 
 <p>mkdir -p /data/bigdata/hadoop/dfs/data</p> 
 <p>mkdir -p /data/bigdata/hadoop/jn</p> 
</blockquote> 
<p></p> 
<h3 id="4%E3%80%81%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E5%92%8C%E7%A6%81%E7%94%A8swap%E4%BA%A4%E6%8D%A2%E5%88%86%E5%8C%BA">4、关闭防火墙和禁用swap交换分区</h3> 
<p>1)关闭防火墙和SeLinux</p> 
<blockquote> 
 <p>systemctl stop firewalld &amp;&amp; systemctl disable firewalld<br> setenforce 0<br> sed -i 's/SELINUX=.*/SELINUX=disabled/g' /etc/sysconfig/selinux</p> 
</blockquote> 
<p>2)禁用swap交换分区</p> 
<blockquote> 
 <p>swapoff -a &amp;&amp; sed -i 's/SELINUX=.*/SELINUX=disabled/g' /etc/sysconfig/selinux</p> 
</blockquote> 
<h2></h2> 
<h3 id="5%E3%80%81%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E9%97%B4%E5%85%8D%E5%AF%86">5、三台机器间免密</h3> 
<p>生成密钥</p> 
<blockquote> 
 <p>ssh-keygen -t rsa</p> 
</blockquote> 
<p></p> 
<p>将密钥复制到其他机器</p> 
<blockquote> 
 <p>ssh-copy-id slave1<br> ssh-copy-id slave2</p> 
</blockquote> 
<h2></h2> 
<h3 id="6%E3%80%81%E5%AE%89%E8%A3%85jdk">6、安装jdk</h3> 
<p>将jdk目录复制到/usr/local</p> 
<p>vim /etc/profile</p> 
<blockquote> 
 <p>export JAVA_HOME=/usr/local/jdk1.8.0_131<br> export JRE_HOME=${JAVA_HOME}/jre<br> export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib<br> export PATH=${JAVA_HOME}/bin:$PATH</p> 
</blockquote> 
<p>source /etc/profile</p> 
<p>java -version</p> 
<p>查看结果</p> 
<p> java version "1.8.0_131"<br> Java(TM) SE Runtime Environment (build 1.8.0_131-b11)<br> Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode)</p> 
<p></p> 
<h3 id="7%E3%80%81%E4%B8%8B%E8%BD%BD%E5%A5%BDhadoop%E5%AE%89%E8%A3%85%E5%8C%85">7、下载好hadoop安装包</h3> 
<p><br> 下载地址</p> 
<p><a href="https://hadoop.apache.org/releases.html" rel="nofollow" title="Apache Hadoop">Apache Hadoop</a></p> 
<p>本次以hadoop3.2.1下载为例</p> 
<p></p> 
<blockquote> 
 <p>解压<br> tar zxvf hadoop-3.2.1.tar.gz -C /usr/local</p> 
 <p></p> 
 <p>vim /etc/profile</p> 
 <p></p> 
 <p>export HADOOP_HOME=/usr/local/hadoop-3.2.1<br> export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</p> 
 <p></p> 
 <p>source /etc/profile</p> 
</blockquote> 
<p></p> 
<h2 id="%E4%B8%89%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE">三、高可用配置</h2> 
<h3 id="1%E3%80%81%E9%85%8D%E7%BD%AEcore-site.xml">1、<strong>配置core-site.xml</strong></h3> 
<pre><code>&lt;configuration&gt;
    &lt;!-- 把多个 NameNode 的地址组装成一个集群 mycluster --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://mycluster&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 hadoop 运行时产生文件的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/data/bigdata/hadoop/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;hadoop101:2181,hadoop102:2181,hadoop103:2181&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- NN 连接 JN 重试次数，默认是 10 次 --&gt;
    &lt;property&gt;
        &lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt;
        &lt;value&gt;20&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 重试时间间隔，默认 1s --&gt;
    &lt;property&gt;
        &lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt;
        &lt;value&gt;5000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;

</code></pre> 
<h3 id="2%E3%80%81%E9%85%8D%E7%BD%AEhdfs-site.xml">2、<strong>配置hdfs-site.xml</strong></h3> 
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;/data/bigdata/hadoop/dfs/name&lt;/value&gt;
        &lt;description&gt;datanode 上存储 hdfs 名字空间元数据&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;/data/bigdata/hadoop/dfs/data&lt;/value&gt;
        &lt;description&gt;datanode 上数据块的物理存储位置&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
        &lt;description&gt;副本个数，默认配置是 3，应小于 datanode 机器数量&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
	
	
    &lt;!-- JournalNode 数据存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
        &lt;value&gt;/data/bigdata/hadoop/jn&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 完全分布式集群名称 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.nameservices&lt;/name&gt;
        &lt;value&gt;mycluster&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 集群中 NameNode 节点都有哪些 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;
        &lt;value&gt;nn1,nn2,nn3&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- NameNode 的 RPC 通信地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;
        &lt;value&gt;hadoop101:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;
        &lt;value&gt;hadoop102:8020&lt;/value&gt;
    &lt;/property&gt;
	&lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn3&lt;/name&gt;
        &lt;value&gt;hadoop103:8020&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- NameNode 的 http 通信地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;
        &lt;value&gt;hadoop101:9870&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;
        &lt;value&gt;hadoop102:9870&lt;/value&gt;
    &lt;/property&gt;
	&lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.mycluster.nn3&lt;/name&gt;
        &lt;value&gt;hadoop103:9870&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 指定 NameNode 元数据在 JournalNode 上的存放位置 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
        &lt;value&gt;qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/mycluster&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 访问代理类：client 用于确定哪个 NameNode 为 Active --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
        &lt;value&gt;sshfence&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 使用隔离机制时需要 ssh 秘钥登录--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
        &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 启用 nn 故障自动转移 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> 
<h3 id="3%E3%80%81%E9%85%8D%E7%BD%AEyarn-site.xml%E6%96%87%E4%BB%B6">3、配置yarn-site.xml文件</h3> 
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 启用 resourcemanager ha --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 声明两台 resourcemanager 的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
        &lt;value&gt;cluster-yarn1&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!--指定 resourcemanager 的逻辑列表--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
        &lt;value&gt;rm1,rm2,rm3&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- ========== rm1 的配置 ========== --&gt;
    &lt;!-- 指定 rm1 的主机名 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;
        &lt;value&gt;hadoop101&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 rm1 的 web 端地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;
        &lt;value&gt;hadoop101:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 rm1 的内部通信地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address.rm1&lt;/name&gt;
        &lt;value&gt;hadoop101:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm1&lt;/name&gt;
        &lt;value&gt;hadoop101:8030&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定供 NM 连接的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;/name&gt;
        &lt;value&gt;hadoop101:8031&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- ========== rm2 的配置 ========== --&gt;
    &lt;!-- 指定 rm2 的主机名 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;
        &lt;value&gt;hadoop102&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;
        &lt;value&gt;hadoop102:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address.rm2&lt;/name&gt;
        &lt;value&gt;hadoop102:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm2&lt;/name&gt;
        &lt;value&gt;hadoop102:8030&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;/name&gt;
        &lt;value&gt;hadoop102:8031&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- ========== rm3 的配置 ========== --&gt;
    &lt;!-- 指定 rm3 的主机名 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm3&lt;/name&gt;
        &lt;value&gt;hadoop103&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 rm3 的 web 端地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm3&lt;/name&gt;
        &lt;value&gt;hadoop103:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 rm3 的内部通信地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address.rm3&lt;/name&gt;
        &lt;value&gt;hadoop103:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定 AM 向 rm3 申请资源的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address.rm3&lt;/name&gt;
        &lt;value&gt;hadoop103:8030&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 指定供 NM 连接的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm3&lt;/name&gt;
        &lt;value&gt;hadoop103:8031&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 指定 zookeeper 集群的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
        &lt;value&gt;hadoop101:2181,hadoop102:2181,hadoop103:2181&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 启用自动恢复 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateSt ore&lt;/value&gt;
    &lt;/property&gt;
	
    &lt;!-- 环境变量的继承 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLAS
SPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
    &lt;/property&gt;

    &lt;!-- ZK中ZNode节点能存储的最大数据量，以字节为单位，默认是 1048576 字节，也就是1MB，现在扩大100倍 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.zk-max-znode-size.bytes&lt;/name&gt;
        &lt;value&gt;104857600&lt;/value&gt;
    &lt;/property&gt;
 
    &lt;!--用于状态存储的类,可以设置为--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;
   &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> 
<p></p> 
<h3 id="4%E3%80%81%E9%85%8D%E7%BD%AEmapred-site.xml">4、配置mapred-site.xml</h3> 
<pre><code>&lt;configuration&gt;
    &lt;!--  指定 MapReduce 程序运行在 Yarn 上  --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--  历史服务器端地址  --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;hadoop101:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;!--  历史服务器 web 端地址  --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;hadoop101:19888&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> 
<p></p> 
<h3 id="5%E3%80%81%E9%85%8D%E7%BD%AEworkers">5、配置workers</h3> 
<pre><code>hadoop101
hadoop102
hadoop103</code></pre> 
<p></p> 
<h3 id="6%E3%80%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AEhadoop-env.sh">6、修改配置<strong>hadoop-env.sh</strong></h3> 
<pre><code>export JAVA_HOME=/usr/local/jdk1.8.0_131
export HADOOP_HOME=/usr/local/hadoop-2.3.1



export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_JOURNALNODE_USER=root
export HDFS_ZKFC_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root</code></pre> 
<p></p> 
<h2 id="%E5%9B%9B%E3%80%81%E5%88%86%E5%8F%91%E6%96%87%E4%BB%B6">四、分发文件</h2> 
<blockquote> 
 <p>scp -r /usr/local/hadoop-3.2.1 hadoop102:/usr/local</p> 
 <p>scp -r /usr/local/hadoop-3.2.1 hadoop103:/usr/local</p> 
</blockquote> 
<p></p> 
<h2 id="%E4%BA%94%E3%80%81%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1">五、启动服务</h2> 
<p>在各个 JournalNode 节点上（每台虚拟机），输入以下命令启动 journalnode 服务</p> 
<p><strong>hdfs --daemon start journalnode</strong></p> 
<p></p> 
<p>node1上格式化namenode<br><strong>hdfs namenode -format</strong></p> 
<p></p> 
<p>node1上启动namenode<br><strong>hdfs --daemon start namenode</strong></p> 
<p></p> 
<p>在 [nn2,nn3] 上，同步 nn1 的元数据信息<br><strong>hdfs namenode -bootstrapStandby</strong></p> 
<p></p> 
<p>在node1节点上格式化ZKFC<br><strong>hdfs zkfc -formatZK</strong></p> 
<p></p> 
<p>node1节点上启动HDFS和Yarn<br><strong>start-dfs.sh<br> start-yarn.sh</strong></p> 
<p></p> 
<p>到此hadoop高可用集群搭建就完成了。</p> 
<p></p> 
<h2 id="%E5%85%AD%E3%80%81%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1">六、查看服务</h2> 
<blockquote> 
 <p>jps</p> 
</blockquote> 
<p><img alt="" height="226" src="https://images2.imgbox.com/d3/80/pX6ZDiS9_o.png" width="243"></p> 
<p><img alt="" height="219" src="https://images2.imgbox.com/c6/5f/pD9RCklu_o.png" width="280"></p> 
<p><img alt="" height="218" src="https://images2.imgbox.com/2b/93/vAbTFcl5_o.png" width="307"></p> 
<p></p> 
<p>查看yarn服务状态</p> 
<blockquote> 
 <p>yarn rmadmin  -getAllServiceState</p> 
 <p>yarn rmadmin -getServiceState rm1</p> 
</blockquote> 
<p></p> 
<p>zkCli.sh 客户端查看 ResourceManager 选举锁节点内容：</p> 
<blockquote> 
 <p>get -s /yarn-leader-election/cluster-yarn1/ActiveStandbyElectorLock</p> 
</blockquote> 
<p></p> 
<p></p> 
<p></p> 
<h2 id="%E4%B8%83%E3%80%81%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3">七、常见问题解决</h2> 
<h3 id="1%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8B%E6%8F%90%E7%A4%BAOperation%20category%20READ%20is%20not%20supported%20in%20state%20standby">1、高可用下提示Operation category READ is not supported in state standby</h3> 
<p>hadoop fs -ls / </p> 
<p>总提示</p> 
<p>hadoop fs -ls /</p> 
<p>2022-12-06 02:02:22,062 INFO retry.RetryInvocationHandler: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit <a href="https://s.apache.org/sbnn-error" rel="nofollow" title="https://s.apache.org/sbnn-error">https://s.apache.org/sbnn-error</a></p> 
<p>        at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:98)</p> 
<p>        at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:2021)</p> 
<p>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1449)</p> 
<p>        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3183)</p> 
<p>        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1173)</p> 
<p></p> 
<p><strong>解决办法：</strong></p> 
<p>手动将活跃的namenode切换到第一台</p> 
<pre><code>hdfs haadmin -failover nn3 nn1</code></pre> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e6ed19ad87a8d67db81a08d0c7fa0338/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">《软件工程》复习题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/26768aac3bd22eaa2c1a18fb2fa65727/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Chat GPT原理</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>