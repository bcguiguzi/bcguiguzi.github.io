<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>三行命令搞定nnUNet v2训练及推理！ - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="三行命令搞定nnUNet v2训练及推理！" />
<meta property="og:description" content="通过前面2小节的学习，我们配好了环境，准备了数据。现在开始你的训练之旅~~
同 V1 一样，一行命令搞定你的数据预处理，训练和测试！！
​
step1: 一行命令数据预处理 使用命令： nnUNetv2_plan_and_preprocess
注意： v2 版本的命令，都是以 nnUNetv2开头
nnUNetv2_plan_and_preprocess -h 可查看使用帮助 nnUNetv2_plan_and_preprocess -d 131（你的数据ID） --verify_dataset_integrity 数据预处理好后，会放在 nnUNet_preprocessed&gt;Datasetxxx_xxx里面
step2: 一行命令开始训练 使用 nnUNetv2_train 命令进行模型训练。命令的一般结构如下：
nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD [其他选项，参见 -h] eg: nnUNetv2_train 131 3d_fullres 1 (表示使用131这个数据集，模型用3d_fullres，训练第一折) UNET_CONFIGURATION： 用于标识所需的 U-Net 配置（defaults: 2d, 3d_fullres, 3d_lowres, 3d_cascade_lowres）。DATASET_NAME_OR_ID： 指定应在其上训练的数据集，FOLD 则指定要训练的 5 折交叉验证中的哪一个折数，0-4表示单个折数，all和5表示5折一起训练。 请注意，并非所有 U-Net 配置都适用于所有数据集。在图像尺寸较小的数据集中，级联 U-Net（以及其中的3D低分辨率配置）会被省略，因为全分辨率 U-Net 的裁剪大小已经涵盖了输入图像的大部分内容。
nnU-Net会每50个epochs存储一次 checkpoint。如果需要继续之前的训练，请将训练命令中添加 --c 参数。
nnUNetv2_train 131 3d_fullres 1 --c 重要提示：如果您计划使用 nnUNetv2_find_best_configuration，请添加 --npz 标记。这会让 nnU-Net 在最终验证期间保存 softmax 输出。它们是必需的。导出的 softmax 预测非常大，因此可能占用大量磁盘空间，因此默认情况下不启用此功能。如果您最初没有使用 --npz 标记运行，但现在需要 softmax 预测，请使用以下命令重新运行验证：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/577330b1b7fec02b70986930d9b26411/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-03T20:35:53+08:00" />
<meta property="article:modified_time" content="2023-09-03T20:35:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">三行命令搞定nnUNet v2训练及推理！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>通过前面2小节的学习，我们配好了环境，准备了数据。现在开始你的训练之旅~~</p> 
<p>同 V1 一样，一行命令搞定你的数据预处理，训练和测试！！<br> ​</p> 
<h3><a id="step1__4"></a>step1: 一行命令数据预处理</h3> 
<p>使用命令： <strong>nnUNetv2_plan_and_preprocess</strong></p> 
<p>注意： v2 版本的命令，都是以 <code>nnUNetv2</code>开头</p> 
<pre><code>nnUNetv2_plan_and_preprocess -h 可查看使用帮助
nnUNetv2_plan_and_preprocess -d 131（你的数据ID） --verify_dataset_integrity
</code></pre> 
<p>数据预处理好后，会放在 <code>nnUNet_preprocessed&gt;Datasetxxx_xxx</code>里面</p> 
<h3><a id="step2__14"></a>step2: 一行命令开始训练</h3> 
<p>使用 <code>nnUNetv2_train</code> 命令进行模型训练。命令的一般结构如下：</p> 
<pre><code class="prism language-bash">nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD <span class="token punctuation">[</span>其他选项，参见 -h<span class="token punctuation">]</span>
eg: nnUNetv2_train <span class="token number">131</span> 3d_fullres <span class="token number">1</span> <span class="token punctuation">(</span>表示使用131这个数据集，模型用3d_fullres，训练第一折<span class="token punctuation">)</span>
</code></pre> 
<ul><li>UNET_CONFIGURATION： 用于标识所需的 U-Net 配置（defaults: 2d, 3d_fullres, 3d_lowres, 3d_cascade_lowres）。</li><li>DATASET_NAME_OR_ID： 指定应在其上训练的数据集，</li><li>FOLD 则指定要训练的 5 折交叉验证中的哪一个折数，0-4表示单个折数，all和5表示5折一起训练。</li></ul> 
<p><strong>请注意，并非所有 U-Net 配置都适用于所有数据集。在图像尺寸较小的数据集中，级联 U-Net（以及其中的3D低分辨率配置）会被省略，因为全分辨率 U-Net 的裁剪大小已经涵盖了输入图像的大部分内容。</strong></p> 
<p>nnU-Net会每50个epochs存储一次 checkpoint。如果需要继续之前的训练，请将训练命令中添加 <code>--c</code> 参数。</p> 
<pre><code>nnUNetv2_train 131 3d_fullres 1 --c
</code></pre> 
<p>重要提示：如果您计划使用 <code>nnUNetv2_find_best_configuration</code>，请添加 <code>--npz</code> 标记。这会让 nnU-Net 在最终验证期间保存 softmax 输出。它们是必需的。导出的 softmax 预测非常大，因此可能占用大量磁盘空间，因此默认情况下不启用此功能。如果您最初没有使用 <code>--npz</code> 标记运行，但现在需要 softmax 预测，请使用以下命令重新运行验证：</p> 
<pre><code class="prism language-bash">nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD <span class="token parameter variable">--val</span> <span class="token parameter variable">--npz</span>
</code></pre> 
<p>您可以通过使用 <code>-device DEVICE</code> 来指定 nnU-Net 应使用的设备。DEVICE 只能是 cpu、cuda 或 mps。如果您有多个 GPU，请使用 <code>CUDA_VISIBLE_DEVICES=X nnUNetv2_train [...]</code> 来选择 GPU ID（需要设备为 cuda）。</p> 
<p>有关其他选项，请参阅 <code>nnUNetv2_train -h</code>。</p> 
<h4><a id="2D_UNet_42"></a>2D U-Net</h4> 
<p>对于 FOLD 在 [0, 1, 2, 3, 4] 中，运行：</p> 
<pre><code class="prism language-bash">nnUNetv2_train DATASET_NAME_OR_ID 2d FOLD <span class="token punctuation">[</span>--npz<span class="token punctuation">]</span>
</code></pre> 
<h4><a id="3D__UNet_48"></a>3D 全分辨率 U-Net</h4> 
<p>对于 FOLD 在 [0, 1, 2, 3, 4] 中，运行：</p> 
<pre><code class="prism language-bash">nnUNetv2_train DATASET_NAME_OR_ID 3d_fullres FOLD <span class="token punctuation">[</span>--npz<span class="token punctuation">]</span>
</code></pre> 
<h4><a id="3D_UNet__54"></a>3D U-Net 级联</h4> 
<h5><a id="3D__UNet_55"></a>3D 低分辨率 U-Net</h5> 
<p>对于 FOLD 在 [0, 1, 2, 3, 4] 中，运行：</p> 
<pre><code class="prism language-bash">nnUNetv2_train DATASET_NAME_OR_ID 3d_lowres FOLD <span class="token punctuation">[</span>--npz<span class="token punctuation">]</span>
</code></pre> 
<h5><a id="3D__UNet_61"></a>3D 全分辨率 U-Net</h5> 
<p>对于 FOLD 在 [0, 1, 2, 3, 4] 中，运行：</p> 
<pre><code class="prism language-bash">nnUNetv2_train DATASET_NAME_OR_ID 3d_cascade_fullres FOLD <span class="token punctuation">[</span>--npz<span class="token punctuation">]</span>
</code></pre> 
<p><strong>请注意级联的 3D 全分辨率 U-Net 需要已完成低分辨率 U-Net 的五个折数！</strong></p> 
<p>训练的模型将被写入到<code>nnUNet_results</code>文件夹中。每次训练都会生成一个自动生成的输出文件夹名称：</p> 
<pre><code>nnUNet_results/DatasetXXX_MYNAME/TRAINER_CLASS_NAME__PLANS_NAME__CONFIGURATION/FOLD
</code></pre> 
<p>例如，对于从MSD中获取的Dataset002_Heart数据集，文件结构如下：</p> 
<pre><code>nnUNet_results/
├── Dataset002_Heart
│   ├── nnUNetTrainer__nnUNetPlans__2d
│   │   ├── fold_0
│   │   ├── fold_1
│   │   ├── fold_2
│   │   ├── fold_3
│   │   ├── fold_4
│   │   ├── dataset.json
│   │   ├── dataset_fingerprint.json
│   │   └── plans.json
│   └── nnUNetTrainer__nnUNetPlans__3d_fullres
│       ├── fold_0
│       ├── fold_1
│       ├── fold_2
│       ├── fold_3
│       ├── fold_4
│       ├── dataset.json
│       ├── dataset_fingerprint.json
│       └── plans.json
</code></pre> 
<p>请注意，在这里不存在3d_lowres和3d_cascade_fullres，因为这个数据集没有触发级联。在每个模型训练的输出文件夹（每个fold_x文件夹）中，将创建以下文件：</p> 
<ul><li>debug.json：包含用于训练该模型的蓝图和推断参数的摘要，以及其他一些有用但不易阅读的信息，用于调试。</li><li>checkpoint_best.pth：在训练过程中识别出的最佳模型的检查点文件。除非您显式告诉nnU-Net使用它，否则目前不会使用它。</li><li>checkpoint_final.pth：最终模型的检查点文件（训练结束后）。这是用于验证和推断的模型。</li><li>network_architecture.pdf（仅在安装了hiddenlayer时可用！）：一个带有网络架构图的PDF文档。</li><li>progress.png：显示训练过程中的loss、Dice系数、学习率和epoch时间。</li></ul> 
<h4><a id="_106"></a>自动确定最佳配置</h4> 
<p>一旦所需的配置经过训练（完全5折交叉验证），您就可以告诉 nnU-Net 自动识别最适合您的组合：</p> 
<pre><code>nnUNetv2_find_best_configuration DATASET_NAME_OR_ID -c CONFIGURATIONS
</code></pre> 
<p>具体详见官网，因为我没有完成5折训练，无法进行实验。</p> 
<h3><a id="step3_113"></a>step3:一行命令进行推理/预测</h3> 
<pre><code>nnUNetv2_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -d DATASET_NAME_OR_ID -c CONFIGURATION --save_probabilities
# nnUNetv2_predict -h 查看更多参数解析
</code></pre> 
<ul><li>INPUT_FOLDER: 测试数据地址</li><li>OUTPUT_FOLDER： 分割数据存放地址</li><li>CONFIGURATION： 使用的什么架构，<code>2d or 3d_fullres or 3d_cascade_fullres</code>等，这里训练用的什么就写什么</li><li>save_probabilities：将预测概率与需要大量磁盘空间的预测分段掩码一起保存。</li></ul> 
<p>​默认情况下，推理将通过交叉验证的所有 5 个折叠作为一个整体来完成（根据5个模型得到一个结果）。我们强烈建议您使用全部 5 折。因此，在运行推理之前必须训练所有 5 个折叠。</p> 
<p>要想每个模型分开得到结果，就加参数<code>-f all</code>，或者只为某一折出结果，就加参数<code>-f 1</code>(得到 fold 1 的结果)</p> 
<p>举例：得到fold 1 的推理结果</p> 
<pre><code>nnUNetv2_predict -i ${nnUNet_raw}/Dataset131_WORD/ImagesTs -o output -d 131 -c 3d_fullres -f 1
# ${nnUNet_raw} 之前设置的环境变量，nnUNet_raw的地址，不会这种方法，可以直接把文件夹的绝对路径写出来
</code></pre> 
<p><img src="https://images2.imgbox.com/7b/63/OIK0PFNN_o.png" alt=""><br> 正确推理后终端显示如上，在output文件夹中会出现每个case的分割结果（nii.gz格式）</p> 
<p><img src="https://images2.imgbox.com/26/f3/bToAkDyE_o.png" alt=""><br> 注意，他不会直接得到每个case的dice值等相关分割指标<br> <img src="https://images2.imgbox.com/7d/27/FG89rard_o.png" alt=""><br> 在之前的文章中，早就分享过各类指标的求法啦。只需要动动小指，按一下 ctrl+c, 在ctrl+v, 再改一下数据地址。就能得到每个case的指标, 如下图所示<br> <img src="https://images2.imgbox.com/c0/dd/CZzVDcYH_o.png" alt=""><br> 查看之前的文章链接<a href="https://blog.csdn.net/u014264373/article/details/117666881" title="论文中常用的图像分割评价指标-附完整代码">【理论+实践】史上最全-论文中常用的图像分割评价指标-附完整代码</a></p> 
<p><strong>还没完！</strong></p> 
<p>这只是得到了每个case的指标，那整体的指标计算呢, 下面一招，直接得到论文结果！<br> <img src="https://images2.imgbox.com/b2/db/Ci1vQpJ5_o.png" alt=""><br> 查看之前的文章链接 <a href="https://blog.csdn.net/u014264373/article/details/119451236" title="如何用excel快速实现“平均值±标准差”">如何用excel快速实现“平均值±标准差”</a></p> 
<h3><a id="nnunet_v1__v2__148"></a>nnunet v1 和 v2 分割结果比较</h3> 
<p>论文里面，数据集WORD腹部16个器官的v1和v2结果比较，相差是不大的<br> <img src="https://images2.imgbox.com/9e/f9/cIoIt90g_o.png" alt=""><br> 我在该数据集上也跑了一遍，由于时间关系，只跑了一折。</p> 
<p><img src="https://images2.imgbox.com/c3/e0/2xfaxrJi_o.png" alt="v1 版本"></p> 
<p><img src="https://images2.imgbox.com/30/48/JhfXh6o9_o.png" alt="v2 版本"></p> 
<p>至于哪个版本结果最好，我想应该是没有统一答案的。如果你追求一个最好的指标，高0.01也是高，那我就建议两个版本都跑，每个模型都跑，5折全跑。all in,最后再来筛选。<br> <img src="https://images2.imgbox.com/35/bd/d8R6lioV_o.png" alt=""></p> 
<blockquote> 
 <p>文章持续更新，可以关注微信公众号【医学图像人工智能实战营】获取最新动态，一个关注于医学图像处理领域前沿科技的公众号。坚持已实践为主，手把手带你做项目，打比赛，写论文。凡原创文章皆提供理论讲解，实验代码，实验数据。只有实践才能成长的更快，关注我们，一起学习进步~</p> 
</blockquote> 
<p>我是Tina, 我们下篇博客见~</p> 
<p>白天工作晚上写文，呕心沥血</p> 
<p>觉得写的不错的话最后，<strong>求点赞，评论，收藏。或者一键三连</strong><br> <img src="https://images2.imgbox.com/b8/d1/AtXDRHEn_o.gif" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/22acf294ef6ded27ad7ab51d56d0c392/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ORB-SLAM3复现的详细过程——配置安装及ROS和脚本运行---Ubuntu20.04</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/65f84a7e4792ae6970afe8de4dcf033d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vuejs计算属性computed &amp; 监听属性watch</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>