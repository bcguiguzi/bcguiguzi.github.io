<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CS143-project3 基于bag of words 的场景识别 Scene Recognition with Bag of Words - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CS143-project3 基于bag of words 的场景识别 Scene Recognition with Bag of Words" />
<meta property="og:description" content="本项目实现两种不同的图像表示——小图像和SIFT特征包，以及两种不同的分类技术——最近邻和线性SVM。通过试验得到准确率是
小图像和最近邻分类器 (准确率20.50%).
SIFT表示包和最近邻分类器 (准确率49.99%).
SIFT表示包和线性SVM分类器 (准确率68.10%). 以下通过4个方面进行详细说明：
小图像特征.最近邻分类器.SIFT表示包.SVM分类器 系统环境：
操作系统：WIN7
实现平台：MATLAB2014a
一.小图像特征表示 小图像表示法比较简单，对图像进行抽样，使图像缩小至16*16的大小。
代码如下：
N = size(image_paths,1); image_feats = [];
for i = 1:N path = image_paths{i,1};
image = imread(path);
%image = rgb2gray(single(image)/255); %转换为灰度图像
image = imresize(image,[16,16]); %转换为16*16的大小
image = reshape(image, 1, 256); %转换为1*256的大小
image_feats = cat(1,image_feats,image);
end
二.最近邻分类器 KNN近邻分类器是一种有监督的分类算法。此项目中，测试图像直接在训练图像集中寻找距离最短的图像，将本测试图像的类别就分为此距离最短的训练图像的类别
实现起来也很简单，以下是代码：
predicted_categories = [];
D = vl_alldist2(test_image_feats&#39;,train_image_feats&#39;); %行转换为列进行距离计算256列
[Y,I] = min(D); %最小距离的计算
predicted_categories = train_labels(I); %返回最近邻（最相似）的类别
三.SIFT表示包 Bag-of-words模型是信息检索领域常用的文档表示方法。在信息检索中，BOW模型假定对于一个文档，忽略它的单词顺序和语法、句法等要素，将其仅仅看作是若干个词汇的集合，文档中每个单词的出现都是独立的，不依赖于其它单词是否出现。也就是说，文档中任意一个位置出现的任何单词，都不受该文档语意影响而独立选择的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/a4f02642e1ecaa9b220bf1b0b7bcff07/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-12-28T11:23:38+08:00" />
<meta property="article:modified_time" content="2016-12-28T11:23:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CS143-project3 基于bag of words 的场景识别 Scene Recognition with Bag of Words</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p align="left" style="color:rgb(68,68,68)">本项目实现两种不同的图像表示——小图像和SIFT特征包，以及两种不同的分类技术——最近邻和线性SVM。通过试验得到准确率是</p> 
<p align="left" style="color:rgb(68,68,68)">小图像和最近邻分类器 (准确率20.50%).</p> 
<p align="left" style="color:rgb(68,68,68)">SIFT表示包和最近邻分类器 (准确率49.99%).</p> 
<span style="color:#000000">SIFT表示包和线性SVM分类器 (准确率68.10%).</span> 
<p style="color:rgb(68,68,68)"> 以下通过4个方面进行详细说明：</p> 
<ol style="color:rgb(0,0,0)"><li style="color:rgb(68,68,68)"><span style="color:#de3737">小图像特征<a target="_blank" href="http://write.blog.csdn.net/postedit#tiny" rel="nofollow noopener noreferrer">.</a></span></li><li style="color:rgb(68,68,68)"><span style="color:#de3737">最近邻分类器.</span></li><li style="color:rgb(68,68,68)"><span style="color:#de3737">SIFT表示包.</span></li><li style="color:rgb(68,68,68)"><span style="color:#de3737">SVM分类器</span></li></ol> 
<p style="color:rgb(68,68,68)"><span style="color:#de3737"></span> </p> 
<p style=""><span style="font-family:Arial">系统环境：</span></p> 
<p style="">操作系统：WIN7</p> 
<p style="">实现平台：MATLAB2014a</p> 
<p style="color:rgb(68,68,68)"> </p> 
<h3 style="">一.小图像特征表示</h3> 
<p style="">小图像表示法比较简单，对图像进行抽样，使图像缩小至16*16的大小。</p> 
<p style="">代码如下：</p> 
<p style=""><code><br> N = size(image_paths,1); <br> image_feats = [];<br> for i = 1:N <br>   path = image_paths{i,1};<br>   image = imread(path);<br>   %image = rgb2gray(single(image)/255); %转换为灰度图像<br>   image = imresize(image,[16,16]); %转换为16*16的大小<br>   image = reshape(image, 1, 256); %转换为1*256的大小<br>   image_feats = cat(1,image_feats,image);<br> end</code></p> 
<h3 style="">二.最近邻分类器</h3> 
<p style=""><span style="font-family:宋体">KNN近邻分类器是一种有监督的分类算法。此项目中，测试图像直接在训练图像集中寻找距离最短的图像，将本测试图像的类别就分为此距离最短的训练图像的类别</span></p> 
<p style=""><span style="font-family:宋体">实现起来也很简单，以下是代码：</span></p> 
<p style=""><span style="font-family:宋体">predicted_categories = [];<br> D = vl_alldist2(test_image_feats',train_image_feats'); %行转换为列进行距离计算256列<br> [Y,I] = min(D); %最小距离的计算<br> predicted_categories = train_labels(I); %返回最近邻（最相似）的类别</span></p> 
<p style="">　</p> 
<h3 style="">三.SIFT表示包</h3> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">Bag-of-words<span style="font-family:宋体">模型是信息检索领域常用的文档表示方法。在信息检索中，</span><span style="font-family:'Times new roman'">BOW</span><span style="font-family:宋体">模型假定对于一个文档，忽略它的单词顺序和语法、句法等要素，将其仅仅看作是若干个词汇的集合，文档中</span>每个单词的出现都是独立的，不依赖于其它单词是否出现。也就是说，文档中任意一个位置出现的任何单词，都不受该文档语意影响而独立选择的。</span></p> 
<p style=""><span lang="EN-US" style="font-family:宋体; font-size:12pt">SIFT</span><span style="font-family:宋体; font-size:12pt">表示包</span><span style="font-family:宋体; font-size:10.5pt">就是参考了文本文档的这种表示方法。将每一副图像视为一个文档，每个特征描述（描述可以多种，本项目使用dense sift）视为一个词汇。构建一个bag_of_feature模型</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">有了这个模型，便能对训练图像和测试图像进行比较了。所以，怎么构建这个模型是重点。</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">构建bag_of_feature需要两个步骤</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">1.创建词汇表</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">    </span><span style="font-family:宋体; font-style:normal; font-size:10.5pt"><span style="font-family:宋体">利用</span><span style="font-family:'Times new roman'">dense_sift</span><span style="font-family:宋体">算法，从每类图像中提取视觉词汇(特征描述算子)。具体实现是调用vl_feat库的vl_dsift函数，其中关键参数有binsize(步长)和step(间距)等。</span></span></p> 
<p style=""><span style="font-family:宋体; font-style:normal; font-size:10.5pt">然后对获取到的词汇做k_means 聚类。k_means是无监督的聚类算法，利用欧式距离将样本分为指定好的k类。k可以调整，本文对k进行不同的取值(下图2)，并分析其性能和准确率。</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">最后，所有图的视觉词汇便汇聚成了k维的一个向量，称其为词汇表。以下为实现代码：</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">vocab2 = [];<br> for i = 1:N <br>   path = image_paths{i};<br>   image = imread(path);<br>   %image = vl_imsmooth(single(image),1.5);<br>   [locations, SIFT_features] = vl_dsift(single(image),'size',1,'step',4);<br>   %[locations, SIFT_features] = vl_dsift(single(image));<br>   %sampled_features = [sampled_features,SIFT_features];<br>   sampled_features = single(SIFT_features);<br>   [vocab1, assignments] = vl_kmeans(sampled_features, vocab_size);<br>   vocab2 = [vocab2,vocab1];<br>   sampled_features = [];<br> end<br> [vocab, assignments] = vl_kmeans(vocab2, vocab_size);</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">2.每幅图像统计词汇直方图</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">    有了词汇表，接下来是利用词汇表来表示图像。通过sift算法可以提取到图像的很多特征，这些特征都可以在词汇表里面找到与其最接近的那个词汇。那么这个词汇的值就+1（假如</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">是+1，只是为了简单计数）。遍历所有特征点，计算词汇出现的次数，形成一个直方图。假如一个图像获取到了N个特征点，那么用词汇表来表示这个图像的时候就是k维的向量，其值总和</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">为N。为了平衡不同图像获取特征点数量不同，还必须对词汇直方图进行归一化。以下为实现代码：</span></p> 
<p style=""><span style="font-family:宋体; font-size:10.5pt">N = size(image_paths,1);<br> parpool(4);%使用并行算法，提高执行效率<br> image_feats = [];parfor i = 1:N <br>   path = image_paths{i};<br>   image = imread(path);<br>   [locations, SIFT_features] = vl_dsift(single(image),'size',1,'step',4);<br>   M = size(SIFT_features,2); %获取特征的数量<br>   SIFT_features = single(SIFT_features);<br>   his = zeros(1,vocab_size); %初始化直方图<br>   D = vl_alldist2(SIFT_features,temp_vocab); %取最小距离<br>   [Y,I] = min(D'); %计算出最小的距离的单词表索引<br>   for j = 1:vocab_size<br>   %循环建立直方图<br>     F = find(I == j);<br>     h_value = size(F,2); %j单词出现的次数<br>     his(1,j) = h_value; %构建直方图<br>   end<br>   his = his ./ norm(his); %归一化直方图<br>   image_feats = [image_feats;his];<br> end<br> delete(gcp('nocreate'));</span></p> 
<p style=""> </p> 
<p style=""><img src="https://images2.imgbox.com/42/02/nQkjo5Rf_o.gif" alt=""></p> 
<p style="">图2(binsize:4 step:4 trans_images:200)</p> 
<p style="">可以看到，当k值越大时，每幅图像能分到更加精确的类别，因此准确率也越高。但是同时计算量也越高，性能越差。</p> 
<h3 style="">四.SVM分类器</h3> 
<p style="">线性SVM分类器是一中有监督的分类算法。其把样本空间映射到更高维的空间，使其线性可分。并构建分类的线性函数，大于0的属于此类，小于0的则不属于</p> 
<p style="">本项目不详细讨论SVM的实现方法，知识用它来对前面已经获取到的bag_of_feature进行分类</p> 
<p style="">思路：</p> 
<p style="">1.循环15个场景,对train_image_feats进行svm训练，得到15个分类器<br> 2.循环test_image_feats图，每幅图进行15个分类计算<br> 3.计算各个分类得分，最高分则为此类</p> 
<p style="">关键代码如下：</p> 
<p style="">[W B] = vl_svmtrain(train_image_feats', labels, 0.00006); %调用vl_feat库函数训练svm</p> 
<p style="">score = w'*image' + b ; %评价公式</p> 
<p style="">　</p> 
<p style="">其中vl_svmtrain的LAMBDA参数对准确度比较敏感，通过多值实验，确定了效果较好的值</p> 
<p style=""><img src="https://images2.imgbox.com/d4/d7/dV9DB8Gm_o.gif" alt=""></p> 
<p style="">下图为当参数选0.00006时，bag of feature+svm 的可视化评估：</p> 
<p style=""><img src="https://images2.imgbox.com/2c/68/2m1co12s_o.png" alt=""></p> 
<p style="">Results visualization for poorly performing recognition pipeline.</p> 
<p style="color:rgb(68,68,68)"><span style="">Accuracy (mean of diagonal of confusion matrix) is 0.681</span></p> 
<p> </p> 
<h3 style="">提示与说明</h3> 
<p style="">1.<span style="font-family:宋体; color:red; font-size:12pt">用不同的词汇表规模做实验，并报告性能。例如：<span lang="EN-US">10, 20, 50,<strong> </strong>100, 200, 400, 1000, 10000</span>。</span></p> 
<p style="">2.get_bags_of_sifts加入了并行算法，用4个核同时抽取图像sift描述和计算直方图，以提高性能。通过实验，比串行节省约1/3的时间</p> 
<p style="">3.SVM中，试样了不同的LAMBDA参数，评估其准确性</p> 
<p style="">4.build_vocabulary中实验了3种算法，最后取效果较优的第三种算法</p> 
<p style="">    第一种算法，从1500幅图中随机抽取一定数量的图像进行sift计算，可能抽取样本不够均匀，影响匹配正确率<br>     第二种算法：先在15个场景的每个场景中100幅图进行sift计算，kmean计算后，再汇总做kmean。<br>     第三种算法：先在每幅图进行sift计算，kmean计算后，再汇总做kmean。</p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0e3d4cb628b2fe571c41c9be2a21fcf8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Spring Security http basic 示例代码</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a7696caca2918f22a0e6f29c27fefa04/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux设备驱动五 (1)总线、设备和驱动</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>