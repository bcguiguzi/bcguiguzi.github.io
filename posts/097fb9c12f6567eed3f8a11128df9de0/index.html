<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Logstash jdbc插件实现数据增量更新 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Logstash jdbc插件实现数据增量更新" />
<meta property="og:description" content="Logstash jdbc插件实现数据增量更新 上节我们看了如何抽取关系型数据库数据至elasticsearch，但实际中我们需要实现增量更新，本文讨论如何实现增量更新。
更新elasticsearch数据 确保elasticsearch中数据为最新的，即原数据表数据更新后推送至elasticsearch中。一般有两种方法：
定时运行相同的logstash配置文件，则会一遍一遍发送数据————包括已改变的数据和未改变的数据。仅发送表中已改变的数据。 下面我们分别探讨这两种方法，逐步掌握一些关键配置，最终实现数据高效地增量更新。
第一种方法——全量更新 第一种方法，配置文件大致如下：
input { jdbc { jdbc_driver_library =&gt; &#34;config.d/ojdbc5.jar&#34; jdbc_driver_class =&gt; &#34;Java::oracle.jdbc.driver.OracleDriver&#34; jdbc_connection_string =&gt; &#34;jdbc:oracle:thin:@192.168.0.192:1521:orcl&#34; jdbc_user =&gt; &#34;testuser&#34; jdbc_password =&gt; &#34;yourpassword&#34; jdbc_paging_enabled =&gt; &#34;true&#34; statement =&gt; &#34;select comp_name,comp_type,unified_code,id as person_id from leg_info&#34; schedule =&gt; &#34;0 5 * * * *&#34; } } output { elasticsearch { index =&gt; &#34;leg_base_info&#34; document_id=&gt; &#34;%{person_id}&#34; hosts =&gt; [&#34;http://localhost:9200&#34;] } } 使用’schedule’选项实现周期运行。这里指定每5分钟运行一次。你可以根据业务需要进行定义，语法可以参考cron教程。
那为什么要指定document_id选项呢？
在elasticsearch中，每个文档都会创建唯一ID，用于标识该文档。因为需要反复运行logstash配置文件，会重复创建相同的文档。通过使用document_id字段可以避免创建重复文档。这里我们告诉插件使用表的主键(id字段)作为文档ID。这样elasticsearch就不会对相同记录创建多个文档，已存在的文档会被覆盖。elasticsearch会保存新增的记录和更新的记录。
第二种方法——增量更新 为了在elasticsearch中实现增量更新，则需要数据库中有一列用作参考，示例表中有update_date字段表示该行数据最后更新时间。下面使用该列,配置文件如下：
input { jdbc { jdbc_driver_library =&gt; &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/097fb9c12f6567eed3f8a11128df9de0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-07-20T12:58:54+08:00" />
<meta property="article:modified_time" content="2019-07-20T12:58:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Logstash jdbc插件实现数据增量更新</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Logstash_jdbc_0"></a>Logstash jdbc插件实现数据增量更新</h3> 
<p><a href="https://blog.csdn.net/neweastsun/article/details/96581236">上节</a>我们看了如何抽取关系型数据库数据至elasticsearch，但实际中我们需要实现增量更新，本文讨论如何实现增量更新。</p> 
<h3><a id="elasticsearch_4"></a>更新elasticsearch数据</h3> 
<p>确保elasticsearch中数据为最新的，即原数据表数据更新后推送至elasticsearch中。一般有两种方法：</p> 
<ol><li>定时运行相同的logstash配置文件，则会一遍一遍发送数据————包括已改变的数据和未改变的数据。</li><li>仅发送表中已改变的数据。</li></ol> 
<p>下面我们分别探讨这两种方法，逐步掌握一些关键配置，最终实现数据高效地增量更新。</p> 
<h3><a id="_12"></a>第一种方法——全量更新</h3> 
<p>第一种方法，配置文件大致如下：</p> 
<pre><code>input {
    jdbc {
        jdbc_driver_library =&gt; "config.d/ojdbc5.jar"
        jdbc_driver_class =&gt; "Java::oracle.jdbc.driver.OracleDriver"
        jdbc_connection_string =&gt; "jdbc:oracle:thin:@192.168.0.192:1521:orcl"
        jdbc_user =&gt; "testuser"
        jdbc_password =&gt; "yourpassword"
        jdbc_paging_enabled =&gt; "true"
        statement =&gt; "select comp_name,comp_type,unified_code,id as person_id from leg_info"
        schedule =&gt; "0 5 * * * *"
    }
}
output {
    elasticsearch {
        index =&gt; "leg_base_info"
        document_id=&gt; "%{person_id}"
        hosts =&gt; ["http://localhost:9200"]
    }
}
</code></pre> 
<p>使用’schedule’选项实现周期运行。这里指定每5分钟运行一次。你可以根据业务需要进行定义，语法可以参考<a href="https://blog.csdn.net/neweastsun/article/details/96566301">cron教程</a>。</p> 
<p>那为什么要指定document_id选项呢？</p> 
<p>在elasticsearch中，每个文档都会创建唯一ID，用于标识该文档。因为需要反复运行logstash配置文件，会重复创建相同的文档。通过使用document_id字段可以避免创建重复文档。这里我们告诉插件使用表的主键(id字段)作为文档ID。这样elasticsearch就不会对相同记录创建多个文档，已存在的文档会被覆盖。elasticsearch会保存新增的记录和更新的记录。</p> 
<h3><a id="_43"></a>第二种方法——增量更新</h3> 
<p>为了在elasticsearch中实现增量更新，则需要数据库中有一列用作参考，示例表中有update_date字段表示该行数据最后更新时间。下面使用该列,配置文件如下：</p> 
<pre><code>input {
    jdbc {
        jdbc_driver_library =&gt; "config.d/ojdbc5.jar"
        jdbc_driver_class =&gt; "Java::oracle.jdbc.driver.OracleDriver"
        jdbc_connection_string =&gt; "jdbc:oracle:thin:@192.168.0.192:1521:orcl"
        jdbc_user =&gt; "testuser"
        jdbc_password =&gt; "yourpassword"
        jdbc_paging_enabled =&gt; "true"
        statement =&gt; "select comp_name,comp_type,unified_code,id as person_id from leg_info where update_date &gt; :sql_last_value"
        tracking_column_type =&gt; "timestamp"
        schedule =&gt; "0 5 * * * *"
    }
}
output {
    elasticsearch {
        index =&gt; "leg_base_info"
        document_id=&gt; "%{person_id}"
        hosts =&gt; ["http://localhost:9200"]
    }
}
</code></pre> 
<p>这里我使用了新的选项 <code>:sql_last_value</code>. 其值用于过滤数据，初始为1970 1 月1 日 星期四。然后跳至当前时间，随后根据schedule 选项中指定的时间周期进行递增。</p> 
<p>当运行上述logstash配置文件时，控制台输出大概如下：</p> 
<pre><code>select * from leg_info where update_date&gt;’2019–07–20 13:08:00'
select * from leg_info where update_date&gt;’2019–07–20 13:13:00'
select * from leg_info where update_date&gt;’2019–07–20 13:18:00'
</code></pre> 
<p><code>sql_last_value</code>参数值根据scheduler自动更新。<code>sql_last_value</code> 存储在哪儿？</p> 
<p>其自动被保存在名为 <code>.logstash_jdbc_last_run</code> 的元数据文件中. windows 中的位置为 <code>C:/Users/%username%</code> ， Linux 则相应的home文件夹中。</p> 
<p>我们也可以配置仅抽取update_date大于最后推送记录update_date的数据，而不是根据scheduler增加 :sql_last_value 的值。如果update_date是在程序级别而不是数据库级别设置的，这非常合适(因为Logstash可以在记录保存到数据库时运行查询)。因此，我们可能会错过一些记录)。</p> 
<p>下面的示例配置文件，使用<strong>use_column_value</strong>字段告诉logstash使用该列的值：</p> 
<pre><code>input {
    jdbc {
        jdbc_driver_library =&gt; "config.d/ojdbc5.jar"
        jdbc_driver_class =&gt; "Java::oracle.jdbc.driver.OracleDriver"
        jdbc_connection_string =&gt; "jdbc:oracle:thin:@192.168.0.192:1521:orcl"
        jdbc_user =&gt; "testuser"
        jdbc_password =&gt; "yourpassword"
        jdbc_paging_enabled =&gt; "true"
        statement =&gt; "select comp_name,comp_type,unified_code,comp_address,id as person_id from leg_info where update_date &gt; :sql_last_value"
        use_column_value =&gt; true
        tracking_column =&gt; "update_date"
        tracking_column_type =&gt; "timestamp"
        schedule =&gt; "0 5 * * * *"
    }
}
output {
    elasticsearch {
        index =&gt; "leg_base_info"
        document_id=&gt; "%{person_id}"
        hosts =&gt; ["http://localhost:9200"]
    }
}
</code></pre> 
<p>update_date是timestamp列。因此我们额外指定tracking_column_type选项。另外需通过use_column_value选项指定用于被跟踪的特定列。这样:sql_last_value在包括最后被推送记录的update_date字段值。因此，当运行该计划，将查询增量数据。</p> 
<p>##　总结</p> 
<p>本文我们讨论如何使用Logstash实现增量抽取关系型数据库数据至Elasticsearch中。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c5568deeac4cc683e2d24a27297369af/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GC算法 (标记清除、复制、标记整理、 分代收集)  、     新生代  老年代</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c69d48870ab1975f317596e8e34da738/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">国际会议poster：  海报制作流程 &amp; 格式介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>