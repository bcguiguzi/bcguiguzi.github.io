<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>梦飞openmv--stm32单片机跑AI - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="梦飞openmv--stm32单片机跑AI" />
<meta property="og:description" content="1 背景
前面两篇文章《openmv底层算法剖析---梦飞openmv前传》 以及《梦飞openmv py-AI机器视觉_自主开发openmv底层固件和硬件》 充分展示了梦飞openmv的开发历程，也充分证实了单片机做图像识别算法的可行性。 引用openmv官方的话术： OpenMV适合做什么？ ---DIY相关的项目制作，比如追踪小球的车，云台，或者解魔方的机器人。 ---对成本要求很高的嵌入式工业方案，比如流水线物品的分拣。 OpenMV不适合做什么？ ---复杂的算法：比如OCR识别，车牌识别，猫狗分类，深度学习之类的。 那么单片机到底能否做AI？小梦给出了一个供大家参考的分析和案例， 我认为是完全可以做AI的，并且有其应用场景和市场前景 2 AI算力的差距
单片机主打的微控制器领域，但是目前AIOT的市场越来越火 ARM公司也不得不推出适用于单片机架构cortex-M系列的神经网络运行加速库CMSIS-NN 使得cortex-M4，cortex-M7系列的单片机有运行AI算法的内核能力 意法半导体也推出了很多基于stm32微控制器的嵌入式AI应用方案（具体可查看https://stm32ai.st.com/zh/） 但要想在图像识别领域使用低端单片机运行AI算法，算力方面差距还是不小 我们以勘智K210和stm32H7为例，计算其AI算力。 2.1 DMIPS和MIPS
1、DMIPS （Dhrystone，Million Instructions executed Per Second）： 是测量处理器运算能力的最常见基准程序之一，常用于处理器的整型运算性能的测量。 Dhrystone是一种整数运算测试程序。 2、MIPS：Million Instructions executed Per Second，每秒执行百万条指令， 用来计算同一秒内系统的处理能力，即每秒执行了多少百万条指令。 2.2 TOPS和FLOPS
1.FLOPS是指每秒钟浮点数运算的次数，它通常用于衡量计算机的通用浮点数计算性能 例如，如果一个处理器能够执行10亿次浮点数运算，则它的浮点运算速度为1 GFLOPS 2.算力 TOPS则是指每秒钟执行的整数和/或定点数运算次数，它主要用于衡量处理器的特定功能的性能， 如人工智能领域的卷积计算等。通常，深度学习处理器的算力 TOPS 比普通处理器的 FLOPS 高得多。 2.3 stm32H7 和K210 AI算力
stm32H7 480M主频，具备双精度FPU浮点运算单元 K210 600M主频，具备专用KPU神经网络运算单元 **整形运算能力对比：** H7整型计算能力856 DMIPS，每秒大概可以处理32位整型运算 856DMIPS=856MIPS，大概是 几百MOPS； 换算0.856G OPS=0.000856TOPS 和AI芯片K210（1TOPS）差了好几个量级 **AI计算能力对比：** 由于AI模型的计算量都是以浮点运算量计算，例如某AI网络模型总计算量为0.012BFLOPs， 使用stm32H7在CMSIS-NN加速条件下一秒可以推理12次（测试值），总计算量大约0.14GFLOP=0.00014TFOPS； K210的AI算力大概0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/0ef42113c827e674a9b628f3f8aef113/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-03T20:29:36+08:00" />
<meta property="article:modified_time" content="2023-08-03T20:29:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">梦飞openmv--stm32单片机跑AI</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>1 背景</strong></p> 
<pre><code>前面两篇文章《openmv底层算法剖析---梦飞openmv前传》
以及《梦飞openmv py-AI机器视觉_自主开发openmv底层固件和硬件》
充分展示了梦飞openmv的开发历程，也充分证实了单片机做图像识别算法的可行性。
引用openmv官方的话术：
OpenMV适合做什么？
---DIY相关的项目制作，比如追踪小球的车，云台，或者解魔方的机器人。
---对成本要求很高的嵌入式工业方案，比如流水线物品的分拣。
OpenMV不适合做什么？
---复杂的算法：比如OCR识别，车牌识别，猫狗分类，深度学习之类的。
那么单片机到底能否做AI？小梦给出了一个供大家参考的分析和案例，
我认为是完全可以做AI的，并且有其应用场景和市场前景
</code></pre> 
<p><strong>2 AI算力的差距</strong></p> 
<pre><code>单片机主打的微控制器领域，但是目前AIOT的市场越来越火
ARM公司也不得不推出适用于单片机架构cortex-M系列的神经网络运行加速库CMSIS-NN
使得cortex-M4，cortex-M7系列的单片机有运行AI算法的内核能力
意法半导体也推出了很多基于stm32微控制器的嵌入式AI应用方案（具体可查看https://stm32ai.st.com/zh/）
但要想在图像识别领域使用低端单片机运行AI算法，算力方面差距还是不小
我们以勘智K210和stm32H7为例，计算其AI算力。
</code></pre> 
<p><strong>2.1 DMIPS和MIPS</strong></p> 
<pre><code>1、DMIPS （Dhrystone，Million Instructions executed Per Second）：
是测量处理器运算能力的最常见基准程序之一，常用于处理器的整型运算性能的测量。
Dhrystone是一种整数运算测试程序。

2、MIPS：Million Instructions executed Per Second，每秒执行百万条指令，
用来计算同一秒内系统的处理能力，即每秒执行了多少百万条指令。
</code></pre> 
<p><strong>2.2 TOPS和FLOPS</strong></p> 
<pre><code>1.FLOPS是指每秒钟浮点数运算的次数，它通常用于衡量计算机的通用浮点数计算性能
例如，如果一个处理器能够执行10亿次浮点数运算，则它的浮点运算速度为1 GFLOPS

2.算力 TOPS则是指每秒钟执行的整数和/或定点数运算次数，它主要用于衡量处理器的特定功能的性能，
如人工智能领域的卷积计算等。通常，深度学习处理器的算力 TOPS 比普通处理器的 FLOPS 高得多。
</code></pre> 
<p><strong>2.3 stm32H7 和K210 AI算力</strong></p> 
<pre><code>stm32H7 480M主频，具备双精度FPU浮点运算单元
K210  600M主频，具备专用KPU神经网络运算单元

**整形运算能力对比：**
H7整型计算能力856 DMIPS，每秒大概可以处理32位整型运算
856DMIPS=856MIPS，大概是 几百MOPS；
换算0.856G OPS=0.000856TOPS
和AI芯片K210（1TOPS）差了好几个量级

**AI计算能力对比：**
由于AI模型的计算量都是以浮点运算量计算，例如某AI网络模型总计算量为0.012BFLOPs，
使用stm32H7在CMSIS-NN加速条件下一秒可以推理12次（测试值），总计算量大约0.14GFLOP=0.00014TFOPS；
K210的AI算力大概0.8TFLOPS，差距更大；
</code></pre> 
<p><strong>2.4 结论：</strong></p> 
<pre><code>1.stm32单片机与AI芯片在AI能力上差距巨大；
2.stm32的浮点运算能力比整形运算能力差6倍以上；
3.由于stm32是纯CPU计算，并具有丰富的外设;AI芯片一般只在AI识别领域有效，
在传统算法处理上性能差距不大，在控制领域单片机具有优势；
</code></pre> 
<p><strong>3 适合openmv的AI网络模型</strong></p> 
<pre><code>TensorFlow Lite是Tensorflow库中针对像笔记本、手机、树莓派、FPGA等边缘设备而设计的机器学习库，
而TensorFlow Lite Micro则更加轻量级，专门针对microcontroller（MCU，即单片机）。
早在2018年openmv团队已经在openmv源码上开始引入tensorflow llite micro推理框架，
但是近几年在深度学习上都没有太多的更新，官方训练的模型也都是只有openmv4及4plus才可使用，
像垃圾分类，交通标志识别和人脸检测准确率和运行效果都比较一般，
主要问题还是在使用的网络模型上，官方使用的fomo网络模型只能定位物体在图像中的大致位置，
并不能准确得到目标的大小，使用mobilenet迁移学习，训练出来的网络模型就算量化之后参数量都还比较大，
不太适合单片机运行；

使用什么AI网络模型才能更好的在单片机上运行呢？在此小梦进行了许多调研
（1）ST官方推出的CUBEI-AI工具
可以让AI网络模型转换成权重矩阵（存放在FLASH）和中间计算激活权重矩阵（存放在RAM）
再通过转换得到的网络模型代码进行深度学习推理，运行效率得到大幅度提升，且更加适合内存很小的单片机；
前期 小梦也在梦飞openmv上使用了cubeAI转换网络Mnist网络模型和部署在openmv上，其中F407和H7皆得到了使用；	

（2）国内sipeed矽速科技公司推出了一套专用于微控制器的AI运行框架TinyMaix
它是一种微型的神经网络推理框架，拥有简洁的API和易于移植的特性
可以移植到任何MCU上，甚至官方给出了能在arduino上运行
（64KB FLASH 2KB RAM）的Mnist手写数字例程，且准确率都在80%以上；
	
（3）在目标检测领域拥有检测效果和性能著称的yolo-fastets相比于经典的YOLO-tiny系列
不仅内存压缩了好几倍，反而精度不降甚至还有所提升，可惜模型还是偏大，量化前大约1.4M
尽管可能可以在片外SRAM和DRAM勉强跑，但对于一般性能没这么强劲、内存资源没这么富裕的通用MCU上还是非常吃力的。
yolo-fastest经过裁剪去除多尺度特征金字塔，只保留单输出的模型，
单目标检测参数量只有几百KB，且模型检测准确率高达85%，网络模型层数只有20+。
参考大佬的网络模型：https://github.com/EdgeAIWithRTT/Project4-Person_detection_RT-AK

（4）轻量化深度学习模型mobilenet_yolo，将yolo检测模型与深度可分离卷积结合
解决了深度学习模型参数量大、无法部署于嵌入式端的问题，但是其在小目标和遮挡物的场景中精度较差。
其中有yoloface50K，yoloface100K以及yoloface500K，模型参数量都能符合MCU的运行。
都几百KB了，还要什么MAP，网络模型来自大佬https://github.com/dog-qiuqiu/MobileNet-Yolo

（5）CNN的全称是"Convolutional Neural Network"(卷积神经网络)。
而神经网络是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）结构和功能的数学模型或计算模型。
神经网络由大量的人工神经元组成，按不同的连接方式构建不同的网络。
CNN是其中的一种，还有GAN(生成对抗网络)，RNN（递归神经网络）等，
神经网络能够类似人一样具有简单的决定能力和简单的判断能力，在图像和语音识别方面能够给出更好的结果。	
CNN是一种人工神经网络，CNN的结构可以分为3层： 
卷积层(Convolutional Layer) - 主要作用是提取特征。
池化层(Max Pooling Layer) - 主要作用是下采样(downsampling)，却不会损坏识别结果。

全连接层(Fully Connected Layer) - 主要作用是分类。
ResNet 网络是在 2015年 由微软实验室中的何凯明等几位大神提出
斩获当年ImageNet竞赛中分类任务第一名，目标检测第一名。获得COCO数据集中目标检测第一名，图像分割第一名。

利用tensorflow手动实现的CNN网络模型，具有很大网络可控性
比如简单的手势识别使用BP神经网路进行训练，准确率大概只有82.5%，
使用目前效果最好的ResNet，能达到了96.7%。
合理的控制网络层数能有效的控制模型参量，使其能在MCU上部署和使用；

以上介绍的四种网络模型及部署方法，小梦均在openmv上进行了部署和使用，运行效果非常显著。
</code></pre> 
<p><strong>4.梦飞openmv运行量化的神经网络</strong></p> 
<pre><code>（1）Mnist深度学习手写数字0-9识别
网络模型：Resnet
模型输入：28x28x1
准确率：93%
量化指标：int8量化，模型30KB
推理速度：125ms（stm32F407），50ms（stm32H7）
应用：数字卡片识别，水表读取
对比：相比于openmv提供的Mnist模型效果更好

（2）数字&amp;字母0-Z识别
网络模型：Resnet
模型输入：28x28x1
准确率：92%
量化指标：int8量化，模型20KB
推理速度：50ms（stm32F407），25ms（stm32H7）
应用：OCR字符识别，车牌识别
对比：相比于其他openmv采用模板匹配准确率大大提升

（3）mobile-yolo轻量化人脸检测模型
网络模型：yoloface50K
模型输入：56x56x3
准确率：72%
量化指标：int8量化，模型43KB
推理速度：128ms（stm32F407），60ms（stm32H7）
应用：人脸识别，人脸追踪，计数
对比：相比于haarcascade这种传统机器学习，适应更多的人脸识别场景
正脸，侧脸，昏暗环境都能识别到人脸，比openmv官方的fomo训练模型效果也更好一点

（4）yolofastest轻量化行人检测模型
网络模型：yolofastest-rule
模型输入：160x160x1
准确率：85%
量化指标：int8量化，模型122KB
推理速度：F407内存不够运行不了，80ms（stm32H7）
应用：行人计数，行人检测
对比：相比于mobilenet训练的只能检测有无行人的模型，能准确知道行人位置

（5）cifar10目标分类
网络模型：CNN
模型输入：32x32x3
准确率：85%
量化指标：int8量化，模型81KB
推理速度：125ms（stm32F407），50ms（stm32H7）
应用：图片分类
对比：mobilenet目标分类，模型参数量小很多，使用resnet准确率也会更高
</code></pre> 
<p><strong>5 总结</strong></p> 
<pre><code>以上深度学习模型均在梦飞openmv上集成和验证使用，其中F407款使用stm32F407VGT6主控，H7款使用stm32H743/H750
经过优化openmv代码和优化tensorflow lite micro的OP算子才能运行
官方版openmv有些op算子不支持，以及对于yolo模型的前处理和后处理不支持，因此不能使用yolo目标检测模型。
基于上阐述，梦飞openmv可能打破很多人对于单片机，对于openmv的认识
官方说的那些openmv不适合做的OCR，猫狗分类，深度学习等
其实在某些应用场景下是完全可以做的，相信通过不断的优化和学习
未来MCU应用AI深度学习将会越来越成熟；
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/48fa49c085efead49afe362c7fc962a4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;11中的内存模型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/557b56af325844eb71065355107b4f21/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">openmv底层算法剖析---梦飞openmv前传</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>