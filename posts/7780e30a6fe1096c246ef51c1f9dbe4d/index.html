<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PyTorch实现苹果M1芯片GPU加速：训练速度提升7倍，性能最高提升21倍 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PyTorch实现苹果M1芯片GPU加速：训练速度提升7倍，性能最高提升21倍" />
<meta property="og:description" content="5月18日，PyTorch官网宣布，通过与Apple的Metal工程团队合作，目前已可以支持在搭载M1芯片的Mac上使用GPU加速PyTorch训练。而在此之前，在Mac上进行PyTorch训练仅能利用CPU。
但随着PyTorch v1.12版本的发布，开发和研究人员可以利用Apple Silicon CPU的优势，大大加快模型训练速度。这解锁了在Mac上执行机器学习工作流程的能力，例如在本地进行原型设计和微调。
据PyTorch官网介绍，其使用Apple的Metal Performance Shaders（MPS）作为PyTorch的后端来加速GPU训练。MPS后端扩展了PyTorch框架，提供了在Mac上设置和运行操作的脚本和功能。MPS通过针对每个Metal GPU系列的独特特性进行微调的内核来优化计算性能。新设备将机器学习计算图和原语映射到MPS提供的MPS Graph框架和优化内核上。
此外，因为每台搭载Apple Silicon的Mac都有统一的内存架构，为GPU提供了直接访问完整内存存储的能力。这让Mac成为机器学习的绝佳平台，也使用户能够在本地训练更大的网络或批大小。同时，这也降低了与基于云的开发相关的成本或对额外本地GPU的需求。此外，统一内存架构还减少了数据检索延迟，提高了端到端的性能。
在下图中，显示了与CPU基线相比，加速GPU训练和评估所带来的性能提升：
图源： PyTorch官网
可以看出，使用GPU可将模型训练速度提升约7倍，评估（Evaluation）速度最高可提升约21倍。
以上是Apple于2022年4月使用配备Apple M1 Ultra、20核CPU、64核GPU、128GB内存和2TB SSD的Mac Studio系统进行的测试结果。系统为macOS Monterey 12.3、预发布的PyTorch 1.12，测试模型为ResNet50（batch size=128）、HuggingFace BERT（batch size=64）和VGG16（batch size=64）。性能测试是使用特定的计算机系统进行的，反映了Mac Studio的大致性能。
对于想要体验的用户，以下为具体要求：只需在搭载M1芯片的Mac上安装原生版本（arm64）的Python，并将系统升级至macOS 12.3或更高版本，然后去官网下载最新的PyTorch预览版就可以。
参考链接：
1.Introducing Accelerated PyTorch Training on Mac | PyTorch
2.Start Locally | PyTorch" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/7780e30a6fe1096c246ef51c1f9dbe4d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-20T18:16:17+08:00" />
<meta property="article:modified_time" content="2022-05-20T18:16:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PyTorch实现苹果M1芯片GPU加速：训练速度提升7倍，性能最高提升21倍</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>5月18日，PyTorch官网宣布，通过与Apple的Metal工程团队合作，目前已可以支持在搭载M1芯片的Mac上使用GPU加速PyTorch训练。而在此之前，在Mac上进行PyTorch训练仅能利用CPU。</p> 
<p>但随着PyTorch v1.12版本的发布，开发和研究人员可以利用Apple Silicon CPU的优势，大大加快模型训练速度。这解锁了在Mac上执行机器学习工作流程的能力，例如在本地进行原型设计和微调。</p> 
<p class="img-center"><img alt="" height="400" src="https://images2.imgbox.com/0e/06/h9aHkmWG_o.png" width="600"></p> 
<p>据PyTorch官网介绍，其使用Apple的Metal Performance Shaders（MPS）作为PyTorch的后端来加速GPU训练。MPS后端扩展了PyTorch框架，提供了在Mac上设置和运行操作的脚本和功能。MPS通过针对每个Metal GPU系列的独特特性进行微调的内核来优化计算性能。新设备将机器学习计算图和原语映射到MPS提供的MPS Graph框架和优化内核上。</p> 
<p>此外，因为每台搭载Apple Silicon的Mac都有统一的内存架构，为GPU提供了直接访问完整内存存储的能力。这让Mac成为机器学习的绝佳平台，也使用户能够在本地训练更大的网络或批大小。同时，这也降低了与基于云的开发相关的成本或对额外本地GPU的需求。此外，统一内存架构还减少了数据检索延迟，提高了端到端的性能。</p> 
<p>在下图中，显示了与CPU基线相比，加速GPU训练和评估所带来的性能提升：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/0c/70/xklUjrlO_o.gif">图源： PyTorch官网</p> 
<p>可以看出，使用GPU可将模型训练速度提升约7倍，评估（Evaluation）速度最高可提升约21倍。</p> 
<blockquote> 
 <p>以上是Apple于2022年4月使用配备Apple M1 Ultra、20核CPU、64核GPU、128GB内存和2TB SSD的Mac Studio系统进行的测试结果。系统为macOS Monterey 12.3、预发布的PyTorch 1.12，测试模型为ResNet50（batch size=128）、HuggingFace BERT（batch size=64）和VGG16（batch size=64）。性能测试是使用特定的计算机系统进行的，反映了Mac Studio的大致性能。</p> 
</blockquote> 
<p>对于想要体验的用户，以下为具体要求：只需在搭载M1芯片的Mac上安装原生版本（arm64）的Python，并将系统升级至macOS 12.3或更高版本，然后去<a href="https://pytorch.org/get-started/locally" rel="nofollow" title="官网">官网</a>下载最新的PyTorch预览版就可以。</p> 
<p>参考链接：</p> 
<p>1.<a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/" rel="nofollow" title="Introducing Accelerated PyTorch Training on Mac | PyTorch">Introducing Accelerated PyTorch Training on Mac | PyTorch</a></p> 
<p>2.<a href="https://pytorch.org/get-started/locally/" rel="nofollow" title="Start Locally | PyTorch">Start Locally | PyTorch</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2ed598053b6bb789f88364a85aa5060a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Eggjs解决跨域问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9db70cde7d4a67c32880ccc0605aa241/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">利用命令简单检查网络</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>