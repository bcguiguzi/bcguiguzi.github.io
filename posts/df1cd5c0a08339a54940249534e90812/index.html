<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>datax 搭建使用 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="datax 搭建使用" />
<meta property="og:description" content="文章目录 datax 环境搭建使用一、解压文件二、配置 json 文件三、执行命令 datax 环境搭建使用 用于全量同步
一、解压文件 将包上传至服务器
输入命令： tar -zxvf datax.tar.gz -C /opt/module/ 将包 解压到 /opt/module 目录
解压完之后，不需要任何的配置，直接就可以用
我们可以测试一下，
输入命令：/opt/module/datax/bin/datax.py /opt/module/datax/job/job.json 显示这些结果就表示成功了，这里面的 datax.py 文件是已经直接有的了，我们不用管，然后我们写数据只需要 编写 json 文件就可以了。
二、配置 json 文件 配置文件，可以直接进入这个网站：https://github.com/alibaba/DataX
然后打开之后，往下面翻
有各种读写的配置
我们就是直接从 mysql 里面读，然后写到 hdfs 上面去，我们直接点 mysql 的读，然后可以查看 mysql 的文档
这里有一个，可以编辑 json 格式化的网站：https://baidufe.com/fehelper/json-format/index.html
这上面的json job有两部分，一个是mysql读的配置 mysqlreader 和 hdfswriter 这两个名字是不能随意更改的
这是 用 表的方式导入
{ &#34;job&#34;: { &#34;content&#34;: [ { &#34;reader&#34;: { &#34;name&#34;: &#34;mysqlreader&#34;, &#34;parameter&#34;: { &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/df1cd5c0a08339a54940249534e90812/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-13T16:22:50+08:00" />
<meta property="article:modified_time" content="2023-11-13T16:22:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">datax 搭建使用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#datax__1" rel="nofollow">datax 环境搭建使用</a></li><li><ul><li><a href="#_3" rel="nofollow">一、解压文件</a></li><li><a href="#_json__11" rel="nofollow">二、配置 json 文件</a></li><li><a href="#_182" rel="nofollow">三、执行命令</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="datax__1"></a>datax 环境搭建使用</h2> 
<p>用于全量同步</p> 
<h3><a id="_3"></a>一、解压文件</h3> 
<p>将包上传至服务器<br> <img src="https://images2.imgbox.com/82/49/STeRb08S_o.png" alt="在这里插入图片描述"><br> 输入命令：<code> tar -zxvf datax.tar.gz -C /opt/module/</code> 将包 解压到 <code>/opt/module</code> 目录<br> 解压完之后，不需要任何的配置，直接就可以用<br> 我们可以测试一下，<br> 输入命令：<code>/opt/module/datax/bin/datax.py /opt/module/datax/job/job.json </code> 显示这些结果就表示成功了，这里面的 datax.py 文件是已经直接有的了，我们不用管，然后我们写数据只需要 编写 json 文件就可以了。<br> <img src="https://images2.imgbox.com/57/88/4j82FhyD_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_json__11"></a>二、配置 json 文件</h3> 
<p>配置文件，可以直接进入这个网站：<a href="https://github.com/alibaba/DataX">https://github.com/alibaba/DataX</a><br> 然后打开之后，往下面翻<br> <img src="https://images2.imgbox.com/39/6a/GbWearcw_o.png" alt="在这里插入图片描述"><br> 有各种读写的配置<br> <img src="https://images2.imgbox.com/a4/38/F5I4BZMZ_o.png" alt="在这里插入图片描述"><br> 我们就是直接从 mysql 里面读，然后写到 hdfs 上面去，我们直接点 mysql 的读，然后可以查看 mysql 的文档<br> <img src="https://images2.imgbox.com/56/e1/mapyUB3F_o.png" alt="在这里插入图片描述"><br> 这里有一个，可以编辑 json 格式化的网站：<a href="https://baidufe.com/fehelper/json-format/index.html" rel="nofollow">https://baidufe.com/fehelper/json-format/index.html</a><br> <img src="https://images2.imgbox.com/61/15/cGDq4SDW_o.png" alt="在这里插入图片描述"><br> 这上面的json job有两部分，一个是mysql读的配置 mysqlreader 和 hdfswriter 这两个名字是不能随意更改的<br> 这是 用 表的方式导入</p> 
<pre><code class="prism language-powershell"><span class="token punctuation">{<!-- --></span>
<span class="token string">"job"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"content"</span>: <span class="token punctuation">[</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"reader"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"mysqlreader"</span><span class="token punctuation">,</span>
<span class="token string">"parameter"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"column"</span>: <span class="token punctuation">[</span>
<span class="token string">"id"</span><span class="token punctuation">,</span>
<span class="token string">"name"</span><span class="token punctuation">,</span>
<span class="token string">"region_id"</span><span class="token punctuation">,</span>
<span class="token string">"area_code"</span><span class="token punctuation">,</span>
<span class="token string">"iso_code"</span><span class="token punctuation">,</span>
<span class="token string">"iso_3166_2"</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"connection"</span>: <span class="token punctuation">[</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"jdbcUrl"</span>: <span class="token punctuation">[</span>
<span class="token string">"jdbc:mysql://hadoop105:3306/edu"</span>
 <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"table"</span>: <span class="token punctuation">[</span>
<span class="token string">"base_province"</span>
<span class="token punctuation">]</span>
<span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"password"</span>: <span class="token string">"p@ssw0rd"</span><span class="token punctuation">,</span>
<span class="token string">"splitPk"</span>: <span class="token string">""</span><span class="token punctuation">,</span>
<span class="token string">"username"</span>: <span class="token string">"root"</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token string">"writer"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"hdfswriter"</span><span class="token punctuation">,</span>
<span class="token string">"parameter"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"column"</span>: <span class="token punctuation">[</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"id"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"bigint"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"name"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"region_id"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"area_code"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"iso_code"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"iso_3166_2"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"compress"</span>: <span class="token string">"gzip"</span><span class="token punctuation">,</span>
<span class="token string">"defaultFS"</span>: <span class="token string">"hdfs://hadoop105:9000"</span><span class="token punctuation">,</span>
<span class="token string">"fieldDelimiter"</span>: <span class="token string">"\t"</span><span class="token punctuation">,</span>
<span class="token string">"fileName"</span>: <span class="token string">"base_province"</span><span class="token punctuation">,</span>
<span class="token string">"fileType"</span>: <span class="token string">"text"</span><span class="token punctuation">,</span>
<span class="token string">"path"</span>: <span class="token string">"/user/hive/warehouse"</span><span class="token punctuation">,</span>
<span class="token string">"writeMode"</span>: <span class="token string">"append"</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"setting"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"speed"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"channel"</span>: 1
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>这个是querySql方式，用sql的方式导入，建议使用这种，比如有时候需要复杂查询，然后筛选出来的数据再导入进去，然后 文件里面的 hdfs 路径，还有 mysql 连接的配置那些需要配置好。</p> 
<pre><code class="prism language-powershell"><span class="token punctuation">{<!-- --></span>
<span class="token string">"job"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"content"</span>: <span class="token punctuation">[</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"reader"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"mysqlreader"</span><span class="token punctuation">,</span>
<span class="token string">"parameter"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"column"</span>: <span class="token punctuation">[</span>
<span class="token string">"id"</span><span class="token punctuation">,</span>
<span class="token string">"name"</span><span class="token punctuation">,</span>
<span class="token string">"region_id"</span><span class="token punctuation">,</span>
<span class="token string">"area_code"</span><span class="token punctuation">,</span>
<span class="token string">"iso_code"</span><span class="token punctuation">,</span>
<span class="token string">"iso_3166_2"</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"connection"</span>: <span class="token punctuation">[</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"jdbcUrl"</span>: <span class="token punctuation">[</span>
<span class="token string">"jdbc:mysql://hadoop105:3306/edu"</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"querySql"</span>: <span class="token punctuation">[</span>
<span class="token string">"select id,name,region_id,area_code,iso_code,iso_3166_2 from base_province where id&gt;=3"</span>
<span class="token punctuation">]</span>
<span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"password"</span>: <span class="token string">"p@ssw0rd"</span><span class="token punctuation">,</span>
<span class="token string">"splitPk"</span>: <span class="token string">"id"</span><span class="token punctuation">,</span>
<span class="token string">"username"</span>: <span class="token string">"root"</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token string">"writer"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"hdfswriter"</span><span class="token punctuation">,</span>
<span class="token string">"parameter"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"column"</span>: <span class="token punctuation">[</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"id"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"bigint"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"name"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"region_id"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"area_code"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"iso_code"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"name"</span>: <span class="token string">"iso_3166_2"</span><span class="token punctuation">,</span>
<span class="token string">"type"</span>: <span class="token string">"string"</span>
<span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"compress"</span>: <span class="token string">"gzip"</span><span class="token punctuation">,</span>
<span class="token string">"defaultFS"</span>: <span class="token string">"hdfs://hadoop105:9000"</span><span class="token punctuation">,</span>
<span class="token string">"fieldDelimiter"</span>: <span class="token string">"\t"</span><span class="token punctuation">,</span>
<span class="token string">"fileName"</span>: <span class="token string">"base_province"</span><span class="token punctuation">,</span>
<span class="token string">"fileType"</span>: <span class="token string">"text"</span><span class="token punctuation">,</span>
<span class="token string">"path"</span>: <span class="token string">"${targetdir}"</span><span class="token punctuation">,</span>
<span class="token string">"writeMode"</span>: <span class="token string">"append"</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token string">"setting"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"speed"</span>: <span class="token punctuation">{<!-- --></span>
<span class="token string">"channel"</span>: 3
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="_182"></a>三、执行命令</h3> 
<p>我们将 json 文件写好之后，我们可以执行了<br> 输入命令：<code>/opt/module/datax/bin/datax.py /opt/module/datax/job/base_province.json </code><br> 运行成功<br> <img src="https://images2.imgbox.com/bc/08/eBC8agpR_o.png" alt="在这里插入图片描述"><br> 然后我们在 去查看一下hdfs 查看一下文件<br> <img src="https://images2.imgbox.com/8c/9b/ghtsaGHO_o.png" alt="在这里插入图片描述"><br> 然后我们来读取一下，查看里面的数据<br> 输入命令：<code>hdfs dfs -cat /user/hive/warehouse/base_province__e27b955a_15bc_4192_b187_d60ece18be86.gz | zcat</code><br> <img src="https://images2.imgbox.com/93/3f/FzgoD0Hu_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e728b7c74d21a1ece0a0b97dbe6ed625/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【EI会议征稿】第四届环境资源与能源工程国际学术会议（ICEREE 2024）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5e061dc0d2d70844e06a3415452fe1db/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数据结构—LinkedList与链表</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>