<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark-hadoop集群中8020：Connection refused - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark-hadoop集群中8020：Connection refused" />
<meta property="og:description" content="一、使用CentOs7虚拟机运行spark案例报出8020端口出现错误 前提条件，使用standalone模式下的Spark，使用spark-shell运行example中的相关测试案例spark-examples_2.12-3.0.0.jar，来计算pi。当spark-shell 停止掉后，集群监控base:4040 页面就看不到历史任务的运行情况，所以需要配置历史服务器记录任务运行情况。
因此，在此基础上需要配置spark的历史服务器来记录任务运行情况，参考网上教程，进行了以下步骤进行配置。
# 1) 修改 spark-defaults.conf.template 文件名为 spark-defaults.conf mv spark-defaults.conf.template spark-defaults.conf # 2) 修改 spark-default.conf 文件，配置日志存储路径 spark.eventLog.enabled true spark.eventLog.dir hdfs://主机名:8020/directory # 注意：需要启动 hadoop 集群，HDFS 上的 directory 目录需要提前存在。 sbin/start-dfs.sh hadoop fs -mkdir /directory # 3) 修改 spark-env.sh 文件, 添加日志配置 export SPARK_HISTORY_OPTS=&#34; -Dspark.history.ui.port=18080 -Dspark.history.fs.logDirectory=hdfs://主机名:8020/directory -Dspark.history.retainedApplications=30&#34; # 4) 重新启动集群和历史服务 sbin/start-all.sh sbin/start-history-server.sh # 5) 重新执行任务 bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://linux1:7077 ./examples/jars/spark-examples_2.12-3.0.0.jar 10 ❗ 在执行第五步的时候出现了报错，部分报错内容如下：
23/07/28 15:19:58 INFO SparkContext: Successfully stopped SparkContext Exception in thread &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/a3764127ea317ef619a06944eac42d28/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-29T00:30:00+08:00" />
<meta property="article:modified_time" content="2023-07-29T00:30:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark-hadoop集群中8020：Connection refused</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h5><a id="CentOs7spark8020_0"></a>一、使用CentOs7虚拟机运行spark案例报出8020端口出现错误</h5> 
<p>    前提条件，使用standalone模式下的Spark，使用spark-shell运行example中的相关测试案例spark-examples_2.12-3.0.0.jar，来<mark>计算pi</mark>。当spark-shell <u>停止掉后</u>，集群监控base:4040 页面就<mark>看不到历史任务的运行情况</mark>，所以需要配置历史服务器记录任务运行情况。<br>     因此，在此基础上需要配置spark的历史服务器来<mark>记录任务运行情况</mark>，参考网上教程，进行了以下步骤进行配置。</p> 
<pre><code class="prism language-shell"><span class="token comment"># 1) 修改 spark-defaults.conf.template 文件名为 spark-defaults.conf</span>
<span class="token function">mv</span> spark-defaults.conf.template spark-defaults.conf

<span class="token comment"># 2) 修改 spark-default.conf 文件，配置日志存储路径</span>
spark.eventLog.enabled <span class="token boolean">true</span>
spark.eventLog.dir hdfs://主机名:8020/directory
<span class="token comment"># 注意：需要启动 hadoop 集群，HDFS 上的 directory 目录需要提前存在。</span>
sbin/start-dfs.sh
hadoop fs <span class="token parameter variable">-mkdir</span> /directory

<span class="token comment"># 3) 修改 spark-env.sh 文件, 添加日志配置</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_HISTORY_OPTS</span><span class="token operator">=</span><span class="token string">"
-Dspark.history.ui.port=18080
-Dspark.history.fs.logDirectory=hdfs://主机名:8020/directory 
-Dspark.history.retainedApplications=30"</span>

<span class="token comment"># 4) 重新启动集群和历史服务</span>
sbin/start-all.sh
sbin/start-history-server.sh

<span class="token comment"># 5) 重新执行任务</span>
bin/spark-submit <span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token parameter variable">--master</span> spark://linux1:7077 ./examples/jars/spark-examples_2.12-3.0.0.jar <span class="token number">10</span>

</code></pre> 
<p>     ❗ 在执行第五步的时候<strong>出现了报错</strong>，部分报错内容如下：</p> 
<pre><code class="prism language-shell"><span class="token number">23</span>/07/28 <span class="token number">15</span>:19:58 INFO SparkContext: Successfully stopped SparkContext
Exception <span class="token keyword">in</span> thread <span class="token string">"main"</span> java.net.ConnectException: Call From base/192.168.10.201 to base:8020 failed on connection exception: java.net.ConnectException: Connection refused<span class="token punctuation">;</span> For <span class="token function">more</span> details see:  http://wiki.apache.org/hadoop/ConnectionRefused
</code></pre> 
<h5><a id="_36"></a>二、解决思路</h5> 
<p>    根据报错内容，以及网络搜索查找原因：</p> 
<ol><li>可能是ip出现异常，导致无法连接。</li><li>端口号没有开放导致拒接连接。</li><li>防火墙未关闭，导致无法连接。</li></ol> 
<h5><a id="_43"></a>三、解决过程</h5> 
<p>    首先根据网络上常用的排查方式，使用telnet指令访问ip或相应端口，查看连接是否正常。<br>     尝试22号端口是否可以连接。</p> 
<p>    发现使用的<mark>ip是可以正常访问的</mark>，但是8020端口拒绝连接。<br> <img src="https://images2.imgbox.com/fd/40/lJM0NAvQ_o.png" alt="在这里插入图片描述"></p> 
<p>    通过netstat查看8020端口，发现该端口不存在，是属于hadoop集群中一个内部通讯的端口。尝试开放该端口，发现开放端口后依旧会导致报错。因此，考虑是<mark>Spark配置文件存在错误</mark>的问题。</p> 
<p>    经过查看端口8020的使用情况发现，8020端口一般作为hadoop2.x系列的内部通讯端口使用。常用端口的使用如下：</p> 
<table><thead><tr><th align="center">端口名称</th><th align="center">hadoop2.x</th><th align="center">hadoop3.x</th></tr></thead><tbody><tr><td align="center">Namenode内部通常端口</td><td align="center">8020/9000</td><td align="center">8020/9000/9820</td></tr><tr><td align="center">Namenode对用户的査询端口</td><td align="center">50070</td><td align="center">9870</td></tr><tr><td align="center">MapReduce 查看执行任务端口</td><td align="center">8088</td><td align="center">8088</td></tr><tr><td align="center">历史服务器通信端口</td><td align="center">19888</td><td align="center">19888</td></tr></tbody></table> 
<p>    通过查看namenode端口的使用发现，hadoop3.x默认使用9820端口，因此，发现问题所在是在<mark>配置spark文件时端口出现错误</mark>。<br> <img src="https://images2.imgbox.com/14/08/FHPfar7Y_o.png" alt="在这里插入图片描述"></p> 
<p>    ❗ 需要将原本spark-default.conf和spark-env.sh的8020端口改为9820端口，之后再<mark>重新启动</mark>spark相关服务即可。</p> 
<p>    相关历史进程可以从http:// ip地址:18080/查看。</p> 
<p><img src="https://images2.imgbox.com/0f/60/zHpYIsfm_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_70"></a>四、小结</h5> 
<p>    在使用Spark和Hadoop时，端口问题可能会出现，以下是一些常见的端口问题小结：</p> 
<ol><li>Hadoop端口问题： 
  <ul><li>NameNode端口：Hadoop的NameNode组件默认使用端口9820。如果无法访问NameNode，请确保9820端口没有被防火墙或其他应用程序占用。</li></ul> </li><li>Spark端口问题： 
  <ul><li>Spark Master端口：Spark的Master节点默认使用端口7077来接收来自Worker节点的连接。如果Worker节点无法连接到Master节点，请检查7077端口是否可用。</li></ul> </li><li>防火墙设置： 
  <ul><li>确保你的防火墙允许Spark和Hadoop相关的端口通过。你可以配置防火墙规则来放行这些端口，或者完全禁用防火墙。但是，请注意这可能会降低系统的安全性，所以应该谨慎操作。</li></ul> </li><li>其他问题： 
  <ul><li>端口冲突：在同一台机器上运行多个Spark或Hadoop集群时，可能会发生端口冲突的情况。确保每个集群使用不同的端口范围来避免冲突。</li><li>网络配置：如果Spark或Hadoop跨多台机器进行通信，确保网络配置正确，允许节点之间的端口通信。</li></ul> </li></ol> 
<p>解决端口问题的方法通常是检查端口是否被占用，配置防火墙规则，以及确保网络和集群配置正确。根据具体情况，可能需要查看日志文件获取更多帮助。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d6971c4836657cad72aa54da5e2d33aa/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">95. Python基础教程:异常处理try...except语句</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bfdc8d76b4fd77fa9864a8beebd7c395/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Dell最新BIOS配置界面</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>