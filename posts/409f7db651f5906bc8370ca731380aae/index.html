<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python实用技能】爬虫升级之路：从专用爬虫到用AI Agent实现通用网络爬虫（适合小白） - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python实用技能】爬虫升级之路：从专用爬虫到用AI Agent实现通用网络爬虫（适合小白）" />
<meta property="og:description" content="大家好，我是同学小张，日常分享AI知识和实战案例欢迎 点赞 &#43; 关注 👏，持续学习，持续干货输出。&#43;v: jasper_8017 一起交流💬，一起进步💪。微信公众号也可搜【同学小张】 🙏 本站文章一览：
目前为止，我们已经写了几个爬虫程序，能将网页中的内容提取出来，或者保存成PDF。本文来总结一下这些方法，循序渐进地带大家看下爬虫的实现方法：从单个网页爬虫，到利用大模型提取指定信息，到利用AI Agent实现自动编写爬虫代码实现通用爬虫。
说明：本人爬虫小白，所以 这篇文章总结的是简单的爬虫程序，可以直接使用的程序 。没有复杂的操作，也没有深入的理解。适合爬虫小白或只是将爬虫作为一个数据来源的非专业人员。想要深入理解爬虫原理的同学，可以退出了。
文章目录 0. 单网页的专用爬虫实现方法0.1 基本的爬虫程序实现方法0.2 利用 selenium 实现爬虫0.3 利用 LangChain 爬取网页内容0.3.1 Loading &#43; Transforming0.3.2 WebBaseLoader 1. 利用大模型直接提取指定信息的探索2. 利用AI Agent实现通用爬虫2.1 实现思路2.2 自动化爬虫代码生成器2.3 可能遇到的问题 3. 总结 0. 单网页的专用爬虫实现方法 这种爬虫是针对特定网页的数据爬取，可以是一个网页，或者是一系列结构相似的网页。
这种爬虫的实现方法，最主要的是，需要打开网页，F12调试，然后找自己需要的文本内容在HTML中的Tag或Class。
0.1 基本的爬虫程序实现方法 如果你会一点爬虫基础，那看到网页结构，应该就知道怎么利用 BeautifulSoup 写一个简单的爬虫程序了。但是如果你一点爬虫基础也没有，不知该如何下手呢？可以利用ChatGPT、文心一言、智谱清言等工具帮你。保姆级操作教程可看下面的文章：
【提效】让GPT帮你写爬虫程序，不懂爬虫也能行 文章中包含了如何找到你需要的文本内容在HTML结构中的Tag、class，如何给大模型Prompt和交互等：
【AI大模型应用开发】【LangChain系列】实战案例2：通过URL加载网页内容 - LangChain对爬虫功能的封装
前面的文章，我们利用LangChain实现了URL网页数据的提取。但是今天想用它抓取微信公众号文章的数据时，失败了。
之前利用 LangChain 实现URL网页数据提取的文章可见：
【AI大模型应用开发】【LangChain系列】实战案例4：再战RAG问答，提取在线网页数据，并返回生成答案的来源 0.2 利用 selenium 实现爬虫 我们在 【Python实用技能】建议收藏：自动化实现网页内容转PDF并保存的方法探索（含代码，亲测可用） 这篇文章中通过 selenium 实现了自动将网页保存为PDF的功能。其实利用 selenium 也可以直接从网页中提取想要的内容。
下面的示例代码中，通过selenium模拟打开网页，通过 xpath 爬取指定元素。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/409f7db651f5906bc8370ca731380aae/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-18T07:00:00+08:00" />
<meta property="article:modified_time" content="2024-03-18T07:00:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python实用技能】爬虫升级之路：从专用爬虫到用AI Agent实现通用网络爬虫（适合小白）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <ul><li>大家好，我是同学小张，日常分享AI知识和实战案例</li><li>欢迎 <strong>点赞 + 关注</strong> 👏，<strong>持续学习</strong>，<strong>持续干货输出</strong>。</li><li>+v: <strong>jasper_8017</strong> 一起交流💬，一起进步💪。</li><li>微信公众号也可搜【同学小张】 🙏</li></ul> 
</blockquote> 
<p><strong><mark>本站文章一览：</mark></strong></p> 
<p><img src="https://images2.imgbox.com/c8/d4/RiXdEplS_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<p>目前为止，我们已经写了几个爬虫程序，能将网页中的内容提取出来，或者保存成PDF。本文来总结一下这些方法，循序渐进地带大家看下爬虫的实现方法：从单个网页爬虫，到利用大模型提取指定信息，到利用AI Agent实现自动编写爬虫代码实现通用爬虫。</p> 
<p><img src="https://images2.imgbox.com/e1/b1/VRgssnOI_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><strong>说明：本人爬虫小白，所以 <font color="red">这篇文章总结的是简单的爬虫程序，可以直接使用的程序</font> 。没有复杂的操作，也没有深入的理解。适合爬虫小白或只是将爬虫作为一个数据来源的非专业人员。想要深入理解爬虫原理的同学，可以退出了。</strong></p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#0__21" rel="nofollow">0. 单网页的专用爬虫实现方法</a></li><li><ul><li><a href="#01__26" rel="nofollow">0.1 基本的爬虫程序实现方法</a></li><li><a href="#02__selenium__50" rel="nofollow">0.2 利用 selenium 实现爬虫</a></li><li><a href="#03__LangChain__100" rel="nofollow">0.3 利用 LangChain 爬取网页内容</a></li><li><ul><li><a href="#031_Loading__Transforming_103" rel="nofollow">0.3.1 Loading + Transforming</a></li><li><a href="#032_WebBaseLoader_115" rel="nofollow">0.3.2 WebBaseLoader</a></li></ul> 
  </li></ul> 
  </li><li><a href="#1__135" rel="nofollow">1. 利用大模型直接提取指定信息的探索</a></li><li><a href="#2_AI_Agent_167" rel="nofollow">2. 利用AI Agent实现通用爬虫</a></li><li><ul><li><a href="#21__169" rel="nofollow">2.1 实现思路</a></li><li><a href="#22__178" rel="nofollow">2.2 自动化爬虫代码生成器</a></li><li><a href="#23__350" rel="nofollow">2.3 可能遇到的问题</a></li></ul> 
  </li><li><a href="#3__362" rel="nofollow">3. 总结</a></li></ul> 
</div> 
<p></p> 
<h2><a id="0__21"></a>0. 单网页的专用爬虫实现方法</h2> 
<blockquote> 
 <p>这种爬虫是针对特定网页的数据爬取，可以是一个网页，或者是一系列结构相似的网页。</p> 
</blockquote> 
<p><mark><strong>这种爬虫的实现方法，最主要的是，需要打开网页，F12调试，然后找自己需要的文本内容在HTML中的Tag或Class。</strong></mark></p> 
<h3><a id="01__26"></a>0.1 基本的爬虫程序实现方法</h3> 
<p>如果你会一点爬虫基础，那看到网页结构，应该就知道怎么利用 BeautifulSoup 写一个简单的爬虫程序了。但是如果你一点爬虫基础也没有，不知该如何下手呢？可以利用ChatGPT、文心一言、智谱清言等工具帮你。保姆级操作教程可看下面的文章：</p> 
<ul><li><a href="https://blog.csdn.net/Attitude93/article/details/135720641">【提效】让GPT帮你写爬虫程序，不懂爬虫也能行</a></li></ul> 
<p>文章中包含了如何找到你需要的文本内容在HTML结构中的Tag、class，如何给大模型Prompt和交互等：</p> 
<p><img src="https://images2.imgbox.com/25/f9/V4ye45w0_o.png" alt="在这里插入图片描述"></p> 
<p><a href="https://blog.csdn.net/Attitude93/article/details/136280643">【AI大模型应用开发】【LangChain系列】实战案例2：通过URL加载网页内容 - LangChain对爬虫功能的封装</a></p> 
<p>前面的文章，我们利用LangChain实现了URL网页数据的提取。但是今天想用它抓取微信公众号文章的数据时，失败了。</p> 
<blockquote> 
 <p>之前利用 LangChain 实现URL网页数据提取的文章可见：</p> 
 <ul><li><a href="https://blog.csdn.net/Attitude93/article/details/136503386">【AI大模型应用开发】【LangChain系列】实战案例4：再战RAG问答，提取在线网页数据，并返回生成答案的来源</a></li></ul> 
</blockquote> 
<h3><a id="02__selenium__50"></a>0.2 利用 selenium 实现爬虫</h3> 
<p>我们在 <a href="https://blog.csdn.net/Attitude93/article/details/136671565">【Python实用技能】建议收藏：自动化实现网页内容转PDF并保存的方法探索（含代码，亲测可用）</a> 这篇文章中通过 selenium 实现了自动将网页保存为PDF的功能。其实利用 selenium 也可以直接从网页中提取想要的内容。</p> 
<p>下面的示例代码中，通过selenium模拟打开网页，通过 xpath 爬取指定元素。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os<span class="token punctuation">,</span>json<span class="token punctuation">,</span>time
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
 
<span class="token keyword">def</span> <span class="token function">crawel_url</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># 创建Chrome WebDriver对象</span>
    driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'now: url: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>url<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
    driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
 
    <span class="token comment"># 添加适当的等待时间或条件，确保页面已完全加载</span>
    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support<span class="token punctuation">.</span>ui <span class="token keyword">import</span> WebDriverWait
    <span class="token keyword">from</span> selenium<span class="token punctuation">.</span>webdriver<span class="token punctuation">.</span>support <span class="token keyword">import</span> expected_conditions <span class="token keyword">as</span> EC

    <span class="token comment"># 等待10秒钟，直到某个元素可见</span>
    wait <span class="token operator">=</span> WebDriverWait<span class="token punctuation">(</span>driver<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
    element <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element<span class="token punctuation">(</span><span class="token string">"xpath"</span><span class="token punctuation">,</span> <span class="token string">"/html/body/div[1]/div[2]/div[1]/div/div[1]/div[2]"</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> element<span class="token punctuation">.</span>text
    <span class="token keyword">print</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span>

    driver<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
url_list <span class="token operator">=</span><span class="token punctuation">[</span>
    <span class="token string">'https://mp.weixin.qq.com/s/2m8MrsCxf5boiH4Dzpphrg'</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

<span class="token keyword">for</span> url <span class="token keyword">in</span> url_list<span class="token punctuation">:</span>
    crawel_url<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<p>xpath的获取方法如下：</p> 
<p><img src="https://images2.imgbox.com/de/dc/LL8qCAhy_o.png" alt="在这里插入图片描述"><br> 找到你想提取的此网页的数据，在F12调试面板中，在该元素位置鼠标右键 —&gt; 复制 —&gt; 复制完整 XPath，替换掉上面程序中的xpath。</p> 
<p>运行结果（看起来效果还不错）：</p> 
<p><img src="https://images2.imgbox.com/36/8b/8u8DIVAC_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="03__LangChain__100"></a>0.3 利用 LangChain 爬取网页内容</h3> 
<p>目前为止，我们接触了两种利用 LangChain 来获取网页内容的方法。</p> 
<h4><a id="031_Loading__Transforming_103"></a>0.3.1 Loading + Transforming</h4> 
<p>第一种方法是使用 LangChain 的 Loading 模块加载HTML网页，利用 Transforming 模块将HTML结构转换为文本。</p> 
<p>其 Loading 模块可以使用 AsyncHtmlLoader 或 AsyncChromiumLoader，Transforming模块可以使用 HTML2Text 或 BeautifulSoup。</p> 
<p>具体使用方法可看这篇文章的前半部分：</p> 
<ul><li><a href="https://blog.csdn.net/Attitude93/article/details/136280643">【AI大模型应用开发】【LangChain系列】实战案例2：通过URL加载网页内容 - LangChain对爬虫功能的封装</a></li></ul> 
<p><img src="https://images2.imgbox.com/8e/ad/NxOC5qaI_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="032_WebBaseLoader_115"></a>0.3.2 WebBaseLoader</h4> 
<p>另一种使用 LangChain 获取网页内容的方法是使用其中的 WebBaseLoader 类。我们在 <a href="https://blog.csdn.net/Attitude93/article/details/136503386">【AI大模型应用开发】【LangChain系列】实战案例4：再战RAG问答，提取在线网页数据，并返回生成答案的来源</a> 使用过：</p> 
<pre><code class="prism language-python">loader <span class="token operator">=</span> WebBaseLoader<span class="token punctuation">(</span>
    web_paths<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"https://lilianweng.github.io/posts/2023-06-23-agent/"</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    bs_kwargs<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
        parse_only<span class="token operator">=</span>bs4<span class="token punctuation">.</span>SoupStrainer<span class="token punctuation">(</span>
            class_<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"post-content"</span><span class="token punctuation">,</span> <span class="token string">"post-title"</span><span class="token punctuation">,</span> <span class="token string">"post-header"</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>这其实是对第一种方法的一种高层封装，将第一种方法中的两个步骤合并在了一起。</p> 
<blockquote> 
 <p><strong>小结：单网页的专用爬虫实现方法，目前我们用过的就这几个，可以看到，无论用哪种方法，都躲不过需要我们手动去 F12 调试页面，分析HTML的结构，找到文本内容的Tag或Class。换一个网页，这些Tag或Class可能就不通用了，需要重新分析结构，查找 Tag和Class。</strong></p> 
</blockquote> 
<h2><a id="1__135"></a>1. 利用大模型直接提取指定信息的探索</h2> 
<p>上面虽然利用了大模型帮我们生成Python代码，但代码不通用，如何利用大模型将这个过程通用化呢？我们也做过探索：</p> 
<ul><li><a href="https://blog.csdn.net/Attitude93/article/details/136280643">【AI大模型应用开发】【LangChain系列】实战案例2：通过URL加载网页内容 - LangChain对爬虫功能的封装</a></li></ul> 
<p><img src="https://images2.imgbox.com/b2/13/fJQo2lWe_o.png" alt="在这里插入图片描述"><br> 在这篇文章的后半部分，我们就利用了 LangChain 中的 create_extraction_chain 来尝试创建一个从网页内容中提取特定内容的通用爬虫。</p> 
<p>其主要代码如下：</p> 
<pre><code class="prism language-python">schema <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"properties"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">"article_title"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"article_content"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">"article_example_python_code"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">"required"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"article_title"</span><span class="token punctuation">,</span> <span class="token string">"article_content"</span><span class="token punctuation">,</span> <span class="token string">"article_example_python_code"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>


<span class="token keyword">def</span> <span class="token function">extract</span><span class="token punctuation">(</span>content<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> schema<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> create_extraction_chain<span class="token punctuation">(</span>schema<span class="token operator">=</span>schema<span class="token punctuation">,</span> llm<span class="token operator">=</span>llm<span class="token punctuation">)</span><span class="token punctuation">.</span>run<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
</code></pre> 
<p>最主要的是 schema 的定义，因为这是告诉LLM我们想要什么样的信息。所以，尽可能详细。其实现原理也比较明确，就是内部将 schema 转换成了 OpenAI 的 function calling 的结构，利用 Function Calling 能力来提取信息。</p> 
<p>具体的操作步骤和原理解释可以看下上面链接中的文章。</p> 
<blockquote> 
 <p><strong>小结：这种方式在获取到网页全部内容后，利用大模型从全部内容中提取出我们需要的信息。不需要知道想要信息的 Tag 和 Class，因此具有一定的通用性。但是效果好坏，完全取决于大模型的能力和我们自己定义的schema内容。目前来看，有点用，但想真正能用，还是非常难的。</strong></p> 
</blockquote> 
<h2><a id="2_AI_Agent_167"></a>2. 利用AI Agent实现通用爬虫</h2> 
<h3><a id="21__169"></a>2.1 实现思路</h3> 
<p>实现真正能够通用的爬虫，我们将目光放到 AI Agent 上。正好，前段时间学习 MetaGPT，里面的教程中就有通用爬虫的实现，咱们借鉴一下。</p> 
<p>具体的MetaGPT实现通用爬虫的详细步骤可以看这篇文章第3部分：<a href="https://blog.csdn.net/Attitude93/article/details/135720544">【AI Agent系列】【MetaGPT】8. 一句话订阅专属信息 - 订阅智能体进阶，实现一个更通用的订阅智能体</a></p> 
<p><img src="https://images2.imgbox.com/ae/42/e6bkM9Ic_o.png" alt="在这里插入图片描述"><br> 它的 <mark><strong>实现思路是先让大模型理解用户想要的数据内容，然后根据这些数据内容让大模型写爬虫代码，然后自动执行爬虫代码，获取相关文本内容。</strong></mark></p> 
<h3><a id="22__178"></a>2.2 自动化爬虫代码生成器</h3> 
<p>我将这个过程单独抽离了出来，自动写爬虫代码的完整代码如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> asyncio
<span class="token keyword">from</span> metagpt<span class="token punctuation">.</span>tools<span class="token punctuation">.</span>web_browser_engine <span class="token keyword">import</span> WebBrowserEngine
<span class="token keyword">from</span> metagpt<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>common <span class="token keyword">import</span> CodeParser
<span class="token keyword">from</span> metagpt<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>parse_html <span class="token keyword">import</span> _get_soup

<span class="token keyword">from</span> openai_test <span class="token keyword">import</span> openai_test

<span class="token keyword">def</span> <span class="token function">get_outline</span><span class="token punctuation">(</span>page<span class="token punctuation">)</span><span class="token punctuation">:</span>
    soup <span class="token operator">=</span> _get_soup<span class="token punctuation">(</span>page<span class="token punctuation">.</span>html<span class="token punctuation">)</span>
    outline <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">process_element</span><span class="token punctuation">(</span>element<span class="token punctuation">,</span> depth<span class="token punctuation">)</span><span class="token punctuation">:</span>
        name <span class="token operator">=</span> element<span class="token punctuation">.</span>name
        <span class="token keyword">if</span> <span class="token keyword">not</span> name<span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">if</span> name <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"script"</span><span class="token punctuation">,</span> <span class="token string">"style"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span>

        element_info <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"name"</span><span class="token punctuation">:</span> element<span class="token punctuation">.</span>name<span class="token punctuation">,</span> <span class="token string">"depth"</span><span class="token punctuation">:</span> depth<span class="token punctuation">}</span>

        <span class="token keyword">if</span> name <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"svg"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            element_info<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
            outline<span class="token punctuation">.</span>append<span class="token punctuation">(</span>element_info<span class="token punctuation">)</span>
            <span class="token keyword">return</span>

        element_info<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">.</span>string
        <span class="token comment"># Check if the element has an "id" attribute</span>
        <span class="token keyword">if</span> <span class="token string">"id"</span> <span class="token keyword">in</span> element<span class="token punctuation">.</span>attrs<span class="token punctuation">:</span>
            element_info<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span>

        <span class="token keyword">if</span> <span class="token string">"class"</span> <span class="token keyword">in</span> element<span class="token punctuation">.</span>attrs<span class="token punctuation">:</span>
            element_info<span class="token punctuation">[</span><span class="token string">"class"</span><span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">[</span><span class="token string">"class"</span><span class="token punctuation">]</span>
        outline<span class="token punctuation">.</span>append<span class="token punctuation">(</span>element_info<span class="token punctuation">)</span>
        <span class="token keyword">for</span> child <span class="token keyword">in</span> element<span class="token punctuation">.</span>children<span class="token punctuation">:</span>
            process_element<span class="token punctuation">(</span>child<span class="token punctuation">,</span> depth <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> element <span class="token keyword">in</span> soup<span class="token punctuation">.</span>body<span class="token punctuation">.</span>children<span class="token punctuation">:</span>
        process_element<span class="token punctuation">(</span>element<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> outline


<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> query<span class="token punctuation">)</span><span class="token punctuation">:</span>
    page <span class="token operator">=</span> <span class="token keyword">await</span> WebBrowserEngine<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>run<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    
    outline <span class="token operator">=</span> get_outline<span class="token punctuation">(</span>page<span class="token punctuation">)</span>
    outline <span class="token operator">=</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>
        <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token string">' '</span><span class="token operator">*</span>i<span class="token punctuation">[</span><span class="token string">'depth'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token string">'.'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">*</span>i<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'class'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span> <span class="token keyword">if</span> i<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span> <span class="token keyword">else</span> <span class="token string">''</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> outline
    <span class="token punctuation">)</span>
    
    <span class="token comment"># print(outline)</span>
    
    PROMPT_TEMPLATE <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Please complete the web page crawler parse function to achieve the User Requirement. The parse \
    function should take a BeautifulSoup object as input, which corresponds to the HTML outline provided in the Context.

    ```python
    from bs4 import BeautifulSoup

    # only complete the parse function
    def parse(soup: BeautifulSoup):
        ...
        # Return the object that the user wants to retrieve, don't use print
    ```

    ## User Requirement
    {requirement}

    ## Context

    The outline of html page to scrabe is show like below:

    ```tree
    {outline}
    ```
    """</span>
    
    code_rsp <span class="token operator">=</span> openai_test<span class="token punctuation">.</span>get_chat_completion<span class="token punctuation">(</span>PROMPT_TEMPLATE<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>outline<span class="token operator">=</span>outline<span class="token punctuation">,</span> requirement<span class="token operator">=</span>query<span class="token punctuation">)</span><span class="token punctuation">)</span>
    code <span class="token operator">=</span> CodeParser<span class="token punctuation">.</span>parse_code<span class="token punctuation">(</span>block<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> text<span class="token operator">=</span>code_rsp<span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span>code<span class="token punctuation">)</span>
    
asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>test<span class="token punctuation">(</span><span class="token string">"https://mp.weixin.qq.com/s/2m8MrsCxf5boiH4Dzpphrg"</span><span class="token punctuation">,</span> <span class="token string">"获取标题，正文中的所有问题，正文中的代码"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>其步骤可总结如下：<br> （1）通过<code>WebBrowserEngine</code> 获得URL的HTML结构： <code>page = await WebBrowserEngine().run(url)</code></p> 
<p>（2）通过<code>get_outline</code>获取出该HTML网页的主体结构，这是为了消除原HTML中的无用数据，同时减少Token消耗： <code>outline = get_outline(page)</code></p> 
<p>（3）将 <code>outline</code> 和 <code>用户的需求数据</code> 组成 <code>Prompt</code>，给大模型，让大模型写代码：<code>code_rsp = openai_test.get_chat_completion(PROMPT_TEMPLATE.format(outline=outline, requirement=query))</code></p> 
<p>其最终运行结果如下（最终输出的是针对此url和用户需求的爬虫代码）：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>soup<span class="token punctuation">:</span> BeautifulSoup<span class="token punctuation">)</span><span class="token punctuation">:</span>
    title <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'h1'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">'rich_media_title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text

    questions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    codes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    sections <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'section'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> section <span class="token keyword">in</span> sections<span class="token punctuation">:</span>
        blocks <span class="token operator">=</span> section<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token string">'h2'</span><span class="token punctuation">,</span> <span class="token string">'h3'</span><span class="token punctuation">,</span> <span class="token string">'pre'</span><span class="token punctuation">,</span> <span class="token string">'ul'</span><span class="token punctuation">,</span> <span class="token string">'blockquote'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> block <span class="token keyword">in</span> blocks<span class="token punctuation">:</span>
            text <span class="token operator">=</span> block<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span>strip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> text<span class="token punctuation">:</span>
                <span class="token keyword">if</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'p'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'h2'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'h3'</span><span class="token punctuation">:</span>
                    <span class="token keyword">if</span> text <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'公众号内文章一览'</span><span class="token punctuation">,</span> <span class="token string">'原创'</span><span class="token punctuation">,</span> <span class="token string">'同学小张'</span><span class="token punctuation">,</span> <span class="token string">'2024-03-13 08:00'</span><span class="token punctuation">,</span> <span class="token string">'北京'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                        questions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
                <span class="token keyword">if</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'pre'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'ul'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'blockquote'</span><span class="token punctuation">:</span>
                    codes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'title'</span><span class="token punctuation">:</span> title<span class="token punctuation">,</span>
        <span class="token string">'questions'</span><span class="token punctuation">:</span> questions<span class="token punctuation">,</span>
        <span class="token string">'codes'</span><span class="token punctuation">:</span> codes
    <span class="token punctuation">}</span>
</code></pre> 
<p>运行该爬虫代码看下大模型写的代码的效果，测试程序如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> asyncio
<span class="token keyword">from</span> metagpt<span class="token punctuation">.</span>tools<span class="token punctuation">.</span>web_browser_engine <span class="token keyword">import</span> WebBrowserEngine
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>soup<span class="token punctuation">:</span> BeautifulSoup<span class="token punctuation">)</span><span class="token punctuation">:</span>
    title <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'h1'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">'rich_media_title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text

    questions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    codes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    sections <span class="token operator">=</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'section'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> section <span class="token keyword">in</span> sections<span class="token punctuation">:</span>
        blocks <span class="token operator">=</span> section<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token string">'h2'</span><span class="token punctuation">,</span> <span class="token string">'h3'</span><span class="token punctuation">,</span> <span class="token string">'pre'</span><span class="token punctuation">,</span> <span class="token string">'ul'</span><span class="token punctuation">,</span> <span class="token string">'blockquote'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> block <span class="token keyword">in</span> blocks<span class="token punctuation">:</span>
            text <span class="token operator">=</span> block<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span>strip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> text<span class="token punctuation">:</span>
                <span class="token keyword">if</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'p'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'h2'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'h3'</span><span class="token punctuation">:</span>
                    <span class="token keyword">if</span> text <span class="token keyword">not</span> <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'公众号内文章一览'</span><span class="token punctuation">,</span> <span class="token string">'原创'</span><span class="token punctuation">,</span> <span class="token string">'同学小张'</span><span class="token punctuation">,</span> <span class="token string">'2024-03-13 08:00'</span><span class="token punctuation">,</span> <span class="token string">'北京'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                        questions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
                <span class="token keyword">if</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'pre'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'ul'</span> <span class="token keyword">or</span> block<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'blockquote'</span><span class="token punctuation">:</span>
                    codes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'title'</span><span class="token punctuation">:</span> title<span class="token punctuation">,</span>
        <span class="token string">'questions'</span><span class="token punctuation">:</span> questions<span class="token punctuation">,</span>
        <span class="token string">'codes'</span><span class="token punctuation">:</span> codes
    <span class="token punctuation">}</span>

<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>
    page <span class="token operator">=</span> <span class="token keyword">await</span> WebBrowserEngine<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>run<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    result <span class="token operator">=</span> parse<span class="token punctuation">(</span>page<span class="token punctuation">.</span>soup<span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
    
asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>test<span class="token punctuation">(</span><span class="token string">"https://mp.weixin.qq.com/s/2m8MrsCxf5boiH4Dzpphrg"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<p><img src="https://images2.imgbox.com/9e/7d/hDGdUwzb_o.png" alt="在这里插入图片描述"><br> 该爬虫程序将网页内容提取成了用户需求的那三个字段：题目、正文问题（文字）、正文代码，效果还是很不错的。</p> 
<p>当然，我们上面是手动将爬虫代码粘贴出来测试的，在AI Agent中，直接再加一个Agent，让其专门自动运行此代码，就完成了通用爬虫的过程（这也是上文链接文章中的做法）：用户全程只需输入一个Url和想要的数据，然后就能拿到想要的内容了，而且效果比上面第1节中利用大模型直接提取指定信息的方法要好得多。</p> 
<h3><a id="23__350"></a>2.3 可能遇到的问题</h3> 
<p>虽然我们上面通过 get_outline 对HTML内容进行了精简，但还是存在超过大模型 Token 数限制的情况，这种情况就无法生成爬虫代码，而是报下面的错误：</p> 
<p><img src="https://images2.imgbox.com/33/5c/L4XpHjsZ_o.png" alt="在这里插入图片描述"><br> 解决这种情况的方法也简单，限制下最终 Prompt 的 Token 数就好了（简单粗暴），这些 Token 已经足以表达 HTML 的结构了。</p> 
<pre><code class="prism language-python"><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">16000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    prompt <span class="token operator">=</span> prompt<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">16000</span><span class="token punctuation">]</span>
</code></pre> 
<h2><a id="3__362"></a>3. 总结</h2> 
<p>本文我们盘点了目前为止我使用过的所有爬虫代码，分析了它们的实现方法。从专用爬虫，到大模型直接提取指定信息的通用爬虫探索，再到最终的利用 AI Agent 实现通用爬虫，逐步递进，总能让你收获点东西。</p> 
<p>本文中的代码和关联文章中的代码都是我亲测可用的，可以直接拿去用。</p> 
<blockquote> 
 <p>题外话：在运行过程中，LangChain 和 MetaGPT 中的相关封装类，底层有使用 Playwright 来进行网页数据获取，所以，你可能需要安装下 Playwright 环境。我在这上面踩了不少坑，如果你需要，可以看这篇文章避下坑：<a href="https://blog.csdn.net/Attitude93/article/details/136688968">【云服务环境】含泪总结：我在云服务安装Python爬虫环境Playwright的踩坑实录</a></p> 
</blockquote> 
<blockquote> 
 <p><strong>如果觉得本文对你有帮助，麻烦点个赞和关注呗 ~~~</strong></p> 
</blockquote> 
<hr> 
<blockquote> 
 <ul><li>大家好，我是 <font color="blue"><strong>同学小张</strong></font>，日常分享AI知识和实战案例</li><li>欢迎 <font color="red"><strong>点赞 + 关注</strong></font> 👏，<strong>持续学习</strong>，<strong>持续干货输出</strong>。</li><li>+v: <font color="blue"><strong>jasper_8017</strong></font> 一起交流💬，一起进步💪。</li><li>微信公众号也可搜<font color="blue">【<strong>同学小张</strong>】</font> 🙏</li></ul> 
</blockquote> 
<p><strong><mark>本站文章一览：</mark></strong></p> 
<p><img src="https://images2.imgbox.com/3e/99/fZK5Jd0t_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/762e3100b5dd68b6e502502ebe21eaea/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">阿里云-零基础入门推荐系统 【排序模型&#43;模型融合】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f0b301f80edfad4b422803115062a050/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Not so Mobile（UVA 839）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>