<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark的数据结构——RDD - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spark的数据结构——RDD" />
<meta property="og:description" content="RDD 的 5 个特征 下面来说一下 RDD 这东西，它是 Resilient Distributed Datasets 的简写。
咱们来看看 RDD 在源码的解释。
A list of partitions: 在大数据领域，大数据都是分割成若干个部分，放到多个服务器上，这样就能做到多线程的处理数据，这对处理大数据量是非常重要的。分区意味着，可以使用多个线程了处理。A function for computing each split：作用在每个分区里面的函数，当我们读取数据之后，当然是要对其加工的，加工的定义就是我们编写的函数，这些函数主要包含转化算子、控制算子、行动算子。A list of dependencies on other RDDs。一个 Spark Application 下面可以有多个 Job ，一个 action 算子就可以分出一个 job ，一个 job 里面又可以分出若干个 stage ， 一个 stage 中又有多个 RDD ，RDD 之间是用上下游关系的，就像流水线的工序，公休之间也会有先后之分的，例如，手机装壳之后才能上螺丝，这种上下游关系，使用依赖描述的，依赖又分为窄依赖和宽依赖。 那两个 RDD 为例，rdd2 依赖于 rdd1 ，Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)Optionally, a list of preferred locations to compute each split on (e." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/d4133a85e49cf68407675682daed4b00/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-13T14:50:49+08:00" />
<meta property="article:modified_time" content="2024-03-13T14:50:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark的数据结构——RDD</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="RDD__5__0"></a>RDD 的 5 个特征</h4> 
<p>下面来说一下 RDD 这东西，它是 Resilient Distributed Datasets 的简写。</p> 
<p>咱们来看看 RDD 在源码的解释。</p> 
<ul><li>A list of partitions: 在大数据领域，大数据都是分割成若干个部分，放到多个服务器上，这样就能做到多线程的处理数据，这对处理大数据量是非常重要的。分区意味着，可以使用多个线程了处理。</li><li>A function for computing each split：作用在每个分区里面的函数，当我们读取数据之后，当然是要对其加工的，加工的定义就是我们编写的函数，这些函数主要包含转化算子、控制算子、行动算子。</li><li>A list of dependencies on other RDDs。一个 Spark Application 下面可以有多个 Job ，一个 action 算子就可以分出一个 job ，一个 job 里面又可以分出若干个 stage ， 一个 stage 中又有多个 RDD ，RDD 之间是用上下游关系的，就像流水线的工序，公休之间也会有先后之分的，例如，手机装壳之后才能上螺丝，这种上下游关系，使用依赖描述的，依赖又分为窄依赖和宽依赖。 那两个 RDD 为例，rdd2 依赖于 rdd1 ，</li><li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</li><li>Optionally, a list of preferred locations to compute each split on (e.g. block locations for</li><li>an HDFS file)</li></ul> 
<h4><a id="RDD__13"></a>RDD 源代码</h4> 
<p>RDD 的代码是非常多的，一个 RDD.scala 类就有 2000 多行。我们只捡能说明问题的就行了。</p> 
<pre><code class="prism language-scala"><span class="token keyword">abstract</span> <span class="token keyword">class</span> RDD<span class="token punctuation">[</span>T<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>
    <span class="token comment">// SparkContext 是代码的运行环境，SparkContext 中有一个 TaskSchedule 和 DAGSchedule ，前者是申请资源，后者是将 job 分割为多个 Stage ，然后提交给相应的 Executor</span>
    <span class="token annotation punctuation">@transient</span> <span class="token keyword">private</span> <span class="token keyword">var</span> _sc<span class="token operator">:</span> SparkContext<span class="token punctuation">,</span>
    <span class="token comment">// deps 代表了上游算子依赖，上游可能有多个依赖，所以这里是一个 Seq .</span>
    <span class="token comment">// 这个 Seq 就是 RDD 中依赖的具体体现</span>
    <span class="token annotation punctuation">@transient</span> <span class="token keyword">private</span> <span class="token keyword">var</span> deps<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span>
  <span class="token punctuation">)</span> <span class="token keyword">extends</span> Serializable <span class="token keyword">with</span> Logging <span class="token punctuation">{<!-- --></span>
  <span class="token comment">// compute 函数代表了 RDD 第二个特征，作用在 partition 上面的函数。</span>
  <span class="token annotation punctuation">@DeveloperApi</span>
  <span class="token keyword">def</span> compute<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">,</span> context<span class="token operator">:</span> TaskContext<span class="token punctuation">)</span><span class="token operator">:</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span>
  <span class="token comment">// 此函数是 RDD 第一个特征的具体表现，各个 RDD 的具体实现，可以根据它获得 RDD 中的分区</span>
  <span class="token keyword">protected</span> <span class="token keyword">def</span> getPartitions<span class="token operator">:</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span>
  <span class="token comment">// 还是依赖相关的函数</span>
  <span class="token keyword">protected</span> <span class="token keyword">def</span> getDependencies<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> deps
  <span class="token comment">// 此函数对应了 RDD 的第 5 个特征。各个 RDD 的实现类，在此函数中，实现就近数据的查找。</span>
  <span class="token keyword">protected</span> <span class="token keyword">def</span> getPreferredLocations<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">)</span><span class="token operator">:</span> Seq<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Nil
  <span class="token comment">// 此函数对应了 RDD 的第四个特征，针对 PairRDDFunction 的分区器。</span>
  <span class="token annotation punctuation">@transient</span> <span class="token keyword">val</span> partitioner<span class="token operator">:</span> Option<span class="token punctuation">[</span>Partitioner<span class="token punctuation">]</span> <span class="token operator">=</span> None

  <span class="token keyword">def</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sc

  <span class="token keyword">val</span> id<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>newRddId<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token keyword">final</span> <span class="token keyword">def</span> dependencies<span class="token operator">:</span> Seq<span class="token punctuation">[</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
  <span class="token punctuation">}</span>

  <span class="token keyword">final</span> <span class="token keyword">private</span> <span class="token keyword">def</span> internalDependencies<span class="token operator">:</span> Option<span class="token punctuation">[</span>Seq<span class="token punctuation">[</span>Dependency<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
  <span class="token punctuation">}</span>

  <span class="token keyword">final</span> <span class="token keyword">def</span> partitions<span class="token operator">:</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
     <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
  <span class="token punctuation">}</span>

  <span class="token keyword">final</span> <span class="token keyword">def</span> preferredLocations<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">)</span><span class="token operator">:</span> Seq<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    checkpointRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>getPreferredLocations<span class="token punctuation">(</span>split<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrElse <span class="token punctuation">{<!-- --></span>
      getPreferredLocations<span class="token punctuation">(</span>split<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>

  <span class="token keyword">final</span> <span class="token keyword">def</span> iterator<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">,</span> context<span class="token operator">:</span> TaskContext<span class="token punctuation">)</span><span class="token operator">:</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">object</span> RDD <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">private</span><span class="token punctuation">[</span>spark<span class="token punctuation">]</span> <span class="token keyword">val</span> CHECKPOINT_ALL_MARKED_ANCESTORS <span class="token operator">=</span>
    <span class="token string">"spark.checkpoint.checkpointAllMarkedAncestors"</span>
  <span class="token keyword">implicit</span> <span class="token keyword">def</span> rddToPairRDDFunctions<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token keyword">implicit</span> kt<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">,</span> vt<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">,</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>K<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> PairRDDFunctions<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">new</span> PairRDDFunctions<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
  <span class="token comment">// 此方法对应了 RDD 的第四个特征，有了它，只要将 RDD 中的数据转化为 tuple2 的数据格式，就能自动调用 PairRDDFunction 中的函数。</span>
  <span class="token keyword">implicit</span> <span class="token keyword">def</span> rddToAsyncRDDActions<span class="token punctuation">[</span>T<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> AsyncRDDActions<span class="token punctuation">[</span>T<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">new</span> AsyncRDDActions<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>还有更重要的一点，就是第二个特征，作用在分区上的函数，RDD 加上 PairRDDFunction 上的函数有很多，可以在上一篇 <a href="https://blog.csdn.net/bluedraam_pp/article/details/136354987">Spark 核心API</a> 中找到。</p> 
<p>下面以 Workd Count 为例子，画图来说明 RDD 的特性。</p> 
<pre><code class="prism language-scala"><span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getCanonicalName<span class="token punctuation">.</span>init<span class="token punctuation">)</span>
<span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
sc<span class="token punctuation">.</span>textfile<span class="token punctuation">(</span><span class="token string">"hdfs://nameservice/user/test_data/file.txt"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>flapMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
</code></pre> 
<p>先来看看 textFile 底层是什么？</p> 
<pre><code class="prism language-scala"><span class="token comment">// SparkContext </span>
<span class="token keyword">def</span> textFile<span class="token punctuation">(</span>
    path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span>
    minPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> defaultMinPartitions<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{<!-- --></span>
  assertNotStopped<span class="token punctuation">(</span><span class="token punctuation">)</span>
  hadoopFile<span class="token punctuation">(</span>path<span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>TextInputFormat<span class="token punctuation">]</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>LongWritable<span class="token punctuation">]</span><span class="token punctuation">,</span> classOf<span class="token punctuation">[</span>Text<span class="token punctuation">]</span><span class="token punctuation">,</span>
    minPartitions<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>pair <span class="token keyword">=&gt;</span> pair<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toString<span class="token punctuation">)</span><span class="token punctuation">.</span>setName<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
<span class="token keyword">def</span> hadoopFile<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">(</span>
    path<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span>
    inputFormatClass<span class="token operator">:</span> Class<span class="token punctuation">[</span>_ <span class="token operator">&lt;</span><span class="token operator">:</span> InputFormat<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    keyClass<span class="token operator">:</span> Class<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">,</span>
    valueClass<span class="token operator">:</span> Class<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">,</span>
    minPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> defaultMinPartitions<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{<!-- --></span>
  assertNotStopped<span class="token punctuation">(</span><span class="token punctuation">)</span>
  FileSystem<span class="token punctuation">.</span>getLocal<span class="token punctuation">(</span>hadoopConfiguration<span class="token punctuation">)</span>
  <span class="token keyword">val</span> confBroadcast <span class="token operator">=</span> broadcast<span class="token punctuation">(</span><span class="token keyword">new</span> SerializableConfiguration<span class="token punctuation">(</span>hadoopConfiguration<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">val</span> setInputPathsFunc <span class="token operator">=</span> <span class="token punctuation">(</span>jobConf<span class="token operator">:</span> JobConf<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> FileInputFormat<span class="token punctuation">.</span>setInputPaths<span class="token punctuation">(</span>jobConf<span class="token punctuation">,</span> path<span class="token punctuation">)</span>
  <span class="token comment">// 最后返回的是 HadoopRDD ，这是我们认识的第一个 RDD </span>
  <span class="token keyword">new</span> HadoopRDD<span class="token punctuation">(</span>
    <span class="token keyword">this</span><span class="token punctuation">,</span>
    confBroadcast<span class="token punctuation">,</span>
    Some<span class="token punctuation">(</span>setInputPathsFunc<span class="token punctuation">)</span><span class="token punctuation">,</span>
    inputFormatClass<span class="token punctuation">,</span>
    keyClass<span class="token punctuation">,</span>
    valueClass<span class="token punctuation">,</span>
    minPartitions<span class="token punctuation">)</span><span class="token punctuation">.</span>setName<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
</code></pre> 
<p>以 HadoopRDD 为例子，我们来看看 RDD 的五个特性。<br> 第一个特征是分区，来看一下 HadoopRDD 的 getPartitions 方法。</p> 
<pre><code class="prism language-scala"><span class="token keyword">override</span> <span class="token keyword">def</span> getPartitions<span class="token operator">:</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">val</span> jobConf <span class="token operator">=</span> getJobConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 获取 splite , 这其实就是将一个 HDFS 文件切分成若干个分区。 </span>
    <span class="token keyword">val</span> allInputSplits <span class="token operator">=</span> getInputFormat<span class="token punctuation">(</span>jobConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getSplits<span class="token punctuation">(</span>jobConf<span class="token punctuation">,</span> minPartitions<span class="token punctuation">)</span>
    <span class="token keyword">val</span> inputSplits <span class="token operator">=</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>ignoreEmptySplits<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      allInputSplits<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>_<span class="token punctuation">.</span>getLength <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{<!-- --></span>
      allInputSplits
    <span class="token punctuation">}</span>
    <span class="token comment">// 根据分区大小来提示优化策略</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>inputSplits<span class="token punctuation">.</span>length <span class="token operator">==</span> <span class="token number">1</span> <span class="token operator">&amp;&amp;</span> inputSplits<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>isInstanceOf<span class="token punctuation">[</span>FileSplit<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token punctuation">}</span>
    <span class="token comment">// 将 FileSplite 组成 hadoopPartition</span>
    <span class="token keyword">val</span> array <span class="token operator">=</span> <span class="token keyword">new</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span><span class="token punctuation">(</span>inputSplits<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token keyword">&lt;-</span> <span class="token number">0</span> until inputSplits<span class="token punctuation">.</span>size<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      array<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token keyword">new</span> HadoopPartition<span class="token punctuation">(</span>id<span class="token punctuation">,</span> i<span class="token punctuation">,</span> inputSplits<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    array
  <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>从 getPatitions 方法，可以看到使用 hadoop-client 的接口，将 HDFS 的文件切成若干 HadoopPartition ，然后返回一个数组 Array[Partition]。</p> 
<p>第二个特征是作用在分区上的函数，那就来到来 compute 函数。</p> 
<pre><code class="prism language-scala"><span class="token keyword">override</span> <span class="token keyword">def</span> compute<span class="token punctuation">(</span>theSplit<span class="token operator">:</span> Partition<span class="token punctuation">,</span> context<span class="token operator">:</span> TaskContext<span class="token punctuation">)</span><span class="token operator">:</span> InterruptibleIterator<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token comment">// 构造 NextIterator 迭代器</span>
  <span class="token keyword">val</span> iter <span class="token operator">=</span> <span class="token keyword">new</span> NextIterator<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">private</span> <span class="token keyword">var</span> reader<span class="token operator">:</span> RecordReader<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    reader <span class="token operator">=</span>
      <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
        inputFormat<span class="token punctuation">.</span>getRecordReader<span class="token punctuation">(</span>split<span class="token punctuation">.</span>inputSplit<span class="token punctuation">.</span>value<span class="token punctuation">,</span> jobConf<span class="token punctuation">,</span> Reporter<span class="token punctuation">.</span>NULL<span class="token punctuation">)</span>
      <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{<!-- --></span>
         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
      <span class="token punctuation">}</span>

    <span class="token keyword">private</span> <span class="token keyword">val</span> key<span class="token operator">:</span> K <span class="token operator">=</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>reader <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token keyword">null</span><span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>K<span class="token punctuation">]</span> <span class="token keyword">else</span> reader<span class="token punctuation">.</span>createKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">private</span> <span class="token keyword">val</span> value<span class="token operator">:</span> V <span class="token operator">=</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>reader <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token keyword">null</span><span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>V<span class="token punctuation">]</span> <span class="token keyword">else</span> reader<span class="token punctuation">.</span>createValue<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 重新 getNext 方法，此方法其实就是从 HDFS 的文件中哪里一行数据，</span>
    <span class="token comment">// K 为对应此行在文件中的位置，</span>
    <span class="token comment">// V 为此行的数据</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> getNext<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
        finished <span class="token operator">=</span> <span class="token operator">!</span>reader<span class="token punctuation">.</span>next<span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
      <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">{<!-- --></span>
         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
      <span class="token punctuation">}</span>
      <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token comment">// 关闭 HDFS 客户端和服务器端的连接</span>
    <span class="token keyword">override</span> <span class="token keyword">def</span> close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">new</span> InterruptibleIterator<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> iter<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>上面的代码中 inputSplit 其实是 FileInputSplit ，reader 是 LineRecordReader 。HadoopRDD 的功能就是从 HDFS 中取数据，向后发送，所以没有数据处理的逻辑。</p> 
<p>第三个特征是描述 RDD 中的依赖。HadoopRDD 是第一个 RDD 所以它前面已经没有了 RDD 。从下面 HadoopRDD 的定义就能看出来。Dependency 为 Nil</p> 
<pre><code class="prism language-scala"><span class="token keyword">class</span> HadoopRDD<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">(</span>
   sc<span class="token operator">:</span> SparkContext<span class="token punctuation">,</span>
   broadcastedConf<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>SerializableConfiguration<span class="token punctuation">]</span><span class="token punctuation">,</span>
   initLocalJobConfFuncOpt<span class="token operator">:</span> Option<span class="token punctuation">[</span>JobConf <span class="token keyword">=&gt;</span> <span class="token builtin">Unit</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   inputFormatClass<span class="token operator">:</span> Class<span class="token punctuation">[</span>_ <span class="token operator">&lt;</span><span class="token operator">:</span> InputFormat<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   keyClass<span class="token operator">:</span> Class<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">,</span>
   valueClass<span class="token operator">:</span> Class<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">,</span>
   minPartitions<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span>
 <span class="token comment">// RDD构造函数是 RDD(SparkContext , Dependency)</span>
 <span class="token comment">// 从下面的代码中，可以看到 Dependency 为 Nil 。</span>
 <span class="token keyword">extends</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">(</span>sc<span class="token punctuation">,</span> Nil<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>preferedLocation 和 key-value RDDS 的特征在 HadoopRDD 没有体现出来。</p> 
<p>下面再看 flatMap ，</p> 
<pre><code class="prism language-scala">  <span class="token keyword">def</span> flatMap<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> TraversableOnce<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> cleanF <span class="token operator">=</span> sc<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    <span class="token keyword">new</span> MapPartitionsRDD<span class="token punctuation">[</span>U<span class="token punctuation">,</span> T<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> iter<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> iter<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>cleanF<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
</code></pre> 
<p>从上面代码中可以看到，MapPartitionsRDD 是 flatMap 的 RDD。还是这五个特征来看 MapPartitionsRDD ，</p> 
<pre><code class="prism language-scala"><span class="token comment">// MapPartitionsRDD#getPartitions</span>
<span class="token keyword">override</span> <span class="token keyword">def</span> getPartitions<span class="token operator">:</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span> <span class="token operator">=</span> firstParent<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">.</span>partitions
<span class="token comment">// RDD#firstParent</span>
<span class="token keyword">protected</span><span class="token punctuation">[</span>spark<span class="token punctuation">]</span> <span class="token keyword">def</span> firstParent<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  dependencies<span class="token punctuation">.</span>head<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>从上面的代码，可以看出，getPartitions 方法取出是第一个父 RDD 的分区，这是第一个特征。</p> 
<p>第二个特征是作用在分区上面的计算，flatMap 是将 line 分裂成单个的单词，所以这里需要函数，就是 f ，<br> f 其实是在 flatMap 函数中定义的 <code>(_, _, iter) =&gt; iter.flatMap(cleanF)</code> , 而 cleanF 就是<br> 我们自定义的 _.split(“\s”) 的,而接收它的是一个 iterator 的 flatMap ，这个 flatMap 是 scala<br> 原生的，并不是 RDD#flatMap。</p> 
<pre><code class="prism language-scala"><span class="token keyword">override</span> <span class="token keyword">def</span> compute<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">,</span> context<span class="token operator">:</span> TaskContext<span class="token punctuation">)</span><span class="token operator">:</span> Iterator<span class="token punctuation">[</span>U<span class="token punctuation">]</span> <span class="token operator">=</span>
  f<span class="token punctuation">(</span>context<span class="token punctuation">,</span> split<span class="token punctuation">.</span>index<span class="token punctuation">,</span> firstParent<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">.</span>iterator<span class="token punctuation">(</span>split<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>从代码中，看到 f 的第三个入参是第一个父 RDD 的迭代器。</p> 
<p>第三个特征是依赖关系，可以从 MapPartitionsRDD 的定义看出。</p> 
<pre><code class="prism language-scala"><span class="token keyword">private</span><span class="token punctuation">[</span>spark<span class="token punctuation">]</span> <span class="token keyword">class</span> MapPartitionsRDD<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">,</span> T<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>
    <span class="token keyword">var</span> prev<span class="token operator">:</span> RDD<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">,</span>
    f<span class="token operator">:</span> <span class="token punctuation">(</span>TaskContext<span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> Iterator<span class="token punctuation">[</span>T<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> Iterator<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment">// (TaskContext, partition index, iterator)</span>
    preservesPartitioning<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
    isFromBarrier<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
    isOrderSensitive<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
  <span class="token keyword">extends</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span><span class="token punctuation">(</span>prev<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span>
  
 <span class="token keyword">def</span> <span class="token keyword">this</span><span class="token punctuation">(</span><span class="token annotation punctuation">@transient</span> oneParent<span class="token operator">:</span> RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">=</span>
    <span class="token keyword">this</span><span class="token punctuation">(</span>oneParent<span class="token punctuation">.</span>context<span class="token punctuation">,</span> List<span class="token punctuation">(</span><span class="token keyword">new</span> OneToOneDependency<span class="token punctuation">(</span>oneParent<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>现在只要弄清楚 pre 是那个 RDD 就可以了，当我们调用 sc.textFile(path).flatMap(_.split(“\s”))，其实 textFile 返回的是 HadoopRDD，所以是 HadoopRDD 调用的 flatMap ，所以 prev 就是 HadoopRDD 的引用。到这里，问题应该就清晰了，OneToOneDependency保存的父 RDD ，再有明显可以看出是窄依赖，一对一嘛。</p> 
<p>preferedLocation 和 key-value RDD 同样都没体现出来。</p> 
<p>下面来看看 map((_,1)) 使用了什么 RDD。</p> 
<pre><code class="prism language-scala"> <span class="token keyword">def</span> map<span class="token punctuation">[</span>U<span class="token operator">:</span> ClassTag<span class="token punctuation">]</span><span class="token punctuation">(</span>f<span class="token operator">:</span> T <span class="token keyword">=&gt;</span> U<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span>U<span class="token punctuation">]</span> <span class="token operator">=</span> withScope <span class="token punctuation">{<!-- --></span>
   <span class="token keyword">val</span> cleanF <span class="token operator">=</span> sc<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
   <span class="token keyword">new</span> MapPartitionsRDD<span class="token punctuation">[</span>U<span class="token punctuation">,</span> T<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> iter<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> iter<span class="token punctuation">.</span>map<span class="token punctuation">(</span>cleanF<span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token punctuation">}</span>
</code></pre> 
<p>从代码来看，f 函数被 map 调用了，对应的 RDD 也是 MapPartitionRDD ，就是迭代器调用的方法发生了改变。还是按照老办法，把五个特征找出来。</p> 
<p>第一个是 getPartitions 返回还是第一个 parent RDD 的分区。<br> 第二个是 compute 中调用的是第一个 parentRDD 分区的迭代器。<br> 第三个是 dependency 是 flatMap 对应的 MapPartiionRDD<br> preferedLocation 和 key-value RDD 同样都没体现出来。</p> 
<p>最后是 reduceByKey(<em>+</em>) , reduceByKey 是 PairRDDFunction 的函数，这是咋回事，map((_,1)) 返回的不是 MapPartitionRDD 吗？怎么又变成 PairRDDFunction 了，这就要讲到 Scala 的隐式转化， 请看下面的代码：</p> 
<pre><code class="prism language-scala"><span class="token keyword">object</span> RDD <span class="token punctuation">{<!-- --></span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
  <span class="token keyword">implicit</span> <span class="token keyword">def</span> rddToPairRDDFunctions<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token keyword">implicit</span> kt<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>K<span class="token punctuation">]</span><span class="token punctuation">,</span> vt<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">,</span> ord<span class="token operator">:</span> Ordering<span class="token punctuation">[</span>K<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token operator">:</span> PairRDDFunctions<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">new</span> PairRDDFunctions<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span>  
</code></pre> 
<p>当调用某个类的方法，发现此类没有这个方法，则就取找隐式方法，这里隐式方法是 rddToPairRDDFunctions，它最终将 MapPartitionRDD 转化为了 PairRDDFunction ，这样就实现了自动化的转化，所以这里能够调用 reduceByKey 方法，这也对应了 RDD 的第四个特性，key-value RDD 。看到这里，它的意思就是将那些数据类型为 (key , value) 的 RDD 自动转化为 PairRDDFunctiono , 并且调用上面的方法。</p> 
<p>接着看 reduceByKey 的源码，</p> 
<pre><code class="prism language-scala"><span class="token keyword">def</span> reduceByKey<span class="token punctuation">(</span>func<span class="token operator">:</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> V<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">self</span><span class="token punctuation">.</span>withScope <span class="token punctuation">{<!-- --></span>
  reduceByKey<span class="token punctuation">(</span>defaultPartitioner<span class="token punctuation">(</span><span class="token keyword">self</span><span class="token punctuation">)</span><span class="token punctuation">,</span> func<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
<span class="token keyword">def</span> reduceByKey<span class="token punctuation">(</span>partitioner<span class="token operator">:</span> Partitioner<span class="token punctuation">,</span> func<span class="token operator">:</span> <span class="token punctuation">(</span>V<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> V<span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> V<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">self</span><span class="token punctuation">.</span>withScope <span class="token punctuation">{<!-- --></span>
  combineByKeyWithClassTag<span class="token punctuation">[</span>V<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">(</span>v<span class="token operator">:</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> v<span class="token punctuation">,</span> func<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitioner<span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>从上面的源码看出，reduceByKey 底层使用的是 combinerByKey() , combinerByKey 在之前的文章已经讲过了，</p> 
<pre><code class="prism language-scala">  <span class="token keyword">def</span> combineByKeyWithClassTag<span class="token punctuation">[</span>C<span class="token punctuation">]</span><span class="token punctuation">(</span>
      createCombiner<span class="token operator">:</span> V <span class="token keyword">=&gt;</span> C<span class="token punctuation">,</span>
      mergeValue<span class="token operator">:</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span> V<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> C<span class="token punctuation">,</span>
      mergeCombiners<span class="token operator">:</span> <span class="token punctuation">(</span>C<span class="token punctuation">,</span> C<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> C<span class="token punctuation">,</span>
      partitioner<span class="token operator">:</span> Partitioner<span class="token punctuation">,</span>
      mapSideCombine<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
      serializer<span class="token operator">:</span> Serializer <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">implicit</span> ct<span class="token operator">:</span> ClassTag<span class="token punctuation">[</span>C<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">self</span><span class="token punctuation">.</span>withScope <span class="token punctuation">{<!-- --></span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">val</span> aggregator <span class="token operator">=</span> <span class="token keyword">new</span> Aggregator<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> C<span class="token punctuation">]</span><span class="token punctuation">(</span>
      <span class="token keyword">self</span><span class="token punctuation">.</span>context<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>createCombiner<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token keyword">self</span><span class="token punctuation">.</span>context<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>mergeValue<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token keyword">self</span><span class="token punctuation">.</span>context<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>mergeCombiners<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">self</span><span class="token punctuation">.</span>partitioner <span class="token operator">==</span> Some<span class="token punctuation">(</span>partitioner<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">new</span> ShuffledRDD<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> C<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token keyword">self</span><span class="token punctuation">,</span> partitioner<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setSerializer<span class="token punctuation">(</span>serializer<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setAggregator<span class="token punctuation">(</span>aggregator<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setMapSideCombine<span class="token punctuation">(</span>mapSideCombine<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>

</code></pre> 
<p>从代码得，combineByKey 底层使用的是 ShuffleRDD 。</p> 
<pre><code class="prism language-scala"><span class="token keyword">override</span> <span class="token keyword">def</span> getPartitions<span class="token operator">:</span> Array<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  Array<span class="token punctuation">.</span>tabulate<span class="token punctuation">[</span>Partition<span class="token punctuation">]</span><span class="token punctuation">(</span>part<span class="token punctuation">.</span>numPartitions<span class="token punctuation">)</span><span class="token punctuation">(</span>i <span class="token keyword">=&gt;</span> <span class="token keyword">new</span> ShuffledRDDPartition<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
<span class="token keyword">override</span> <span class="token keyword">def</span> compute<span class="token punctuation">(</span>split<span class="token operator">:</span> Partition<span class="token punctuation">,</span> context<span class="token operator">:</span> TaskContext<span class="token punctuation">)</span><span class="token operator">:</span> Iterator<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">val</span> dep <span class="token operator">=</span> dependencies<span class="token punctuation">.</span>head<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> C<span class="token punctuation">]</span><span class="token punctuation">]</span>
  <span class="token keyword">val</span> metrics <span class="token operator">=</span> context<span class="token punctuation">.</span>taskMetrics<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>createTempShuffleReadMetrics<span class="token punctuation">(</span><span class="token punctuation">)</span>
  SparkEnv<span class="token punctuation">.</span>get<span class="token punctuation">.</span>shuffleManager<span class="token punctuation">.</span>getReader<span class="token punctuation">(</span>
    dep<span class="token punctuation">.</span>shuffleHandle<span class="token punctuation">,</span> split<span class="token punctuation">.</span>index<span class="token punctuation">,</span> split<span class="token punctuation">.</span>index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> context<span class="token punctuation">,</span> metrics<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>Iterator<span class="token punctuation">[</span><span class="token punctuation">(</span>K<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>在 compute 中并没有从依赖中取出迭代器，而是调用了 ShuffleManager#getReader 方法，这是因为 combineByKey 是做分区操作的，所以要将相同 key 的数据通过网络发送到不同的机器上，其实就是 Map-Reduce 计算引擎的 shuffle 过程，这里也是一样的，这也是 ShuffleRDD 名称的由来。</p> 
<p>paritition 的特性：</p> 
<ol><li>parttion 特性，在 compute 函数中，使用 ShuffleManager 拿到 shuffle 到本分区的数据。这里是根据 key 进行了重新的分区</li><li>compute 的特性，ShuffleRDD 的计算函数是封装在了 aggregator 成员变量了，而 aggregator 又被保存到了ShuffleDependency 中，其实是在 BlockStoreShuffleReader 中调用了 combinerBykey 中的我们自定义的函数。</li><li>依赖的是 ShuffleDependency ，就是宽依赖。</li><li>key-value RDD 的特性 ，其实就是 PairRDDFunction 的隐式转化，在 reduceByKey 中体现的比较明显。</li><li>preferedLocation 还是没有找对应的逻辑。</li></ol> 
<p>下面以图的方式来总结一下，HadoopRDD、MapPartitionsRDD、ShuffleRDD 这三个 RDD 在 word count 这个例子中的对应关系。</p> 
<p><img src="https://images2.imgbox.com/8e/62/a6uhkeWO_o.png" alt="wordcount的 RDD 结构图"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6c140c1caa74b06d10315f34fa8f060e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数学建模——蒙特卡洛法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7b489c827a2972952fce4c5338c63d94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Http 请求状态码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>