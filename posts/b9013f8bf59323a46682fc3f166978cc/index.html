<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[论文精读]Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[论文精读]Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection" />
<meta property="og:description" content="论文网址：[2304.08876] 用于定向微小目标检测的动态粗到细学习 (arxiv.org)
论文代码：https://github.com/ChaselTsui/mmrotate-dcfl
英文是纯手打的！论文原文的summarizing and paraphrasing。可能会出现难以避免的拼写错误和语法错误，若有发现欢迎评论指正！文章偏向于笔记，谨慎食用
1. 省流版 1.1. 心得 （1）为什么学脑科学的我要看这个啊？愿世界上没有黑工
（2）最开始写小标题的时候就发现了，分得好细啊，好感度&#43;&#43;
（3）作为一个外行人，这文章感觉提出了好多东西
1.2. 论文总结图
2. 论文逐段精读 2.1. Abstract ①Extreme geometric shapes (tiny) and finite features (few pixels) of tiny rotating objects will cause serious mismatch (inaccurate positional prior?) and imbalance (inaccurate positive sample features?) issues
②They proposed dynamic prior and coarse-to-fine assigner, called DCFL
posterior adj.在后部的;在后面的 n.臀部;屁股
2.2. Introduction ①Oriented bounding box greatly eliminates redundant background area, especially in aerial images" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/b9013f8bf59323a46682fc3f166978cc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-14T21:34:16+08:00" />
<meta property="article:modified_time" content="2024-03-14T21:34:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[论文精读]Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p>论文网址：<a href="https://arxiv.org/abs/2304.08876" rel="nofollow" title="[2304.08876] 用于定向微小目标检测的动态粗到细学习 (arxiv.org)">[2304.08876] 用于定向微小目标检测的动态粗到细学习 (arxiv.org)</a></p> 
<p>论文代码：<a href="https://github.com/ChaselTsui/mmrotate-dcfl" title="https://github.com/ChaselTsui/mmrotate-dcfl">https://github.com/ChaselTsui/mmrotate-dcfl</a></p> 
<p>英文是纯手打的！论文原文的summarizing and paraphrasing。可能会出现难以避免的拼写错误和<a href="https://so.csdn.net/so/search?q=%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF&amp;spm=1001.2101.3001.7020" title="语法错误">语法错误</a>，若有发现欢迎评论指正！文章偏向于笔记，谨慎食用</p> 
<p></p> 
<h2>1. 省流版</h2> 
<h3>1.1. 心得</h3> 
<p>（1）为什么学脑科学的我要看这个啊？愿世界上没有黑工</p> 
<p>（2）最开始写小标题的时候就发现了，分得好细啊，好感度++</p> 
<p>（3）作为一个外行人，这文章感觉提出了好多东西</p> 
<p></p> 
<p>1.2. 论文总结图</p> 
<p></p> 
<h2>2. 论文逐段精读</h2> 
<h3>2.1. Abstract</h3> 
<p>        ①Extreme geometric shapes (tiny) and finite features (few pixels) of tiny rotating objects will cause serious mismatch (inaccurate positional prior?) and imbalance (inaccurate positive sample features?) issues</p> 
<p>        ②They proposed dynamic prior and coarse-to-fine assigner, called DCFL</p> 
<p></p> 
<p>posterior  adj.在后部的;在后面的  n.臀部;屁股</p> 
<p></p> 
<h3>2.2. Introduction</h3> 
<p>        ①Oriented bounding box greatly eliminates redundant background area, especially in aerial images</p> 
<p>        ②Comparison figure:</p> 
<p class="img-center"><img alt="" height="338" src="https://images2.imgbox.com/34/00/A1ShFU5v_o.png" width="532"></p> 
<p>where M* denotes matching function;</p> 
<p>green, blue and red boxes are true positive, false positive, and false negative predictions respectively,</p> 
<p>the left figure set is static and the right is dynamic</p> 
<p>        ③Figure of mismatch and imbalance issues:</p> 
<p class="img-center"><img alt="" height="246" src="https://images2.imgbox.com/a9/60/12KT0xUX_o.png" width="528"></p> 
<p>each point in the left figure denotes a prior location（<span style="color:#be191c;">先验打那么多个点啊...而且为啥打得那么整齐，这是什么one-stage吗</span>）</p> 
<p><span style="color:#be191c;">饼状图是说当每个框都是某个角度的时候吗？当每个框都不旋转的时候阳性样本平均数量是5.2？还是说饼状图的意思是自由旋转，某个特定角度的框的阳性样本是多少多少？这个饼状图并没有横向比较诶，只有这张图自己内部比较。</span></p> 
<p>柱状图是锚框大小不同下平均阳性</p> 
<p>        ④They introduce dynamic Prior Capturing Block (PCB) as their prior method. Based on this, they further utilize Cross-FPN-layer Coarse Positive Sample (CPS) to assign labels. After that, they reorder these candidates by prediction (posterior), and present gt by finer Dynamic Gaussian Mixture Model (DGMM)</p> 
<p></p> 
<p>eradicate  vt.根除;消灭;杜绝  n.根除者;褪色灵</p> 
<p></p> 
<p>2.3. Related Work</p> 
<p>2.3.1. Oriented Object Detection</p> 
<p>（1）Prior for Oriented Objects</p> 
<p>（2）Label Assignment</p> 
<p>2.3.2. Tiny Object Detection</p> 
<p>（1）Multi-scale Learning</p> 
<p>（2）Label Assignment</p> 
<p>（3）Context Information</p> 
<p>（4）Feature Enhancement</p> 
<p></p> 
<h3>2.4. Method</h3> 
<p>（1）Overview</p> 
<p>        ①For a set of dense prior <img alt="P\in\mathbb{R}^{W\times H\times C}" class="mathcode" src="https://images2.imgbox.com/87/b3/EYyTZ3b8_o.png">, where <img alt="W" class="mathcode" src="https://images2.imgbox.com/0f/ad/l3KmDrfa_o.png"> denotes width, <img alt="H" class="mathcode" src="https://images2.imgbox.com/a3/23/8cD9Vr93_o.png"> denotes height and <img alt="C" class="mathcode" src="https://images2.imgbox.com/63/09/IxSV5wBF_o.png"> denotes the number of shape information（<span style="color:#be191c;">什么东西啊，是那些点吗</span>）, mapping it to <img alt="D" class="mathcode" src="https://images2.imgbox.com/81/52/lehWRia6_o.png"> by Deep Neural Network (DNN):</p> 
<p style="text-align:center;"><img alt="D=\mathrm{DNN}_{h}(P)" class="mathcode" src="https://images2.imgbox.com/46/35/F6uxh232_o.png"></p> 
<p>where <img alt="\mathrm{DNN}_{h}" class="mathcode" src="https://images2.imgbox.com/d8/0b/5gpK7cPN_o.png"> represents the detection head（<span style="color:#be191c;">探测头...外行不太懂，感觉也就是一个函数嘛？</span>）;</p> 
<p>one part <img alt="D_{cls}\in\mathbb{R}^{W\times H\times A}" class="mathcode" src="https://images2.imgbox.com/5b/d4/6R6EqbQI_o.png"> in <img alt="D" class="mathcode" src="https://images2.imgbox.com/f5/b0/EGs4gj83_o.png"> denotes the classification scores, where <img alt="A" class="mathcode" src="https://images2.imgbox.com/38/36/KovJ0wpP_o.png"> means the class number（<span style="color:#be191c;">更被认为是阳性的样本那层的<img alt="W\times H" class="mathcode" src="https://images2.imgbox.com/17/c8/Ux5nII51_o.png">里的数据会更大吗</span>）;</p> 
<p>one part <img alt="D_{reg}\in\mathbb{R}^{W\times H\times B}" class="mathcode" src="https://images2.imgbox.com/9d/dc/etUmxYOz_o.png"> in <img alt="D" class="mathcode" src="https://images2.imgbox.com/a9/36/VU64NxEe_o.png"> denotes the classification scores, where <img alt="B" class="mathcode" src="https://images2.imgbox.com/a7/46/hsoixdOP_o.png"> means the box parameter number（<span style="color:#494949;">查宝说是w, h, x, y, a之类的是box parameter</span>）</p> 
<p>        ②In static methods, the pos labels assigned for <img alt="P" class="mathcode" src="https://images2.imgbox.com/5a/ce/ZSC5ue1P_o.png"> is <img alt="G=\mathcal{M}_{s}(P,GT)" class="mathcode" src="https://images2.imgbox.com/b4/61/LAQmoAxb_o.png"></p> 
<p>        ③In dynamic methods, the pos labels set <img alt="G" class="mathcode" src="https://images2.imgbox.com/7a/28/vklU4nzP_o.png"> integrate posterior information: <img alt="G={\mathcal M}_{d}(P,D,GT)" class="mathcode" src="https://images2.imgbox.com/a7/26/Iyxx59LB_o.png"></p> 
<p>        ④The loss function:</p> 
<p style="text-align:center;"><img alt="\mathcal{L}=\sum_{i=1}^{N_{pos}}\mathcal{L}_{pos}(D_{i},G_{i})+\sum_{j=1}^{N_{neg}}\mathcal{L}_{neg}(D_{j},y_{j})" class="mathcode" src="https://images2.imgbox.com/cf/51/rJ5C3stM_o.png"></p> 
<p>where <img alt="N_{pos}" class="mathcode" src="https://images2.imgbox.com/69/1e/K9YfhCdV_o.png"> and <img alt="N_{neg}" class="mathcode" src="https://images2.imgbox.com/77/83/GqpJKW2f_o.png"> represent the number of positive and negative samples, <img alt="y_i" class="mathcode" src="https://images2.imgbox.com/41/f9/YTswGlZP_o.png"> is the neg labels set</p> 
<p>        ⑤Modelling <img alt="D" class="mathcode" src="https://images2.imgbox.com/fd/6d/hbmJdSrS_o.png">, <img alt="{\mathcal M}_{d}" class="mathcode" src="https://images2.imgbox.com/7d/2d/rEBoLT7v_o.png"> and <img alt="GT" class="mathcode" src="https://images2.imgbox.com/ea/c7/R7gwRa3z_o.png">:</p> 
<p style="text-align:center;"><img alt="\tilde{D}=\mathrm{DNN}_{h}(\underbrace{\mathrm{DNN}_{p}(P)}_{\text{Dynamic Prior}\hat{P}})" class="mathcode" src="https://images2.imgbox.com/42/ec/ClwH8kfL_o.png"></p> 
<p style="text-align:center;"><img alt="\tilde{G}=\mathcal{M}_{d}(\mathcal{M}_{s}(\tilde{P},GT),\tilde{GT})" class="mathcode" src="https://images2.imgbox.com/62/e0/Q2DdtvuM_o.png"></p> 
<p style="text-align:center;"><img alt="\mathcal{L}=\sum_{i=1}^{\hat{N}_{pos}}\mathcal{L}_{pos}(\tilde{D}_{i},\tilde{G}_{i})+\sum_{j=1}^{\tilde{N}_{neg}}\mathcal{L}_{neg}(\tilde{D}_{j},y_{j})" class="mathcode" src="https://images2.imgbox.com/8f/4f/OezFsVoZ_o.png"></p> 
<p></p> 
<h4>2.4.1. Dynamic Prior</h4> 
<p>        ①Flexibility may alleviate mismatch problem</p> 
<p>        ②Each prior represents a feature point</p> 
<p>        ③The structure of Prior Capturing Block (PCB):</p> 
<p class="img-center"><img alt="" height="224" src="https://images2.imgbox.com/80/9c/yADjcEDB_o.png" width="801"></p> 
<p>the surrounding information is considered by dilated convolution. Then caputure dynamic prior by Deformable Convolution Network (DCN). Moreover, using the offset learned from the regression branch to guide feature extraction in the classification branch and improve alignment between the two tasks.</p> 
<p>        ④To achieve dynamic prior capturing, initializing each prior loaction <img alt="\mathbf{p}(x,y)" class="mathcode" src="https://images2.imgbox.com/81/68/gLIr1stD_o.png"> by each feature point’s spatial location <img alt="\mathbf{s}" class="mathcode" src="https://images2.imgbox.com/a3/a3/1V8qa3Us_o.png">. In each iteration, capture the offset set of each prior position <img alt="\Delta \mathbf{o}" class="mathcode" src="https://images2.imgbox.com/5a/ed/UiF0t108_o.png"> to update <img alt="\mathbf{s}" class="mathcode" src="https://images2.imgbox.com/17/09/eJ57cqIV_o.png">:</p> 
<p style="text-align:center;"><img alt="\tilde{\mathbf{s}}=\mathbf{s}+st\sum_{i=1}^{n}\Delta\mathbf{o}_{i}/2n" class="mathcode" src="https://images2.imgbox.com/b3/83/b9EcluxN_o.png"></p> 
<p>where <img alt="st" class="mathcode" src="https://images2.imgbox.com/3c/3d/xUlgRHjQ_o.png"> denotes the stride of feature map, <img alt="n" class="mathcode" src="https://images2.imgbox.com/0a/17/9C0oxbEt_o.png"> denotes the number of offsets;</p> 
<p>2D Gaussian distribution <img alt="\mathcal{N}_{p}(\boldsymbol{\mu}_{p},\boldsymbol{\Sigma}_{p})" class="mathcode" src="https://images2.imgbox.com/ee/21/cBY5W1AG_o.png"> is regarded as the prior distribution;</p> 
<p>动态的<img alt="\tilde{\mathbf{s}}" class="mathcode" src="https://images2.imgbox.com/6f/40/QVpdGokS_o.png">作为高斯的平均向量<img alt="\boldsymbol{\mu}_{p}" class="mathcode" src="https://images2.imgbox.com/be/b9/IUC3zoyw_o.png">（<span style="color:#be191c;">啥玩意儿？？</span>）;</p> 
<p>        ⑤Presetting a square <img alt="\left ( w,h,\theta \right )" class="mathcode" src="https://images2.imgbox.com/1a/e9/t6TUjkER_o.png"> on each feature point</p> 
<p>        ⑥The co-variance matrix:</p> 
<p style="text-align:center;"><img alt="\Sigma_p=\begin{bmatrix}\cos\theta&amp;-\sin\theta\\\sin\theta&amp;\cos\theta\end{bmatrix}\begin{bmatrix}\frac{w^2}{4}&amp;0\\0&amp;\frac{h^2}{4}\end{bmatrix}\begin{bmatrix}\cos\theta&amp;\sin\theta\\-\sin\theta&amp;\cos\theta\end{bmatrix}\\\\ =\begin{bmatrix}\cos\theta&amp;-\sin\theta\\\sin\theta&amp;\cos\theta\end{bmatrix}\begin{bmatrix}\frac{w}{2}&amp;0\\0&amp;\frac{h}{2}\end{bmatrix}\begin{bmatrix}\frac{w}{2}&amp;0\\0&amp;\frac{h}{2}\end{bmatrix}\begin{bmatrix}\cos\theta&amp;\sin\theta\\-\sin\theta&amp;\cos\theta\end{bmatrix}\\\\ =RR^T" class="mathcode" src="https://images2.imgbox.com/eb/c0/pXUKfEp9_o.png"></p> 
<p></p> 
<p>dilate  v.扩张;(使)膨胀;扩大    deformable  adj.可变形的；应变的；易变形的</p> 
<p></p> 
<h4>2.4.2. Coarse Prior Matching</h4> 
<p>        ①For prior, limiting <img alt="gt" class="mathcode" src="https://images2.imgbox.com/ad/fa/ut0waymb_o.png"> to a single FPN may cause sub-optimal layer selection and releasing <img alt="gt" class="mathcode" src="https://images2.imgbox.com/c5/0c/1sNku2A1_o.png"> to all layers may cause slow convergence</p> 
<p>        ②Therefore, they propose Cross-FPN-layer Coarse Positive Sample (CPS) candidates, expanding candidate layers to <img alt="gt" class="mathcode" src="https://images2.imgbox.com/d9/47/XuapD9hY_o.png">'s nearby spatial location and adjacent FPN layers</p> 
<p>        ③Generalized Jensen-Shannon Divergence (GJSD) constructs CPS between <img alt="\mathcal{N}_{p}(\boldsymbol{\mu}_{p},\boldsymbol{\Sigma}_{p})" class="mathcode" src="https://images2.imgbox.com/d1/68/lpwwLJy4_o.png"> and <img alt="\mathcal{N}_{g}(\boldsymbol{\mu}_{g},\boldsymbol{\Sigma}_{g})" class="mathcode" src="https://images2.imgbox.com/3c/06/FSfnvsgp_o.png">:</p> 
<p style="text-align:center;"><img alt="\mathrm{GJSD}(\mathcal{N}_{p},\mathcal{N}_{g})=(1-\alpha)\mathrm{KL}(\mathcal{N}_{\alpha},\mathcal{N}_{p})+\alpha\mathrm{KL}(\mathcal{N}_{\alpha},\mathcal{N}_{g})" class="mathcode" src="https://images2.imgbox.com/3c/8a/BlcV2Tyz_o.png"></p> 
<p style="text-align:center;"><img alt="\left\{\begin{matrix} \operatorname{KL}\left(P\left\|Q\right)\right. =\sum P\left(x\right)\log\frac{P\left(x\right)}{Q\left(x\right)} \\\\ \operatorname{KL}\left(P\left\|Q\right)\right) =\int P\left(x\right)\log\frac{P\left(x\right)}{Q\left(x\right)}dx \end{matrix}\right." class="mathcode" src="https://images2.imgbox.com/06/e9/oQ8CmwaD_o.png"></p> 
<p>which yields a closed-form solution;</p> 
<p>where <img alt="\Sigma_{\alpha}=(\Sigma_{p}\Sigma_{g})_{\alpha}^{\Sigma}=\left((1-\alpha)\Sigma_{p}^{-1}+\alpha\Sigma_{g}^{-1}\right)^{-1}" class="mathcode" src="https://images2.imgbox.com/49/03/eytudAUo_o.png">;</p> 
<p><img alt="\begin{aligned} \mu_{\alpha}&amp; =\left(\mu_{p}\mu_{g}\right)_{\alpha}^{\mu} \\ &amp;=\Sigma_{\alpha}\left((1-\alpha)\Sigma_{p}^{-1}\mu_{p}+\alpha\Sigma_{g}^{-1}\mu_{g}\right) \end{aligned}" class="mathcode" src="https://images2.imgbox.com/06/59/n2TTPime_o.png"></p> 
<p>and due to the homogeneity of <img alt="\mathcal{N}_{p}" class="mathcode" src="https://images2.imgbox.com/b1/42/ghZjCQ06_o.png"> and <img alt="\mathcal{N}_{g}" class="mathcode" src="https://images2.imgbox.com/60/fa/weQgIMuU_o.png">, <img alt="\alpha =0.5" class="mathcode" src="https://images2.imgbox.com/35/42/wv3VvZyK_o.png"></p> 
<p>        ④Choosing top <img alt="K" class="mathcode" src="https://images2.imgbox.com/4e/fe/vwXTRZBA_o.png"> prior with highest GJSD for each <img alt="gt" class="mathcode" src="https://images2.imgbox.com/3e/a4/6p9oW8lq_o.png">（选差异最大的那些）</p> 
<p></p> 
<h4>2.4.3. Finer Dynamic Posterior Matching</h4> 
<p>        ①Two main steps are contained in this section, a posterior re-ranking strategy and a Dynamic Gaussian Mixture Model (DGMM) constraint</p> 
<p>        ②The Possibility of becoming True predictions (PT) of the <img alt="i^{th}" class="mathcode" src="https://images2.imgbox.com/09/c8/PkvaaV92_o.png"> sample <img alt="D_i" class="mathcode" src="https://images2.imgbox.com/5a/73/K5wT95En_o.png"> is:</p> 
<p style="text-align:center;"><img alt="PT_i=\frac{1}{2}Cls(D_i)+\frac{1}{2}IoU(D_i,gt_i)" class="mathcode" src="https://images2.imgbox.com/20/f1/kSH20h9D_o.png"></p> 
<p>choosing top <img alt="Q" class="mathcode" src="https://images2.imgbox.com/21/dd/7xNRzO8X_o.png"> samples with the highest scores as Medium Positive Sample (MPS) candidates</p> 
<p>        ③They apply DGMM, which contains geometry center and semantic center in one object, to filter far samples</p> 
<p>        ④For specific instance <img alt="gt_i" class="mathcode" src="https://images2.imgbox.com/8a/01/qh1X58k1_o.png">, the mean vector <img alt="\boldsymbol{\mu}_{i,1}" class="mathcode" src="https://images2.imgbox.com/46/ef/ORgb8NEw_o.png"> of the first Gaussian is the geometry center <img alt="\left ( cx_i,cy_i \right )" class="mathcode" src="https://images2.imgbox.com/e4/68/XIltL86o_o.png">, the deduced <img alt="\boldsymbol{\mu}_{i,2}" class="mathcode" src="https://images2.imgbox.com/d5/70/jF2e9oR4_o.png"> in MPS denotes semantic center <img alt="\left ( sx_i,sy_i \right )" class="mathcode" src="https://images2.imgbox.com/3c/e9/1OetYI6B_o.png"></p> 
<p>        ⑤Parameterizing a instance:</p> 
<p style="text-align:center;"><img alt="DGMM_i(s|x,y)=\sum_{m=1}^2w_{i,m}\sqrt{2\pi|\Sigma_{i,m}|}\mathcal{N}_{i,m}(\mu_{i,m},\Sigma_{i,m})" class="mathcode" src="https://images2.imgbox.com/65/86/8x5skx50_o.png"></p> 
<p>where <img alt="w_{i,m}" class="mathcode" src="https://images2.imgbox.com/93/88/TVQwb0Ax_o.png"> denotes weight of each Gaussian distribution and their summation is 1;</p> 
<p><img alt="\mu_{i,m}" class="mathcode" src="https://images2.imgbox.com/5a/4f/kETMvPPK_o.png"> equals to <img alt="gt" class="mathcode" src="https://images2.imgbox.com/65/d3/PV7M7Qls_o.png">'s <img alt="\boldsymbol{\Sigma}_{g}" class="mathcode" src="https://images2.imgbox.com/87/ff/tCMYuWch_o.png">（<span style="color:#be191c;">什么啊这是，但是m可以等于1或者2诶，那你g的协方差不就又是语义中心又是几何中心了吗</span>）</p> 
<p>        ⑥For any <img alt="DGMM(s|MPS)&lt;e^{-g}" class="mathcode" src="https://images2.imgbox.com/94/b3/tsc6kwMp_o.png">, setting negative masks</p> 
<p></p> 
<h3>2.5.  Experiments</h3> 
<h4>2.5.1. Datasets</h4> 
<p>        ①Datasets: DOTAv1.0 /v1.5/v2.0, DIOR-R, VisDrone, and MS COCO</p> 
<p>        ②Ablation dataset: DOTA-v2.0 with the most numbet of tiny objects</p> 
<p>        ③Comparing dataset: DOTA-v1.0, DOTAv1.5, DOTA-v2.0, VisDrone2019, MS COCO and DIOR-R</p> 
<p></p> 
<h4>2.5.2. Implementation Details</h4> 
<p>        ①Batch size: 4</p> 
<p>        ②Framework based: MMDetection and MMRotate</p> 
<p>        ③Backbone: ImageNet pre-trained models</p> 
<p>        ④Learning rate: 0.005 with SGD</p> 
<p>        ⑤Momentum: 0.9</p> 
<p>        ⑥Weight decay: 0.0001</p> 
<p>        ⑦Default backbone: ResNet-50 with FPN</p> 
<p>        ⑧Loss: Focal loss for classifying and IoU loss for regression</p> 
<p>        ⑨Data augmentation: random flipping</p> 
<p>        ⑩On DOTA-v1.0 and DOTA-v2.0, using official setting to crop images to 1024×1024. The overlap is 200 and epoch is 12</p> 
<p>        ⑪On other datasets, setting the input size to 1024 × 1024 (overlap 200), 800 × 800, 1333 × 800, and 1333×800 for DOTA-v1.5, DIOR-R, VisDrone, and COCO respectively. Epoch is set as  40, 40, 12, and 12 on the DOTA-v1.5, DIOR-R, COCO, and VisDrone</p> 
<p></p> 
<h4>2.5.3. Main Results</h4> 
<p>（1）Results on DOTA series</p> 
<p>        ①Comparison table on DOTA-v2.0 OBB:</p> 
<p class="img-center"><img alt="" height="360" src="https://images2.imgbox.com/a9/d3/d1T31kce_o.png" width="837"></p> 
<p>where the red ones are the best and the blue ones are the second best performance on each metric</p> 
<p>        ②Comparison table on DOTA-v1.0 OBB:</p> 
<p class="img-center"><img alt="" height="104" src="https://images2.imgbox.com/6a/8d/GpkwM9y8_o.png" width="510"></p> 
<p>        ③Comparison table on DOTA-v1.5 OBB:</p> 
<p class="img-center"><img alt="" height="156" src="https://images2.imgbox.com/4f/63/EEmMmyaK_o.png" width="510"></p> 
<p></p> 
<p>（2）Results on DIOR-R</p> 
<p>        ①Comparison table on DIOR-R:</p> 
<p class="img-center"><img alt="" height="106" src="https://images2.imgbox.com/5a/99/cvFiUU2w_o.png" width="502"></p> 
<p>        ②Results of typical tiny objects vehicle, bridge, and wind-mill:</p> 
<p class="img-center"><img alt="" height="111" src="https://images2.imgbox.com/2b/8a/uJhozNJJ_o.png" width="492"></p> 
<p></p> 
<p>（3）Results on HBB Datasets</p> 
<p>        ①Comparison table on VisDrone, MS COCO abd DOTA-v2.0 HBB:</p> 
<p class="img-center"><img alt="" height="107" src="https://images2.imgbox.com/23/d1/KGh6flfb_o.png" width="491"></p> 
<p></p> 
<h4>2.5.4. Ablation Study</h4> 
<p>（1）Effects of Individual Strategy</p> 
<p>        ①Employ prior on each feature point</p> 
<p>        ②Individual effectiveness:</p> 
<p class="img-center"><img alt="" height="150" src="https://images2.imgbox.com/3d/93/GVw5WU95_o.png" width="352"></p> 
<p></p> 
<p>（2）Comparisons of Different CPS</p> 
<p>        ①Ablation:</p> 
<p class="img-center"><img alt="" height="148" src="https://images2.imgbox.com/34/8f/Of4WLhM0_o.png" width="316"></p> 
<p></p> 
<p>（3）Fixed Prior and Dynamic Prior</p> 
<p>        ①Ablation:</p> 
<p class="img-center"><img alt="" height="118" src="https://images2.imgbox.com/07/36/60Iy1MRx_o.png" width="216"></p> 
<p></p> 
<p>（4）Detailed Design in PCB</p> 
<p>（5）Effects of Parameters</p> 
<p>2.6. Analysis</p> 
<p>（1）Reconciliation of imbalance problems</p> 
<p>（2）Visualization</p> 
<p>（3）Speed</p> 
<p>2.7. Conclusion</p> 
<p></p> 
<p>3. 知识补充</p> 
<p></p> 
<h2>4. Reference List</h2> 
<p>Xu, C. et al. (2023) 'Dynamic Coarse-to-Fine Learning for Oriented Tiny Object Detection', <em>CVPR</em>. doi: <a href="https://doi.org/10.48550/arXiv.2304.08876" rel="nofollow" title="https://doi.org/10.48550/arXiv.2304.08876">https://doi.org/10.48550/arXiv.2304.08876</a></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d76929a4768430d1fe560789cbd0167a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JVM基础篇</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9eb11b81b9bd192fa6a714da370c578f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">市场复盘总结 20240314</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>