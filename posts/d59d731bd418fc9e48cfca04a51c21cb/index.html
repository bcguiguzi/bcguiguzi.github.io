<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DALL·E 3:Improving Image Generation with Better Captions - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="DALL·E 3:Improving Image Generation with Better Captions" />
<meta property="og:description" content=" 论文链接：https://cdn.openai.com/papers/dall-e-3.pdf
DALLE3 API：https://github.com/Agora-X/Dalle3
官网链接：添加链接描述
DALLE3讲解视频：B站视频
推荐DALLE2的讲解视频：B站：跟李沐学AI 之前精讲的DALLE2论文
北理&amp;上海AI Lab&amp;清华提出 Mini DALL·E 3：https://arxiv.org/pdf/2310.07653.pdf
code：https://github.com/Zeqiang-Lai/Mini-DALLE3
要点分析
文章主要在讲：通过更好的文本标注（Better Captions），提升图像生成质量 1. 摘要（Abstract） 解决问题：因为数据比较noise，很难按照prompt生成需要的图片方法/贡献：提出image captioner（图片标注器），生成图像精准的标注，去训练模型 3. 文章主体 3.1. 数据生成方法 两种标注模式： 1.短标注：只描述主要物体，主体详细标注：主体、环境、背景、文字、风格等 Clip scores高于短标注 生成标注&#43;原始文本标注的比例【意思train的时候加入生成标签，test的时候不加入呗？】 混合原因：生成文本是基于数据的模式，用户的文本（原始标注）有自己的风格，原始标注相当于正则95%&gt; 90% &gt; 80%，但是不是100%最好
用户的prompt简短，不能充分发挥模型能力 用GPT扩写用户的prompt
3.2. 评估方式 自动评估： Clip scores：用Ms COCO的caption生成图片，然后用Clip scores去评估图片文本之间的匹配程度Drawbench：Images提出的比较全的评测prompts，然后用GPT-V（多模态）来评估生成突破和Prompts的匹配度（生成模型评估生成模型hh）T2l-Compbench：与Drawbench类似，区别在于GPT-V换成VQA 人工评估： Prompt fllowing：Prompts和图像匹配程度style：图片质量，评估者是看不到Prompts，直接看两张图片哪个更好coherence：观察不合理的结构，虚幻的场景人工评估打低分，作者换成用MS COCO的Caption生成的图像去做评估 4. 实验效果 评估结果：DALL-E 3 &gt; Midjourney 5.2 &gt; Stable Diffusion XL &gt; DALL-E 2 5. 总结 方法局限性：
位置关系不准确文字的生成不行：因为T5 text encoder的局限性，它会把用户的prompts分隔开，整体把握小 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/d59d731bd418fc9e48cfca04a51c21cb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-27T21:44:19+08:00" />
<meta property="article:modified_time" content="2024-02-27T21:44:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DALL·E 3:Improving Image Generation with Better Captions</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>论文链接：<a href="https://cdn.openai.com/papers/dall-e-3.pdf" rel="nofollow">https://cdn.openai.com/papers/dall-e-3.pdf</a><br> DALLE3 API：<a href="https://github.com/Agora-X/Dalle3">https://github.com/Agora-X/Dalle3</a><br> 官网链接：<a href="https://openai.com/dall-e-3" rel="nofollow">添加链接描述</a></p> 
</blockquote> 
<blockquote> 
 <p>DALLE3讲解视频：<a href="https://www.bilibili.com/video/BV1jz4y1P7hG/?spm_id_from=333.788&amp;vd_source=ae1cee5304fd2df54b474c255024da42" rel="nofollow">B站视频</a><br> 推荐DALLE2的讲解视频：<a href="https://www.bilibili.com/video/BV17r4y1u77B/?spm_id_from=333.999.0.0&amp;vd_source=3935ff8554b8158fd7f238fe1d28009e" rel="nofollow">B站：跟李沐学AI 之前精讲的DALLE2论文</a></p> 
</blockquote> 
<blockquote> 
 <p>北理&amp;上海AI Lab&amp;清华提出 Mini DALL·E 3：<a href="https://arxiv.org/pdf/2310.07653.pdf" rel="nofollow">https://arxiv.org/pdf/2310.07653.pdf</a><br> code：<a href="https://github.com/Zeqiang-Lai/Mini-DALLE3">https://github.com/Zeqiang-Lai/Mini-DALLE3</a></p> 
</blockquote> 
<p>要点分析</p> 
<pre><code>文章主要在讲：通过更好的文本标注（Better Captions），提升图像生成质量
</code></pre> 
<p><img src="https://images2.imgbox.com/68/7d/QLHwUN2F_o.png" alt="在这里插入图片描述" width="500"><br> <img src="https://images2.imgbox.com/e8/f2/CESwxcMz_o.png" alt="在这里插入图片描述" width="700"></p> 
<h2><a id="1_Abstract_17"></a>1. 摘要（Abstract）</h2> 
<ul><li>解决问题：因为数据比较noise，很难按照prompt生成需要的图片</li><li>方法/贡献：提出image captioner（图片标注器），生成图像精准的标注，去训练模型</li></ul> 
<h2><a id="3__21"></a>3. 文章主体</h2> 
<h3><a id="31__22"></a>3.1. 数据生成方法</h3> 
<ul><li>两种标注模式： 
  <ul><li>1.短标注：只描述主要物体，主体</li><li>详细标注：主体、环境、背景、文字、风格等 
    <ul><li>Clip scores高于短标注</li></ul> </li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/39/5d/GYDx0FAl_o.png" alt="在这里插入图片描述" width="600"></p> 
<p><img src="https://images2.imgbox.com/03/d6/87TVK8R8_o.png" alt="在这里插入图片描述" width="700"></p> 
<ul><li>生成标注+原始文本标注的比例【意思train的时候加入生成标签，test的时候不加入呗？】 
  <ul><li>混合原因：生成文本是基于数据的模式，用户的文本（原始标注）有自己的风格，原始标注相当于正则</li><li>95%&gt; 90% &gt; 80%，但是不是100%最好<br> <img src="https://images2.imgbox.com/86/e0/PXRW9OwC_o.png" alt="在这里插入图片描述" width="600"></li></ul> </li><li>用户的prompt简短，不能充分发挥模型能力 
  <ul><li>用GPT扩写用户的prompt<br> <img src="https://images2.imgbox.com/a4/ca/lOSsQfRQ_o.png" alt="在这里插入图片描述" width="600"></li></ul> </li></ul> 
<h3><a id="32__39"></a>3.2. 评估方式</h3> 
<p><img src="https://images2.imgbox.com/41/2e/a0xeQeF1_o.png" alt="在这里插入图片描述" width="600"></p> 
<ul><li>自动评估： 
  <ul><li>Clip scores：用Ms COCO的caption生成图片，然后用Clip scores去评估图片文本之间的匹配程度</li><li>Drawbench：Images提出的比较全的评测prompts，然后用GPT-V（多模态）来评估生成突破和Prompts的匹配度（生成模型评估生成模型hh）</li><li>T2l-Compbench：与Drawbench类似，区别在于GPT-V换成VQA</li></ul> </li><li>人工评估： 
  <ul><li>Prompt fllowing：Prompts和图像匹配程度</li><li>style：图片质量，评估者是看不到Prompts，直接看两张图片哪个更好</li><li>coherence：观察不合理的结构，虚幻的场景人工评估打低分，作者换成用MS COCO的Caption生成的图像去做评估</li></ul> </li></ul> 
<p><img src="https://images2.imgbox.com/84/8d/4SQJPQZw_o.png" alt="在这里插入图片描述" width="600"></p> 
<h2><a id="4__54"></a>4. 实验效果</h2> 
<ul><li>评估结果：DALL-E 3 &gt; Midjourney 5.2 &gt; Stable Diffusion XL &gt; DALL-E 2</li></ul> 
<h2><a id="5__57"></a>5. 总结</h2> 
<p>方法局限性：</p> 
<ul><li>位置关系不准确</li><li>文字的生成不行：因为T5 text encoder的局限性，它会把用户的prompts分隔开，整体把握小</li></ul> 
<p><img src="https://images2.imgbox.com/d8/e6/1moOkh8n_o.png" alt="在这里插入图片描述" width="600"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0c4c09bd1bdf8ed2347da4710b2c7e62/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【JAVA】java项目提交到gitee哪些文件可以不提交</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/051e2ca73d5f239cdc7cb4f52d2226fb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">105. replace( )函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>