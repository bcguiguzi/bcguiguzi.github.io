<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>nnUNet推理与预测（手把手一步一步实现。接上文用自己的数据训练） - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="nnUNet推理与预测（手把手一步一步实现。接上文用自己的数据训练）" />
<meta property="og:description" content="如上图所示，当我们训练了大概几轮之后会在nnUNet_trained_models文件下生成nnUNet以及2d的模型文件，我们可以看到fold_4里面会有model_best.model，这个模型文件就是我们训练好的模型了，我们也可以通过同级目录下的progress.png，来查看loss函数的变化。接上文有几点要注意的情况，首先nnunet并不需要手动调学习率和训练轮数（这里nnunet默认是要训练1000轮），学习率的调整是用的损失函数的加权平均值使用的损失函数来对其进行更正的。还有就是nnunet的loss函数默认是趋向-1的，也就是说在训练的过程中，我们通过每轮训练的日志可以查看到每轮的loss函数，这个数值应该是负数，而且越趋向于-1，效果越好。(后期发现虽然第一次趋向-1但是大概率是我第一次显卡的问题，显卡算力和显存都会影响，后期在服务器上运行发现损失函数趋势正常（好像服务器也是趋向-1 但是不重要loss只要下降了就行），但是从效果来看，损失函数趋势对影响不是很大，这边建议还是在服务器上跑，当时我用了400张左右采集到的数据，最后效果还不错，效果要好于UNet网络。对于损失函数还想说的是，只要他的loss在下降就ok我们中途也可以通过生成的best_model来看一下当前训练轮数的效果怎么样 。)我们可以注意到我们选择使用的是V2也就是nnUNetTrainerV2训练方法，我们可以仔细查看这个py文件，大致说来就是他在V1的训练方法上进行了改进（深监督），想要具体的了解loss函数，我们可以通过这篇论文来了解”Focal Loss for Dense Object Detection“附上个论文加实现代码的链接🔗：Focal Loss for Dense Object Detection | Papers With Code#3 best model for Long-tail Learning on EGTEA (Average Precision metric)https://paperswithcode.com/paper/focal-loss-for-dense-object-detection#
言归正传，这里我附一张根据上一篇文章训练的loss结果：
可以看出接近1000epochs的时候loss不断的趋向于-1，如果你在训练的时候发现loss数值大于0而且没有趋向于-1的趋势，这可能因为GPU的原因，主要还是显存，官方推荐至少要8G，这里我在自己电脑上（4G，1650）修改过batchsize之后是可以训练的，但是我的电脑上给出的loss函数均大于0，而在服务器上运行（3090）的结果是越来越趋向于-1的，（显存一定要大！！还有预处理的时候要100G固态硬盘，固态硬盘是原论文中说到的，硬盘我没有受到影响，但是显存一定要大！！最少8G，不然没有效果）而且训练的效果也完全不一样，所以还是需要一个配置高的GPU去训练，毕竟nnunet从预训练开始就是对数据集进行大量的处理。其次有就是nnunet默认的batchsize是2，这里不建议再去减小batchsize（batchsize也不能调小，可以大但是不能小，确实可以自己改代码（这个代码很难去改，因为原论文不想你修改这个参数，我自己强制给改了为了测试，发现没有分割效果，所以说到这里就是在服务器上做就行！！）），找一个显存大的显卡这些问题都可以ignore。
中途可以用生成好的best_model检查一些效果，这个代码是：-chk model_best #应该是这个太久了有些忘记了，不对的话说一下我再看看。
预测的话把数据弄到数据的ts里。具体代码如果你做到这里肯定能知道的，我时间太久了忘记了。。
如果要fintune的话，load原模型，继续训练就好了。
差不多就这些吧。
如果损失函数趋势没有问题，那么我们只需要等待1000轮的训练即可。（当时是差不多500轮左右就拟合了，所以只训练了一半，效果还是ok的）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/94bc261262aebdbdc1cf255c79e7ad5b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-06T10:52:27+08:00" />
<meta property="article:modified_time" content="2022-07-06T10:52:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">nnUNet推理与预测（手把手一步一步实现。接上文用自己的数据训练）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/70/23/WTxU1hG3_o.png"></p> 
<p> 如上图所示，当我们训练了大概几轮之后会在nnUNet_trained_models文件下生成nnUNet以及2d的模型文件，我们可以看到fold_4里面会有model_best.model，这个模型文件就是我们训练好的模型了，我们也可以通过同级目录下的progress.png，来查看loss函数的变化。接上文有几点要注意的情况，首先nnunet并不需要手动调学习率和训练轮数（这里nnunet默认是要训练1000轮），学习率的调整是用的损失函数的加权平均值使用的损失函数来对其进行更正的。<span style="color:#fe2c24;"><strong>还有就是nnunet的loss函数默认是趋向-1的</strong>，也就是说在训练的过程中，我们通过每轮训练的日志可以查看到每轮的loss函数，这个数值应该是负数，而且越趋向于-1，效果越好。(</span><span style="color:#511b78;">后期发现虽然第一次趋向-1但是大概率是我第一次显卡的问题，显卡算力和显存都会影响，后期在服务器上运行发现损失函数趋势正常（好像服务器也是趋向-1 但是不重要loss只要下降了就行），但是从效果来看，损失函数趋势对影响不是很大，这边建议还是在服务器上跑，当时我用了400张左右采集到的数据，最后效果还不错，效果要好于UNet网络。对于损失函数还想说的是，只要他的loss在下降就ok我们中途也可以通过生成的best_model来看一下当前训练轮数的效果怎么样  。</span><span style="color:#fe2c24;">)</span>我们可以注意到我们选择使用的是V2也就是nnUNetTrainerV2训练方法，我们可以仔细查看这个py文件，大致说来就是他在V1的训练方法上进行了改进（深监督），想要具体的了解loss函数，我们可以通过这篇论文来了解”Focal Loss for Dense Object Detection“附上个论文加实现代码的链接🔗：<a class="has-card" href="https://paperswithcode.com/paper/focal-loss-for-dense-object-detection#" rel="nofollow" title="Focal Loss for Dense Object Detection | Papers With Code"><span class="link-card-box"><span class="link-title">Focal Loss for Dense Object Detection | Papers With Code</span><span class="link-desc">#3 best model for Long-tail Learning on EGTEA (Average Precision metric)</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/a1/58/0saeVRuu_o.png">https://paperswithcode.com/paper/focal-loss-for-dense-object-detection#</span></span></a></p> 
<p style="text-align:center;">言归正传，这里我附一张根据上一篇文章训练的loss结果：<img alt="" src="https://images2.imgbox.com/98/b9/JreHU2Re_o.png"></p> 
<p> 可以看出接近1000epochs的时候loss不断的趋向于-1，如果你在训练的时候发现loss数值大于0而且没有趋向于-1的趋势，这可能因为GPU的原因，主要还是显存，官方推荐至少要8G，这里我在自己电脑上（4G，1650）修改过batchsize之后是可以训练的，但是我的电脑上给出的loss函数均大于0，而在服务器上运行（3090）的结果是越来越趋向于-1的，（<span style="color:#fe2c24;">显存一定要大！！还有预处理的时候要100G固态硬盘，固态硬盘是原论文中说到的，硬盘我没有受到影响，但是显存一定要大！！最少8G，不然没有效果</span>）而且训练的效果也完全不一样，所以还是需要一个配置高的GPU去训练，毕竟nnunet从预训练开始就是对数据集进行大量的处理。其次有就是nnunet默认的batchsize是2，这里不建议再去减小batchsize（batchsize也不能调小，可以大但是不能小，确实可以自己改代码（这个代码很难去改，因为原论文不想你修改这个参数，我自己强制给改了为了测试，发现没有分割效果，所以说到这里就是在服务器上做就行！！）），找一个显存大的显卡这些问题都可以ignore。</p> 
<p>中途可以用生成好的best_model检查一些效果，这个代码是：-chk model_best #应该是这个太久了有些忘记了，不对的话说一下我再看看。</p> 
<p></p> 
<p>预测的话把数据弄到数据的ts里。具体代码如果你做到这里肯定能知道的，我时间太久了忘记了。。</p> 
<p>如果要fintune的话，load原模型，继续训练就好了。</p> 
<p>差不多就这些吧。</p> 
<p></p> 
<p>如果损失函数趋势没有问题，那么我们只需要等待1000轮的训练即可。（当时是差不多500轮左右就拟合了，所以只训练了一半，效果还是ok的）</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/96cb8e42a4a976a4d9000a73ca93abf5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java 的四种引用方式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/26da93e1270f0e340593be44299e92e8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">go 电脑屏幕截图，二维码识别 示例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>