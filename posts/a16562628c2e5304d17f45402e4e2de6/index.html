<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>1.搭建Kubernetes环境 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="1.搭建Kubernetes环境" />
<meta property="og:description" content="搭建Kubernetes环境 容器编排 有了docker的经验，我们可以轻松的使用容器实现应用的打包、分发。
但是想要将容器技术应用到大规模生产环境，还有更多的问题。容器解决了打包、分发。但是对于生产环境而言，我们还需要服务发现、负载均衡、扩容缩容等更高级的特性。
这些容器的管理、调度工作，就是容器编排Container Orchestration。
Kubernetes Kubernetes就是一个生产级别的容器编排平台和集群管理系统。
谷歌很早期（2002年前后）就开始了容器化的相关工作。从一开始谷歌就没有引入虚拟机，因为利用虚拟机隔离程序会造成资源的浪费，谷歌认为操作系统本身就应该提供程序隔离的能力。
谷歌自己有一套容器标准叫做lmctfy（Let Me Contain That For You）。2006年谷歌把一部分技术加入了Linux, 就是我们现在看到的cgroups控制群组（Control Groups，目前常用的简写为 cgroups），它与名称空间一样，都是直接由Linux内核提供的功能，用于隔离或者说分配并限制某个进程组能够使用的资源配额。
cgroups 项目最早是由Google的工程师在2006年发起的，当时取的名字就叫做“进程容器”（Process Containers），不过“容器”（Container）这个名词的定义在那时候还没有今天那么清晰，不同场景中常有不同的指向。到2007年这个项目才被重新命名为cgroups，在2008年1月合并到了2.6.24版的内核后正式对外发布。2008年8月Linux推出了自己的container LXC = namespace &#43; cgroups。早期的docker就是依赖于lxc技术
Google自己的容器编排系统叫做Borg。2008年，Google Cloud发展初期，google曾经想将容器技术推向市场，发布了Google App Engine，支持自动监控、serverless、自动扩容/缩容等云原生特性。但是市场并不接受。
直到2015年，业内普遍接受了docker等容器工具，Google才推出了开源版的Borg - Kubernetes系统。仅仅两年就打败了Docker Swarm，成为了容器编排领域的事实标准。
kubeadm 安装 cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system sudo apt install apt-transport-https ca-certificates curl sudo curl -s https://mirrors." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/a16562628c2e5304d17f45402e4e2de6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-18T16:46:36+08:00" />
<meta property="article:modified_time" content="2024-02-18T16:46:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">1.搭建Kubernetes环境</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Kubernetes_0"></a>搭建Kubernetes环境</h2> 
<h3><a id="_2"></a>容器编排</h3> 
<p>有了docker的经验，我们可以轻松的使用容器实现应用的打包、分发。</p> 
<p>但是想要将容器技术应用到大规模生产环境，还有更多的问题。容器解决了打包、分发。但是对于生产环境而言，我们还需要服务发现、负载均衡、扩容缩容等更高级的特性。</p> 
<p>这些容器的管理、调度工作，就是容器编排Container Orchestration。</p> 
<h3><a id="Kubernetes_10"></a>Kubernetes</h3> 
<p>Kubernetes就是一个生产级别的容器编排平台和集群管理系统。</p> 
<p>谷歌很早期（2002年前后）就开始了容器化的相关工作。从一开始谷歌就没有引入虚拟机，因为利用虚拟机隔离程序会造成资源的浪费，谷歌认为操作系统本身就应该提供程序隔离的能力。</p> 
<p>谷歌自己有一套容器标准叫做lmctfy（Let Me Contain That For You）。2006年谷歌把一部分技术加入了Linux, 就是我们现在看到的cgroups控制群组（Control Groups，目前常用的简写为 cgroups），它与名称空间一样，都是直接由Linux内核提供的功能，用于隔离或者说分配并限制某个进程组能够使用的资源配额。</p> 
<p>cgroups 项目最早是由Google的工程师在2006年发起的，当时取的名字就叫做“进程容器”（Process Containers），不过“容器”（Container）这个名词的定义在那时候还没有今天那么清晰，不同场景中常有不同的指向。到2007年这个项目才被重新命名为cgroups，在2008年1月合并到了2.6.24版的内核后正式对外发布。2008年8月Linux推出了自己的container LXC = namespace + cgroups。早期的docker就是依赖于lxc技术</p> 
<p>Google自己的容器编排系统叫做Borg。2008年，Google Cloud发展初期，google曾经想将容器技术推向市场，发布了Google App Engine，支持自动监控、serverless、自动扩容/缩容等云原生特性。但是市场并不接受。</p> 
<p>直到2015年，业内普遍接受了docker等容器工具，Google才推出了开源版的Borg - Kubernetes系统。仅仅两年就打败了Docker Swarm，成为了容器编排领域的事实标准。</p> 
<h3><a id="kubeadm_24"></a>kubeadm</h3> 
<h4><a id="_26"></a>安装</h4> 
<pre><code class="prism language-bash">
<span class="token function">cat</span> <span class="token operator">&lt;&lt;</span><span class="token string">EOF<span class="token bash punctuation"> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/modules-load.d/k8s.conf</span>
br_netfilter
EOF</span>


<span class="token function">cat</span> <span class="token operator">&lt;&lt;</span><span class="token string">EOF<span class="token bash punctuation"> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/sysctl.d/k8s.conf</span>
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF</span>
<span class="token function">sudo</span> <span class="token function">sysctl</span> <span class="token parameter variable">--system</span>

<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> apt-transport-https ca-certificates <span class="token function">curl</span>

<span class="token function">sudo</span> <span class="token function">curl</span> <span class="token parameter variable">-s</span> https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -

<span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/kubernetes.list <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main
EOF</span>

<span class="token comment"># install Kubernetes</span>
<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> kubeadm kubelet kubectl kubernetes-cni
<span class="token comment"># kubeadm is already the newest version (1.26.1-00).</span>
<span class="token comment"># kubectl is already the newest version (1.26.1-00).</span>
<span class="token comment"># kubelet is already the newest version (1.26.1-00).</span>
</code></pre> 
<h4><a id="kubeadm_init_55"></a>kubeadm init</h4> 
<pre><code class="prism language-bash"><span class="token comment"># kubeadm init</span>
kubeadm init --apiserver-advertise-address <span class="token variable"><span class="token variable">$(</span><span class="token function">hostname</span> <span class="token parameter variable">-i</span><span class="token variable">)</span></span> --pod-network-cidr <span class="token number">10.5</span>.0.0/16
</code></pre> 
<pre><code class="prism language-log">Initializing machine ID from random generator.
I0201 07:03:44.227509    4579 version.go:251] remote version is much newer: v1.26.1; falling back to: stable-1.20
[init] Using Kubernetes version: v1.20.15
[preflight] Running pre-flight checks
        [WARNING Service-Docker]: docker service is not active, please run 'systemctl start docker.service'
        [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
        [WARNING FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
[preflight] The system verification failed. Printing the output from the verification:
KERNEL_VERSION: 4.4.0-210-generic
DOCKER_VERSION: 20.10.1
OS: Linux
CGROUPS_CPU: enabled
CGROUPS_CPUACCT: enabled
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: enabled
CGROUPS_PIDS: enabled
CGROUPS_HUGETLB: enabled
        [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 20.10.1. Latest validated version: 19.03
        [WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module: "configs", output: "", err: exit status 1
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local node3] and IPs [10.96.0.1 192.168.0.16]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [localhost node3] and IPs [192.168.0.16 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [localhost node3] and IPs [192.168.0.16 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[kubelet-check] Initial timeout of 40s passed.
[apiclient] All control plane components are healthy after 58.522724 seconds
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.20" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node node3 as control-plane by adding the labels "node-role.kubernetes.io/master=''" and "node-role.kubernetes.io/control-plane='' (deprecated)"
[mark-control-plane] Marking the node node3 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: xki0su.skku36yc82040guc
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.0.16:6443 --token xki0su.skku36yc82040guc \
    --discovery-token-ca-cert-hash sha256:1a91dc6db669ceaed8e077855aeb9e2c06662a206ffb64000a38cb822246563c 
Waiting for api server to startup
Warning: resource daemonsets/kube-proxy is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
daemonset.apps/kube-proxy configured
pod "kube-proxy-clpn2" deleted
pod "kube-proxy-g2ssm" deleted
</code></pre> 
<h5><a id="1_preflight_158"></a>1. preflight</h5> 
<p>执行 kubeadm init指令后，kubeadm 首先要做的Preflight Checks检查，确定这台机器可以用来部署 Kubernetes:</p> 
<ul><li>Linux内核的版本必须是否是 3.10 以上？</li><li>Docker版本</li><li>Linux Cgroups模块启用</li><li>kubeadm和kubelet的版本</li><li>Kubernetes安装 / 工作端口<br> …</li></ul> 
<pre><code class="prism language-log">[preflight] Running pre-flight checks
        [WARNING Service-Docker]: docker service is not active, please run 'systemctl start docker.service'
        [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
        [WARNING FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
[preflight] The system verification failed. Printing the output from the verification:
KERNEL_VERSION: 4.4.0-210-generic
DOCKER_VERSION: 20.10.1
OS: Linux
CGROUPS_CPU: enabled
CGROUPS_CPUACCT: enabled
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: enabled
CGROUPS_PIDS: enabled
CGROUPS_HUGETLB: enabled
        [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 20.10.1. Latest validated version: 19.03
        [WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module: "configs", output: "", err: exit status 1
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
</code></pre> 
<h5><a id="2_certs_192"></a>2. certs</h5> 
<p>通过Preflight Checks之后，kubeadm将生成 Kubernetes 对外提供服务所需的证书和对应的目录</p> 
<pre><code class="prism language-log">[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local node3] and IPs [10.96.0.1 192.168.0.16]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [localhost node3] and IPs [192.168.0.16 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [localhost node3] and IPs [192.168.0.16 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
</code></pre> 
<h5><a id="3_kubeconfig_213"></a>3. kubeconfig</h5> 
<p>kubeadm 接下来会为其他组件生成访问 kube-apiserver 所需的配置文件,文件路径为：<code>/etc/kubernetes/xxx.conf</code>。记录了当前节点的服务器地址、监听端口、证书目录等信息。</p> 
<pre><code class="prism language-log">[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
</code></pre> 
<h5><a id="4_kubeletstart_222"></a>4. kubelet-start</h5> 
<p>启动kubelet</p> 
<pre><code class="prism language-log">[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
</code></pre> 
<h5><a id="5_controlplane_230"></a>5. control-plane</h5> 
<p>kubeadm为control-plane组件生成Pod配置文件，以Static Pod的方式部署kube-apiserver、kube-controller-manager、kube-scheduler三个组件</p> 
<pre><code class="prism language-log">[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
[control-plane] Creating static Pod manifest for "kube-scheduler"
</code></pre> 
<h5><a id="6_etcd_239"></a>6. etcd</h5> 
<p>kubeadm 生成Etcd的Pod YAML 文件，以Static Pod的方式启动Etcd</p> 
<pre><code>[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
</code></pre> 
<h5><a id="7_check_244"></a>7. check</h5> 
<p>kubeadm检查localhost:6443/healthz，等待control-plane组件完全运行</p> 
<pre><code>[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[kubelet-check] Initial timeout of 40s passed.
[apiclient] All control plane components are healthy after 58.522724 seconds
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.20" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node node3 as control-plane by adding the labels "node-role.kubernetes.io/master=''" and "node-role.kubernetes.io/control-plane='' (deprecated)"
[mark-control-plane] Marking the node node3 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
</code></pre> 
<h5><a id="8_bootstraptoken_257"></a>8. bootstrap-token</h5> 
<p>kubeadm为集群生成bootstrap token。任何持有token的节点都可以通过 kubeadm join 加入集群（需要安装了kubelet和kubadm）。</p> 
<pre><code class="prism language-log">[bootstrap-token] Using token: xki0su.skku36yc82040guc
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
</code></pre> 
<p>在token生成之后，kubeadm在etcd中创建一个cluster-info的ConfigMap，保存ca.crt证书等信息</p> 
<h5><a id="9_addons_270"></a>9. addons</h5> 
<p>安装默认插件。Kubernetes默认kube-proxy和DNS这两个插件是必须安装的，分别提供整个集群的服务发现和DNS功能。</p> 
<pre><code class="prism language-bash"><span class="token punctuation">[</span>addons<span class="token punctuation">]</span> Applied essential addon: CoreDNS
<span class="token punctuation">[</span>addons<span class="token punctuation">]</span> Applied essential addon: kube-proxy
</code></pre> 
<h5><a id="10initialized_successfully_277"></a>10.initialized successfully</h5> 
<pre><code class="prism language-log">Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.0.16:6443 --token xki0su.skku36yc82040guc \
    --discovery-token-ca-cert-hash sha256:1a91dc6db669ceaed8e077855aeb9e2c06662a206ffb64000a38cb822246563c 
Waiting for api server to startup
Warning: resource daemonsets/kube-proxy is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.
daemonset.apps/kube-proxy configured
pod "kube-proxy-clpn2" deleted
pod "kube-proxy-g2ssm" deleted
</code></pre> 
<h4><a id="kubeadm_join_306"></a>kubeadm join</h4> 
<p>kubeadm init 生成 bootstrap token 之后，在任意安装了 kubelet 和 kubeadm 的机器上执行 kubeadm join</p> 
<pre><code class="prism language-bash">kubeadm <span class="token function">join</span> <span class="token number">192.168</span>.0.16:6443 <span class="token parameter variable">--token</span> xki0su.skku36yc82040guc <span class="token punctuation">\</span>
    --discovery-token-ca-cert-hash sha256:1a91dc6db669ceaed8e077855aeb9e2c06662a206ffb64000a38cb822246563c 
</code></pre> 
<pre><code class="prism language-log">Initializing machine ID from random generator.
[preflight] Running pre-flight checks
        [WARNING Service-Docker]: docker service is not active, please run 'systemctl start docker.service'
        [WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
        [WARNING FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
[preflight] The system verification failed. Printing the output from the verification:
KERNEL_VERSION: 4.4.0-210-generic
DOCKER_VERSION: 20.10.1
OS: Linux
CGROUPS_CPU: enabled
CGROUPS_CPUACCT: enabled
CGROUPS_CPUSET: enabled
CGROUPS_DEVICES: enabled
CGROUPS_FREEZER: enabled
CGROUPS_MEMORY: enabled
CGROUPS_PIDS: enabled
CGROUPS_HUGETLB: enabled
        [WARNING SystemVerification]: this Docker version is not on the list of validated versions: 20.10.1. Latest validated version: 19.03
        [WARNING SystemVerification]: failed to parse kernel config: unable to load kernel module: "configs", output: "", err: exit status 1
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
</code></pre> 
<p>kubeadm首次访问kube-apiserver没有加密(signing request)。<br> 为了拿到保存在ConfigMap中的 cluster-info需要bootstrap token作为验证。<br> 拿到cluster-info里的kube-apiserver的地址、端口、证书之后，kubelet以secure模式连接到apiserver，节点加入集群。</p> 
<h3><a id="minkube_350"></a>minkube</h3> 
<p>完整的kubernetes一般都运行在大规模的计算集群上。Google推荐的学习kubernetes的方法是通过minukube。</p> 
<p>minikube是一个迷你版的Kubernetes，集成了Kubernetes的绝大多数功能特性，适合初学者。</p> 
<h4><a id="minikube_356"></a>下载安装minikube</h4> 
<p>访问 https://minikube.sigs.k8s.io/docs/start/，下载安装对应的版本</p> 
<pre><code class="prism language-bash"><span class="token function">curl</span> <span class="token parameter variable">-LO</span> https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
<span class="token function">sudo</span> <span class="token function">install</span> minikube-linux-amd64 /usr/local/bin/minikube

minikube version
<span class="token comment"># minikube version: v1.29.0</span>
<span class="token comment"># commit: ddac20b4b34a9c8c857fc602203b6ba2679794d3</span>

minikube kubectl
<span class="token comment"># kubectl controls the Kubernetes cluster manager.</span>

minikube start
<span class="token comment"># Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default</span>

minikube status
<span class="token comment"># minikube</span>
<span class="token comment"># type: Control Plane</span>
<span class="token comment"># host: Running</span>
<span class="token comment"># kubelet: Running</span>
<span class="token comment"># apiserver: Running</span>
<span class="token comment"># kubeconfig: Configured</span>

minikube <span class="token function">node</span> list
<span class="token comment"># minikube        192.168.49.2</span>
</code></pre> 
<h4><a id="kubectl_386"></a>kubectl</h4> 
<pre><code class="prism language-bash"><span class="token builtin class-name">alias</span> <span class="token assign-left variable">kubectl</span><span class="token operator">=</span><span class="token string">"minikube kubectl --"</span>
<span class="token builtin class-name">source</span> <span class="token operator">&lt;</span><span class="token punctuation">(</span>kubectl completion <span class="token function">bash</span><span class="token punctuation">)</span>

<span class="token builtin class-name">echo</span> <span class="token string">'alias kubectl="minikube kubectl --"'</span> <span class="token operator">&gt;&gt;</span> ~/.bashrc
<span class="token builtin class-name">echo</span> <span class="token string">'source &lt;(kubectl completion bash)'</span> <span class="token operator">&gt;&gt;</span> ~/.bashrc
</code></pre> 
<ul><li>minikube用于管理本地Kubernetes集群</li><li>kubectl操作Kubernetes</li></ul> 
<pre><code class="prism language-bash">kubectl version <span class="token parameter variable">--short</span> 
<span class="token comment"># Flag --short has been deprecated, and will be removed in the future. The --short output will become the default.</span>
<span class="token comment"># Client Version: v1.26.1</span>
<span class="token comment"># Kustomize Version: v4.5.7</span>
<span class="token comment"># Server Version: v1.26.1</span>

kubectl get nodes
<span class="token comment"># NAME       STATUS   ROLES           AGE     VERSION</span>
<span class="token comment"># minikube   Ready    control-plane   8m29s   v1.26.1</span>
</code></pre> 
<p>当前只有一个控制平面节点(Master节点)</p> 
<h3><a id="kubernetes__412"></a>kubernetes 架构</h3> 
<p><img src="https://images2.imgbox.com/04/a9/5BUby7l5_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<p>控制平面节点里有4个组件，分别是apiserver、etcd、scheduler、controller-manager (cloud-controller-manager / kube-controller-manager)。</p> 
<ul><li>apiserver是Kubernetes系统的唯一入口，它对外公开了一系列的 RESTful API，负责处理接受请求的工作。</li><li>etcd 是一个高可用的分布式键值存储数据库，用来持久化存储系统里的各种资源对象和状态。</li><li>scheduler负责容器的编排工作，检查节点的资源状态，把 Pod 调度到最适合的节点上运行：监视新创建的、未指定运行节点（node）的 Pods， 并选择节点来让Pod在上面运行</li><li>controller-manager 负责维护容器和节点等资源的状态。</li></ul> 
<p>查看组件状态，通过-n 指定名字空间</p> 
<pre><code class="prism language-bash">kubectl get pod <span class="token parameter variable">-n</span> kube-system
<span class="token comment"># NAME                               READY   STATUS    RESTARTS      AGE</span>
<span class="token comment"># coredns-787d4945fb-cb6bs           1/1     Running   0             61m</span>
<span class="token comment"># etcd-minikube                      1/1     Running   0             62m</span>
<span class="token comment"># kube-apiserver-minikube            1/1     Running   0             62m</span>
<span class="token comment"># kube-controller-manager-minikube   1/1     Running   0             62m</span>
<span class="token comment"># kube-proxy-tfzx2                   1/1     Running   0             61m</span>
<span class="token comment"># kube-scheduler-minikube            1/1     Running   0             62m</span>
<span class="token comment"># storage-provisioner                1/1     Running   1 (61m ago)   62m</span>
</code></pre> 
<p>Worker Node里有3个组件：kubelet、kube-proxy、container-runtime</p> 
<ul><li>kubelet 代理，负责Node相关的操作。会在集群中每个节点（node）上运行。 它保证容器（containers）都运行在 Pod 中。</li><li>kube-proxy网络代理，负责管理容器的网络通信。</li><li>container-runtime容器运行环境。</li></ul> 
<p>查看组件状态</p> 
<pre><code class="prism language-bash">minikube <span class="token function">ssh</span>
<span class="token function">docker</span> <span class="token function">ps</span> <span class="token operator">|</span> <span class="token function">grep</span> kube-proxy

<span class="token function">ps</span> <span class="token parameter variable">-ef</span> <span class="token operator">|</span> <span class="token function">grep</span> kubelet
</code></pre> 
<p>除了组件之外，kubernetes还支持插件Addons：</p> 
<ul><li>DNS：几乎所有 Kubernetes 集群都应该有集群DNS。集群DNS是一个DNS服务器，和环境中的其他DNS服务器一起工作，它为Kubernetes服务提供DNS记录。</li><li>Dashboard：基于Web的用户界面。它使用户可以管理集群中运行的应用程序以及集群本身，并进行故障排除。</li><li>Container Resource Monitoring 容器资源监控：将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供浏览这些数据的界面。</li><li>Cluster-level Logging 集群日志：将容器的日志数据保存到一个集中的日志存储中</li></ul> 
<pre><code class="prism language-bash">minikube addons list

<span class="token comment">#|-----------------------------|----------|--------------|--------------------------------|</span>
<span class="token comment">#| ADDON NAME                    | PROFILE    | STATUS         | MAINTAINER                       |</span>
<span class="token comment">#| ----------------------------- | ---------- | -------------- | -------------------------------- |</span>
<span class="token comment">#| ambassador                    | minikube   | disabled       | 3rd party (Ambassador)           |</span>
<span class="token comment">#| auto-pause                    | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| cloud-spanner                 | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| csi-hostpath-driver           | minikube   | disabled       | Kubernetes                       |</span>
<span class="token comment">#| dashboard                     | minikube   | enabled ✅      | Kubernetes                       |</span>
<span class="token comment">#| default-storageclass          | minikube   | enabled ✅      | Kubernetes                       |</span>
<span class="token comment">#| efk                           | minikube   | disabled       | 3rd party (Elastic)              |</span>
<span class="token comment">#| freshpod                      | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| gcp-auth                      | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| gvisor                        | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| headlamp                      | minikube   | disabled       | 3rd party (kinvolk.io)           |</span>
<span class="token comment">#| helm-tiller                   | minikube   | disabled       | 3rd party (Helm)                 |</span>
<span class="token comment">#| inaccel                       | minikube   | disabled       | 3rd party (InAccel               |</span>
<span class="token comment">#|                               |            |                | [info@inaccel.com])              |</span>
<span class="token comment">#| ingress                       | minikube   | disabled       | Kubernetes                       |</span>
<span class="token comment">#| ingress-dns                   | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| istio                         | minikube   | disabled       | 3rd party (Istio)                |</span>
<span class="token comment">#| istio-provisioner             | minikube   | disabled       | 3rd party (Istio)                |</span>
<span class="token comment">#| kong                          | minikube   | disabled       | 3rd party (Kong HQ)              |</span>
<span class="token comment">#| kubevirt                      | minikube   | disabled       | 3rd party (KubeVirt)             |</span>
<span class="token comment">#| logviewer                     | minikube   | disabled       | 3rd party (unknown)              |</span>
<span class="token comment">#| metallb                       | minikube   | disabled       | 3rd party (MetalLB)              |</span>
<span class="token comment">#| metrics-server                | minikube   | disabled       | Kubernetes                       |</span>
<span class="token comment">#| nvidia-driver-installer       | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| nvidia-gpu-device-plugin      | minikube   | disabled       | 3rd party (Nvidia)               |</span>
<span class="token comment">#| olm                           | minikube   | disabled       | 3rd party (Operator Framework)   |</span>
<span class="token comment">#| pod-security-policy           | minikube   | disabled       | 3rd party (unknown)              |</span>
<span class="token comment">#| portainer                     | minikube   | disabled       | 3rd party (Portainer.io)         |</span>
<span class="token comment">#| registry                      | minikube   | disabled       | Google                           |</span>
<span class="token comment">#| registry-aliases              | minikube   | disabled       | 3rd party (unknown)              |</span>
<span class="token comment">#| registry-creds                | minikube   | disabled       | 3rd party (UPMC Enterprises)     |</span>
<span class="token comment">#| storage-provisioner           | minikube   | enabled ✅      | Google                           |</span>
<span class="token comment">#| storage-provisioner-gluster   | minikube   | disabled       | 3rd party (Gluster)              |</span>
<span class="token comment">#| volumesnapshots               | minikube   | disabled       | Kubernetes                       |</span>
<span class="token comment">#| ----------------------------- | ---------- | -------------- | -------------------------------- |</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e0a1e8c96d4c22a4ad443422b1fef9d5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【个人博客搭建】butterfly主题配置</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1cc48c69dc498ba72f168651c4466bc2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2.Kubernetes基础-1</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>