<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习十大算法的每个算法的核心思想、工作原理、适用情况及优缺点 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习十大算法的每个算法的核心思想、工作原理、适用情况及优缺点" />
<meta property="og:description" content="简述机器学习十大算法的每个算法的核心思想、工作原理、适用情况及优缺点等。
1）C4.5算法：
ID3算法是以信息论为基础，以信息熵和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。
C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有：
1）用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；
2）在树构造过程中进行剪枝
3）能处理非离散的数据
4）能处理不完整的数据
C4.5算法优点：产生的分类规则易于理解，准确率较高。
缺点：
1)在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。
2)C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。
2）K means 算法：
是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k&lt; n。 算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。
其中N为样本数，K是簇数，rnk b表示n属于第k个簇，uk 是第k个中心点的值。然后求出最优的uk
优点：算法速度很快
缺点是，分组的数目k是一个输入参数，不合适的k可能返回较差的结果。
3）朴素贝叶斯算法：
朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。算法的基础是概率问题，分类原理是通过某对象的先验概率，利用贝叶斯公式计算出其后验概率，即该对象属于某一类的概率，选择具有最大后验概率的类作为该对象所属的类。朴素贝叶斯假设是约束性很强的假设，假设特征条件独立，但朴素贝叶斯算法简单，快速，具有较小的出错率。
在朴素贝叶斯的应用中，主要研究了电子邮件过滤以及文本分类研究。
4)K最近邻分类算法（KNN）
分类思想比较简单，从训练样本中找出K个与其最相近的样本，然后看这k个样本中哪个类别的样本多，则待判定的值（或说抽样）就属于这个类别。
缺点：
1）K值需要预先设定，而不能自适应
2）当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。
该算法适用于对样本容量比较大的类域进行自动分类。
5)EM最大期望算法
EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。
EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。
6）PageRank算法
是google的页面排序算法，是基于从许多优质的网页链接过来的网页，必定还是优质网页的回归关系，来判定所有网页的重要性。（也就是说，一个人有着越多牛X朋友的人，他是牛X的概率就越大。）
优点：
完全独立于查询，只依赖于网页链接结构，可以离线计算。
缺点：
1）PageRank算法忽略了网页搜索的时效性。
2）旧网页排序很高，存在时间长，积累了大量的in-links，拥有最新资讯的新网页排名却很低，因为它们几乎没有in-links。
7)AdaBoost
Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器(强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。
整个过程如下所示：
1. 先通过对N个训练样本的学习得到第一个弱分类器；
2. 将分错的样本和其他的新数据一起构成一个新的N个的训练样本，通过对这个样本的学习得到第二个弱分类器；
3. 将和都分错了的样本加上其他的新样本构成另一个新的N个的训练样本，通过对这个样本的学习得到第三个弱分类器；
4. 如此反复，最终得到经过提升的强分类器。
目前AdaBoost算法广泛的应用于人脸检测、目标识别等领域。
8）Apriori算法
Apriori算法是一种挖掘关联规则的算法，用于挖掘其内含的、未知的却又实际存在的数据关系，其核心是基于两阶段频集思想的递推算法 。
Apriori算法分为两个阶段：
1）寻找频繁项集
2）由频繁项集找关联规则
算法缺点：
1） 在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素；
2） 每次计算项集的支持度时，都对数据库中 的全部记录进行了一遍扫描比较，需要很大的I/O负载。
9）SVM支持向量机
支持向量机是一种基于分类边界的方法。其基本原理是（以二维数据为例）：如果训练数据分布在二维平面上的点，它们按照其分类聚集在不同的区域。基于分类边界的分类算法的目标是，通过训练，找到这些分类之间的边界（直线的――称为线性划分，曲线的――称为非线性划分）。对于多维数据（如N维），可以将它们视为N维空间中的点，而分类边界就是N维空间中的面，称为超面（超面比N维空间少一维）。线性分类器使用超平面类型的边界，非线性分类器使用超曲面。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/d7606ad8493cab96a33880e4e4f1c4ae/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2013-07-29T15:35:00+08:00" />
<meta property="article:modified_time" content="2013-07-29T15:35:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习十大算法的每个算法的核心思想、工作原理、适用情况及优缺点</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="cnblogs_post_body" class="blogpost-body"> 
 <p><strong><span style="font-size:14px;">简述机器学习十大算法的每个算法的核心思想、工作原理、适用情况及优缺点等。</span></strong></p> 
 <p><strong><span style="font-size:14px;">1）C4.5算法：</span></strong></p> 
 <p><span style="font-size:14px;">ID3算法是以<a href="http://baike.baidu.com/view/15076.htm" rel="nofollow">信息论</a>为基础，以<a href="http://baike.baidu.com/view/401605.htm" rel="nofollow">信息熵</a>和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。</span></p> 
 <p><span style="font-size:14px;">C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有：</span></p> 
 <p><span style="font-size:14px;">1）用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；</span></p> 
 <p><span style="font-size:14px;">2）在树构造过程中进行剪枝</span></p> 
 <p><span style="font-size:14px;">3）能处理非离散的数据</span></p> 
 <p><span style="font-size:14px;">4）能处理不完整的数据</span></p> 
 <p><span style="font-size:14px;"> C4.5算法优点：产生的分类规则易于理解，准确率较高。</span></p> 
 <p><span style="font-size:14px;">缺点：</span></p> 
 <p><span style="font-size:14px;">1)在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。</span></p> 
 <p><span style="font-size:14px;">2)C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><span style="font-size:14px;"><strong>2）K means 算法</strong>：</span></p> 
 <p><span style="font-size:14px;">是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k&lt; n。 算法的核心就是要优化失真函数J,使其收敛到局部最小值但不是全局最小值。</span></p> 
 <p><span style="font-size:14px;">其中N为样本数，K是簇数，rnk b表示n属于第k个簇，uk 是第k个中心点的值。</span><span style="font-size:14px;">然后求出最优的uk</span></p> 
 <p align="center"></p> 
 <p><span style="font-size:14px;">优点：算法速度很快</span></p> 
 <p><span style="font-size:14px;">缺点是，分组的数目k是一个输入参数，不合适的k可能返回较差的结果。</span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><strong><span style="font-size:14px;">3）朴素贝叶斯算法：</span></strong></p> 
 <p><span style="font-size:14px;">朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法。算法的基础是概率问题，分类原理是通过某对象的先验概率，利用贝叶斯公式计算出其后验概率，即该对象属于某一类的概率，选择具有最大后验概率的类作为该对象所属的类。朴素贝叶斯假设是约束性很强的假设，假设特征条件独立，但朴素贝叶斯算法简单，快速，具有较小的出错率。</span></p> 
 <p><span style="font-size:14px;">在朴素贝叶斯的应用中，主要研究了电子邮件过滤以及文本分类研究。</span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><strong><span style="font-size:14px;">4)K最近邻分类算法（KNN）</span></strong></p> 
 <p><span style="font-size:14px;">分类思想比较简单，从训练样本中找出K个与其最相近的样本，然后看这k个样本中哪个类别的样本多，则待判定的值（或说抽样）就属于这个类别。</span></p> 
 <p><span style="font-size:14px;">缺点：</span></p> 
 <p><span style="font-size:14px;">1）K值需要预先设定，而不能自适应</span></p> 
 <p><span style="font-size:14px;">2）当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。</span></p> 
 <p><span style="font-size:14px;">该算法适用于对样本容量比较大的类域进行自动分类。</span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><strong><span style="font-size:14px;">5)EM最大期望算法</span></strong></p> 
 <p><span style="font-size:14px;">EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。</span></p> 
 <p><span style="font-size:14px;">EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。</span></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><span style="font-size:14px;"><strong>6）PageRank算法</strong></span></p> 
 <p><span style="font-size:14px;">是google的页面排序算法，是基于从许多优质的网页链接过来的网页，必定还是优质网页的回归关系，来判定所有网页的重要性。（也就是说，一个人有着越多牛X朋友的人，他是牛X的概率就越大。）</span></p> 
 <p><span style="font-size:14px;">优点：</span></p> 
 <p><span style="font-size:14px;">完全独立于查询，只依赖于网页链接结构，可以离线计算。</span></p> 
 <p><span style="font-size:14px;">缺点：</span></p> 
 <p><span style="font-size:14px;">1）PageRank算法忽略了网页搜索的时效性。</span></p> 
 <p><span style="font-size:14px;">2）旧网页排序很高，存在时间长，积累了大量的in-links，拥有最新资讯的新网页排名却很低，因为它们几乎没有in-links。</span></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><strong><span style="font-size:14px;">7)AdaBoost</span></strong></p> 
 <p><span style="font-size:14px;">Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器(强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。</span></p> 
 <p><span style="font-size:14px;">整个过程如下所示：<br> 1. 先通过对N个训练样本的学习得到第一个弱分类器；<br> 2. 将分错的样本和其他的新数据一起构成一个新的N个的训练样本，通过对这个样本的学习得到第二个弱分类器；<br> 3. 将和都分错了的样本加上其他的新样本构成另一个新的N个的训练样本，通过对这个样本的学习得到第三个弱分类器；<br> 4. 如此反复，最终得到经过提升的强分类器。</span></p> 
 <p><span style="font-size:14px;">目前AdaBoost算法广泛的应用于人脸检测、目标识别等领域。</span></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><span style="font-size:14px;"><strong>8）Apriori算法</strong></span></p> 
 <p><span style="font-size:14px;">Apriori算法是一种挖掘关联规则的算法，用于挖掘其内含的、未知的却又实际存在的数据关系，其核心是基于两阶段频集思想的递推算法 。</span></p> 
 <p><span style="font-size:14px;">Apriori算法分为两个阶段：</span></p> 
 <p><span style="font-size:14px;">1）寻找频繁项集</span></p> 
 <p><span style="font-size:14px;">2）由频繁项集找关联规则</span></p> 
 <p><span style="font-size:14px;">算法缺点：</span></p> 
 <p><span style="font-size:14px;">1） 在每一步产生侯选项目集时循环产生的组合过多，没有排除不应该参与组合的元素；</span></p> 
 <p><span style="font-size:14px;">2） 每次计算项集的支持度时，都对数据库中    的全部记录进行了一遍扫描比较，需要很大的I/O负载。</span></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><span style="font-size:14px;"><strong>9）SVM支持向量机</strong></span></p> 
 <p><span style="font-size:14px;">支持向量机是一种基于分类边界的方法。其基本原理是（以二维数据为例）：如果训练数据分布在二维平面上的点，它们按照其分类聚集在不同的区域。<strong>基于分类边界的分类算法的目标是，通过训练，找到这些分类之间的边界</strong>（直线的――称为线性划分，曲线的――称为非线性划分）。对于多维数据（如N维），可以将它们视为N维空间中的点，而分类边界就是N维空间中的面，称为超面（超面比N维空间少一维）。线性分类器使用超平面类型的边界，非线性分类器使用超曲面。</span></p> 
 <p><span style="font-size:14px;"><strong>支持向量机的原理是将低维空间的点映射到高维空间，使它们成为线性可分，再使用线性划分的原理来判断分类边界。</strong>在高维空间中是一种线性划分，而在原有的数据空间中，是一种非线性划分。</span></p> 
 <p><span style="font-size:14px;">SVM在解决小样本、非线性及高维模式识别问题中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中。</span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><span style="font-size:14px;"> </span></p> 
 <p><span style="font-size:14px;"><strong>10）CART分类与回归树</strong></span></p> 
 <p><span style="font-size:14px;">是一种决策树分类方法，采用基于最小距离的基尼指数估计函数，用来决定由该子数</span></p> 
 <p><span style="font-size:14px;">据集生成的决策树的拓展形。如果目标变量是标称的，称为分类树；如果目标变量是连续的，称为回归树。分类树是使用树结构算法将数据分成离散类的方法。<strong></strong></span></p> 
 <p><span style="font-size:14px;">优点</span></p> 
 <p><span style="font-size:14px;">1）非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。</span></p> 
 <p><span style="font-size:14px;">2）在面对诸如存在缺失值、变量数多等问题时CART 显得非常稳健。</span></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><strong><span style="font-size:14px;"> </span></strong></p> 
 <p><span style="font-size:14px;"> </span></p> 
</div> 
<p>转载于:https://www.cnblogs.com/wuwuwu/p/6335236.html</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/feac02d2fa05defb15db5c752e7e6c2e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">函数式思维: 为什么函数式编程越来越受关注</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2ccbc213b975c9a009997f9d08d41f92/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vs2010 directX winnt.h错误</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>