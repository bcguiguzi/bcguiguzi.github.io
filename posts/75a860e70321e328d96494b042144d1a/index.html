<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>SNPE教程三：模型转换、量化 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="SNPE教程三：模型转换、量化" />
<meta property="og:description" content="一、模型转换 1、转换指令： 这里只讲解onnx转换，其他类似
onnx转到dlc(snpe的模型文件)需要用到一个工具就是snpe-onnx-to-dlc。
snpe-onnx-to-dlc
转化指令参数 格式意义是否必要 --i 输入的onnx模型 指定输入模型必要 --output_path 输出dlc文件的路径 指定输出路径 --disable_batchnorm_folding 禁止将BN层融合到卷积中 --input_type 输入名字 输入类型 （类型支持image, default, opaque）
指定多个输入的输入类型
image就是输入均值是0.0f,最大值是255.0f那么就会将他银蛇到无符号八位
default就是浮点输入到dsp然后被量化
opaque就是如果输入时浮点特定层输入也要求浮点那就不量化
--input_encoding 输入名字 指定的编码格式 可以指定多个层级的输入的编码格式（包括（bgr， rgb， rgba, argb32, nv21, time_series, other) --validation_target 运行环境 运行设备 在指定的运行环境和运行设备上验证
运行环境:cpu，gpu, dsp
运行设备：snapdragon_801， snapdragon_820, snapdragon_835
如果不指定会在所有设备上验证
--strict 会严格在指定设备验证 --dry_run DRY_RUN 评估没有经过任何算子转化的模型并返回不支持的算子
DRY_RUN = {‘info’, &#39;debug&#39;}
debug可以看到更多信息
--udo_config_paths 自定义算子路径 指定自定义算子路径 例子：snpe-onnx-to-dlc --input_network models/bvlc_alexnet/bvlc_alexnet/model.onnx --output_path bvlc_alexnet.dlc
2、算子支持 各个框架的算子支持情况请看：Snapdragon Neural Processing Engine SDK: Supported Network Layershttps://developer." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/75a860e70321e328d96494b042144d1a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-31T16:56:45+08:00" />
<meta property="article:modified_time" content="2023-10-31T16:56:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">SNPE教程三：模型转换、量化</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><strong>一、模型转换</strong></h2> 
<h4>1、转换指令：</h4> 
<p>这里只讲解onnx转换，其他类似</p> 
<p>onnx转到dlc(snpe的模型文件)需要用到一个工具就是snpe-onnx-to-dlc。</p> 
<p>snpe-onnx-to-dlc</p> 
<table align="center" border="1" cellpadding="1" cellspacing="1" style="width:700px;"><caption>
   转化指令参数 
 </caption><thead><tr><th style="width:318px;">格式</th><th style="width:254px;">意义</th><th style="width:32px;">是否必要</th></tr></thead><tbody><tr><td style="width:318px;"> <pre>--i 输入的onnx模型
</pre> </td><td style="width:254px;">指定输入模型</td><td style="width:32px;">必要</td></tr><tr><td style="width:318px;"> <pre>--output_path   输出dlc文件的路径</pre> </td><td style="width:254px;">指定输出路径</td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre>--disable_batchnorm_folding
</pre> </td><td style="width:254px;">禁止将BN层融合到卷积中</td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre>--input_type 输入名字 输入类型</pre> <p>（类型支持image, default, opaque）</p> </td><td style="width:254px;"> <p>指定多个输入的输入类型</p> <p><u>image</u>就是输入均值是0.0f,最大值是255.0f那么就会将他银蛇到无符号八位</p> <p><u>default</u>就是浮点输入到dsp然后被量化</p> <p><u>opaque</u>就是如果输入时浮点特定层输入也要求浮点那就不量化</p> </td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre> --input_encoding 输入名字 指定的编码格式</pre> </td><td style="width:254px;">可以指定多个层级的输入的编码格式（包括（bgr， rgb， rgba, argb32, nv21, time_series, other)</td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre>--validation_target 运行环境 运行设备</pre> </td><td style="width:254px;"> <p>在指定的运行环境和运行设备上验证</p> <p>运行环境:cpu，gpu, dsp</p> <p>运行设备：snapdragon_801， snapdragon_820, snapdragon_835</p> <p>如果不指定会在所有设备上验证</p> </td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre> --strict</pre> </td><td style="width:254px;">会严格在指定设备验证</td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre>--dry_run DRY_RUN</pre> </td><td style="width:254px;"> <p>评估没有经过任何算子转化的模型并返回不支持的算子</p> <p>DRY_RUN = {‘info’, 'debug'}</p> <p>debug可以看到更多信息</p> </td><td style="width:32px;"></td></tr><tr><td style="width:318px;"> <pre>--udo_config_paths 自定义算子路径</pre> </td><td style="width:254px;">指定自定义算子路径</td><td style="width:32px;"> <p></p> <p></p> </td></tr></tbody></table> 
<p>例子：snpe-onnx-to-dlc --input_network models/bvlc_alexnet/bvlc_alexnet/model.onnx --output_path bvlc_alexnet.dlc</p> 
<h4>2、算子支持</h4> 
<p>各个框架的算子支持情况请看：<a class="has-card" href="https://developer.qualcomm.com/sites/default/files/docs/snpe/network_layers.html" rel="nofollow" title="Snapdragon Neural Processing Engine SDK: Supported Network Layers"><span class="link-card-box"><span class="link-title">Snapdragon Neural Processing Engine SDK: Supported Network Layers</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/5f/0c/s2QZyFOm_o.png" alt="icon-default.png?t=N7T8">https://developer.qualcomm.com/sites/default/files/docs/snpe/network_layers.html</span></span></a></p> 
<h4>3、网络resize</h4> 
<p>不管是在模型转换中还是 在运行环境中都不支持可变的输入张量。但可以通过代码将网络重新resize</p> 
<p>示例：</p> 
<p>转换后的模型的输入是1,3,244,244</p> 
<pre>snpe-caffe2-to-dlc -p predict_net.pb -e init_net.pb -i data 1,3,244,244 -d model.dlc</pre> 
<pre><code class="language-cpp">#include &lt;SNPE/SNPE.hpp&gt;

auto container = zdl::DlContainer::IDlContainer::open("model.dlc");

//创建一个新的形状
zdl::DlSystem::TensorShapeMap inputShapeMap;
inputShapeMap.add("data", {3,1080,1440,3})

zdl::SNPE::SNPEBuilder builder(container.get());

//重新设置输入的shape
builder.setInputDimensions(inputShapeMap);

auto snpe = builder.build();</code></pre> 
<hr> 
<h2><strong>二、模型量化</strong></h2> 
<h4>1、量化算法</h4> 
<p>这里用到的量化算法其实也很简单就是把一堆浮点数完整的映射到0~255中。</p> 
<p>步骤如下：</p> 
<ol><li>计算输入数据的范围</li><li>计算编码的最小值最大值（固定0点，255点），步长(要求输入浮点数的0.0必须要能被映射到0~255上) 
  <ul><li>如果是全是正数，则最小值给0，最大值不变</li><li>如果全是负数，则最大值给0，最小值不变</li><li>如果既有正也有负，那么计算步长，如果输入浮点的0点不能被映射那么将最小最大值同时向左或向右偏移几个步长</li></ul></li><li>将输入浮点映射到0~255</li><li>输出量化值和编码参数</li></ol> 
<p>例如：</p> 
<ul><li>输入：[-1.8, -1.0, 0, 0.5]</li><li>最小值-1.8， 最大值0.5</li><li>计算步长  = （0.5 - -1.8）/  255 = 0.009</li><li>浮点0点对应(0.0 - -1.8) / 2.3 x 255 = 199.59 （精确到0.01）</li><li>不能被完全映射所以将最小最大值同时向左偏移 0.43 x 0.009 = 0.00391</li><li>所以调整后的最小值为-1.8 - 0.391 = -1.80391， 最大值为0.5 - 0.00369 = 0.49609</li><li>输出[0, 89, 200, 255]</li></ul> 
<p>量化位宽一般默认为8位，但是偏移也可以设置为32位，32位偏移可能会带来一些精度提升</p> 
<h4><strong>2、量化模式</strong></h4> 
<ul><li><strong>默认量化模式：</strong>如上所属</li><li><strong>增强量化模式：</strong>一般适用于长尾分布的数据（这里值的长尾分布是输入的值集中在某个小范围）。增强量化会使用最小范围并且遵从输入浮点0点能被完全映射原则</li><li><strong>调整权重量化模式：</strong>只有在量化到8位时才能用，修改输入的最大最小值同样遵从最小范围和输入浮点0点能被完全映射原则</li></ul> 
<h4><strong>3、量化参数覆盖</strong></h4> 
<p>量化参数也可以自己提供用来做量化，这些自己提供的参数会覆盖模型转化或用snpe工具量化产生的参数。参数文件是个json，格式如下</p> 
<pre><code class="language-python">{
    
  "activation_encodings": {                #激活部分的量化参数
      "Conv1:0": [                         #指定要被覆盖参数的张量名
          {
              "bitwidth": 8,               #指定位宽
              "max": 12.82344407824954,    
              "min": 0.0,    
              "offset": 0,                 #输入浮点数0点对应到0~255上的值
              "scale": 0.050288015993135454#步长
          }
      ],
      "input:0": [
          {
              "bitwidth": 8,
              "max": 0.9960872825108046,
              "min": -1.0039304197656937,
              "offset": 127,
              "scale": 0.007843206675594112
          }
      ]
  },
  "param_encodings": {                    #权重或偏移的量化参数
      "Conv2d/weights": [
          {
              "bitwidth": 8,
              "max": 1.700559472933134,
              "min": -2.1006477158567995,
              "offset": 140,
              "scale": 0.01490669485799974
          }
      ]
  }
}</code></pre> 
<h4>4、量化要求</h4> 
<p>量化工具<a href="https://developer.qualcomm.com/sites/default/files/docs/snpe/tools.html#tools_snpe-dlc-quantize" rel="nofollow" title="snpe-dlc-quantize">snpe-dlc-quantize</a>要求指定模型输入批次为一。为了计算量化参数的范围需要一些具有代表性的数据集。一般5-10张就够了，如果要求稳定性，推荐50-100张但是不要用训练集里的数据</p> 
<p>对于在AIP上运行的模型必须要量化成八位</p> 
<h4>5、量化指令</h4> 
<p>snpe-dlc-quantize</p> 
<h4><strong>6、数据列表</strong></h4> 
<p>数据列表txt格式如下</p> 
<pre><code>#&lt;output_layer_name&gt;[&lt;space&gt;&lt;output_layer_name&gt;]     //指定哪几层输出
%&lt;output_tensor_name&gt;[&lt;space&gt;&lt;output_tensor_name&gt;]   
路径..xxx.raw
路径..xxx.raw
路径..xxx.raw
路径..xxx.raw
路径..xxx.raw
路径..xxx.raw
路径..xxx.raw
.
.
.</code></pre> 
<h4>7、输入数据预处理</h4> 
<p>输入数据形状： NCHW</p> 
<h4>8、不同运行环境</h4> 
<table align="center" border="1" cellpadding="1" cellspacing="1" style="width:700px;"><thead><tr><th>运行环境</th><th>量化 / 非量化</th></tr></thead><tbody><tr><td>CPU / GPU</td><td>量化非量化都可以输入，但是只运行非量化。所以如果输入一个量化DLC，初始化时，模型会被反量化，增加初始化时间，精度也可能受影响。</td></tr><tr><td>DSP</td><td>量化非量化都可以输入，但是只运行量化。所以如果输入一个非量化DLC，初始化时模型会被强制量化，增加初始化时间。</td></tr><tr><td>AIP</td><td>只能输入量化</td></tr></tbody></table> 
<p>---------未完待续---------</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9f2fe0a44b6ce062f27262f277b6418c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MineCraft 1.20.1模组开发-（1）-为蓝宝石剑添加右键发射凋零骷髅头以及攻击附加漂浮的效果</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/42dee4aea315c80e6116bede52612fe4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">缓存(Redis)工具类，包含缓存击穿、缓存穿透、生成全局唯一id的解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>