<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PicoDet：专为移动CPU优化的快速目标检测 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PicoDet：专为移动CPU优化的快速目标检测" />
<meta property="og:description" content="概述
PicoDet是在2021年11月发布的一种机器学习模型。它将最近在目标检测模型方面的研究成果集成到一个轻量级模型中，以在移动CPU上实现高准确度和高速目标检测。
COCO dataset
架构
PicoDet通过使用轻量级结构作为骨干，提高了特征提取的速度。通过改进损失函数，它还提高了训练的稳定性和效率。
最近几年来，基于无锚点的检测器在目标检测中变得越来越受欢迎，而全卷积单阶段目标检测（FCOS）解决了重叠的地面实况标签问题。而典型的锚框为每个坐标都有多个锚点，FCOS为每个坐标只有一个中心点；使用FCOS的无锚点方法具有无需超参数调整的优势。
然而，通常无锚点的检测器用于服务器端处理的模型，这些模型相对较大。用于移动应用的无锚点模型仅限于NanoDet和YOLOX-Nano。对于轻量级无锚点检测器来说，很难平衡准确性和效率。PicoDet是一种受FCOS和广义焦点损失（GFL）启发的新尝试。
PicoDet
CSP是ResNet等模型中使用的“跳跃连接”机制的进化。它通过添加一个机制来切断和连接先前阶段的特征图，而无需进行卷积运算，从而便于反向传播并减少操作量。在PicoDet中，将3x3深度卷积扩展为5x5深度卷积，以扩大感受野。
CSPNet
为了改善标签分配策略，采用了SimOTA，并采用了Varifocal Loss（VFL）和GIoU损失作为损失函数。
SimOTA也用于YOLOX。在确定预测边界框与地面实况边界框之间的映射以计算损失时，该方法不是分配最近的地面实况，而是解决了一个优化问题，以分配更合适的地面实况。SimOTA是OTA（Optimal Transport Assignment）的更快版本。
SimOTA
在这个目标检测模型中，通过将地面实况边界框分配给HEAD预测的每个边界框，并反向传播损失来进行学习。地面实况边界框可能会重叠。如果预测边界框落在该区域内，我们将出现一种称为“模糊锚点”的情况，我们不知道要分配哪个地面实况。OTA具有一种算法，使将地面实况边界框分配给模糊锚点变得困难。
模糊锚点
以下是OTA分配的结果示例。图像中的点是预测边界框的中心点，红色椭圆显示了分配策略的差异。
OTA分配的结果
PicoDet中用于特征提取的骨干是Enhanced ShuffleNet，这是ShuffleNetV2的改进版本，是一种适用于移动设备的高效模型架构。ShuffleNet引入了“逐点组卷积”和“通道混洗”操作，以加速1x1卷积，这是MobileNet的瓶颈。
Enhanced ShuffleNet
一次性神经架构搜索（NAS）被引入以搜索每层的最佳通道数量。搜索结果显示，使通道数量成为8的倍数对提高推断速度的贡献最大。
性能
以下是使用高通骁龙865 CPU的性能。在使用NCNN在CPU上运行时，YOLOX-Tiny在mAP 32.8时需要32.77毫秒，而PicoDet在mAP 30.6时需要12.37毫秒。在17.39毫秒内可以实现mAP 34.3。
这种性能提升是在CPU上运行推断时可以测量到的，而在GPU上运行时它们表现相同。因此，YOLOX-Tiny可能更适用于Jetson设备，而PicoDet可能最适合树莓派等设备。
用法
可以使用以下命令将PicoDet与ailia SDK一起用于检测网络摄像头视频流中的对象。
$ python3 picodet.py -v 0 ax Inc. 开发了ailia SDK，该SDK支持跨平台、基于GPU的快速推断。ax Inc. 提供从咨询和模型创建到基于AI的应用程序和SDK开发的广泛服务。如有任何疑问，请随时与我们联系。
· END ·
HAPPY LIFE
本文仅供学习交流使用，如有侵权请联系作者删除" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/a4ff6d6ac1cc6fef937881b03161ffd4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-15T09:58:16+08:00" />
<meta property="article:modified_time" content="2024-03-15T09:58:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PicoDet：专为移动CPU优化的快速目标检测</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:left;"><strong>概述</strong><br></p> 
 <p style="text-align:left;">PicoDet是在2021年11月发布的一种机器学习模型。它将最近在目标检测模型方面的研究成果集成到一个轻量级模型中，以在移动CPU上实现高准确度和高速目标检测。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/b1/b6/54rRdXIc_o.png" alt="c8577f9bcc9943b302f51592c8b7b9f1.png"></p> 
 <p style="text-align:center;">COCO dataset</p> 
 <p style="text-align:left;"><strong>架构</strong></p> 
 <p style="text-align:justify;">PicoDet通过使用轻量级结构作为骨干，提高了特征提取的速度。通过改进损失函数，它还提高了训练的稳定性和效率。</p> 
 <p style="text-align:justify;">最近几年来，基于无锚点的检测器在目标检测中变得越来越受欢迎，而全卷积单阶段目标检测（FCOS）解决了重叠的地面实况标签问题。而典型的锚框为每个坐标都有多个锚点，FCOS为每个坐标只有一个中心点；使用FCOS的无锚点方法具有无需超参数调整的优势。</p> 
 <p style="text-align:justify;">然而，通常无锚点的检测器用于服务器端处理的模型，这些模型相对较大。用于移动应用的无锚点模型仅限于NanoDet和YOLOX-Nano。对于轻量级无锚点检测器来说，很难平衡准确性和效率。PicoDet是一种受FCOS和广义焦点损失（GFL）启发的新尝试。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/89/71/hE4PYEnB_o.png" alt="082354355ce7393c93906d556d316929.png"></p> 
 <p style="text-align:center;">PicoDet</p> 
 <p style="text-align:justify;">CSP是ResNet等模型中使用的“跳跃连接”机制的进化。它通过添加一个机制来切断和连接先前阶段的特征图，而无需进行卷积运算，从而便于反向传播并减少操作量。在PicoDet中，将3x3深度卷积扩展为5x5深度卷积，以扩大感受野。</p> 
 <p style="text-align:justify;"><img src="https://images2.imgbox.com/17/2d/IIaL4Wo7_o.png" alt="b96ae68558329ebe12a4ce474fe74b75.png"></p> 
 <p style="text-align:center;">CSPNet</p> 
 <p style="text-align:justify;">为了改善标签分配策略，采用了SimOTA，并采用了Varifocal Loss（VFL）和GIoU损失作为损失函数。</p> 
 <p style="text-align:justify;">SimOTA也用于YOLOX。在确定预测边界框与地面实况边界框之间的映射以计算损失时，该方法不是分配最近的地面实况，而是解决了一个优化问题，以分配更合适的地面实况。SimOTA是OTA（Optimal Transport Assignment）的更快版本。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/24/cc/Ojawltei_o.png" alt="bc02f6e014ae6e28d03adc1a86fe82f7.png"></p> 
 <p style="text-align:center;">SimOTA</p> 
 <p style="text-align:justify;">在这个目标检测模型中，通过将地面实况边界框分配给HEAD预测的每个边界框，并反向传播损失来进行学习。地面实况边界框可能会重叠。如果预测边界框落在该区域内，我们将出现一种称为“模糊锚点”的情况，我们不知道要分配哪个地面实况。OTA具有一种算法，使将地面实况边界框分配给模糊锚点变得困难。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/4a/03/7lxUNDBB_o.png" alt="a0030d4fde0b16ab095ad57b63856b68.png"></p> 
 <p style="text-align:center;">模糊锚点</p> 
 <p style="text-align:justify;">以下是OTA分配的结果示例。图像中的点是预测边界框的中心点，红色椭圆显示了分配策略的差异。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/f4/a4/H3d1Ekgm_o.png" alt="02e1377becad79eded32c6a8322679d1.png"></p> 
 <p style="text-align:center;">OTA分配的结果</p> 
 <p style="text-align:justify;">PicoDet中用于特征提取的骨干是Enhanced ShuffleNet，这是ShuffleNetV2的改进版本，是一种适用于移动设备的高效模型架构。ShuffleNet引入了“逐点组卷积”和“通道混洗”操作，以加速1x1卷积，这是MobileNet的瓶颈。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/00/47/aYSwe821_o.png" alt="919dc840c19151d96048b5bf42e98baa.png"></p> 
 <p style="text-align:center;">Enhanced ShuffleNet</p> 
 <p style="text-align:justify;">一次性神经架构搜索（NAS）被引入以搜索每层的最佳通道数量。搜索结果显示，使通道数量成为8的倍数对提高推断速度的贡献最大。</p> 
 <p style="text-align:justify;"><strong>性能</strong></p> 
 <p style="text-align:justify;">以下是使用高通骁龙865 CPU的性能。在使用NCNN在CPU上运行时，YOLOX-Tiny在mAP 32.8时需要32.77毫秒，而PicoDet在mAP 30.6时需要12.37毫秒。在17.39毫秒内可以实现mAP 34.3。</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/40/d1/QFBf2Esr_o.png" alt="579da1531080927bd3cfed0d9a017adb.png"></p> 
 <p style="text-align:justify;">这种性能提升是在CPU上运行推断时可以测量到的，而在GPU上运行时它们表现相同。因此，YOLOX-Tiny可能更适用于Jetson设备，而PicoDet可能最适合树莓派等设备。</p> 
 <p style="text-align:justify;"><strong>用法</strong></p> 
 <p style="text-align:justify;">可以使用以下命令将PicoDet与ailia SDK一起用于检测网络摄像头视频流中的对象。</p> 
 <pre class="has"><code class="language-shell">$ python3 picodet.py -v 0</code></pre> 
 <p style="text-align:justify;">ax Inc. 开发了ailia SDK，该SDK支持跨平台、基于GPU的快速推断。ax Inc. 提供从咨询和模型创建到基于AI的应用程序和SDK开发的广泛服务。如有任何疑问，请随时与我们联系。</p> 
 <p><strong>·  END  ·</strong><br></p> 
 <p>HAPPY LIFE</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/b6/78/owfoPmUb_o.png" alt="7015e0c6f9467a29ec4b4cac5f4326e5.png"></p> 
 <p style="text-align:right;">本文仅供学习交流使用，如有侵权请联系作者删除</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b939231559e1d48bd7c12eac9030f2b3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python--字符串切片和常用的写法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b388f1dd25160bdf49e1bba619c0afbb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">VDI、VPN 与 RDP：选择安全的远程访问解决方案</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>