<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>注意力机制概览 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="注意力机制概览" />
<meta property="og:description" content="目录 一、背景二、前置知识2.1 通道注意力2.2 空间注意力2.3 self-attention 三、各种改进版本3.1 跨特征3.1.1 BiSeNet [1]3.1.2 SKNet [2] 3.2 分组3.2.1 SGNet [3]3.2.2 SANet [4] 3.3 Self Attention3.3.1 non local attention [5]3.3.2 GCNet [6]3.3.3 dual attention [7] 3.4 空间&#43;通道3.4.1 BAM [8]3.4.2 scSE [9] 参考文献 一、背景 注意力机制可有效提高模型对特征的提取能力，进而提高模型精度。本文首先对经典的三种注意力学习方法进行介绍，后结合自己一点点浅薄认知，对注意力机制后续的改进方向进行归纳，希望对大家能有帮助。
二、前置知识 2.1 通道注意力 对特征图进行全局平均池化，后经过两层全连接层，最后使用Sigmoid输出0-1之间的权重
2.2 空间注意力 ​ 将特征图进行压缩，得到空间方向上的权重图
2.3 self-attention 这里借助了Non-local Neural Networks中的一张图。self-attention本质上是一种空间注意机制，如上图所示，需要求解一个[THW, THW]的矩阵，该矩阵中的每一行，表示原特征图中的一点与其余点的关系
三、各种改进版本 将改进的注意力机制主要分为四类
跨特征：构建不同的特征表达，后进行融合分组：对特征图按通道分组后，再使用注意力机制self-attention：本质上，self-attention就是一系列矩阵运算，对运算过程中的某些步骤进行优化空间&#43;通道：很自然的想法，同时使用两种注意力机制 3.1 跨特征 3.1.1 BiSeNet [1] 对不同层次的特征使用通道注意力机制进行融合。这应该属于应用创新，没有构建新的注意力机制，而是将老的注意力机制应用到特征融合方向
3.1.2 SKNet [2] 使用不同感受野卷积核构建多分支特征，将这些特征 add 后计算不同分支的同道注意力系数，后沿着通道方向进行加权求和
3.2 分组 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/37e7415d8a6030722204fe9cc4640b0b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-29T14:34:00+08:00" />
<meta property="article:modified_time" content="2023-09-29T14:34:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">注意力机制概览</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><ul><li><a href="#_1" rel="nofollow">一、背景</a></li><li><a href="#_5" rel="nofollow">二、前置知识</a></li><li><ul><li><a href="#21__7" rel="nofollow">2.1 通道注意力</a></li><li><a href="#22__13" rel="nofollow">2.2 空间注意力</a></li><li><a href="#23_selfattention_18" rel="nofollow">2.3 self-attention</a></li></ul> 
    </li><li><a href="#_24" rel="nofollow">三、各种改进版本</a></li><li><ul><li><a href="#31__33" rel="nofollow">3.1 跨特征</a></li><li><ul><li><a href="#311_BiSeNet_1_35" rel="nofollow">3.1.1 BiSeNet [1]</a></li><li><a href="#312_SKNet_2_41" rel="nofollow">3.1.2 SKNet [2]</a></li></ul> 
     </li><li><a href="#32__47" rel="nofollow">3.2 分组</a></li><li><ul><li><a href="#321_SGNet_3_49" rel="nofollow">3.2.1 SGNet [3]</a></li><li><a href="#322_SANet_4_55" rel="nofollow">3.2.2 SANet [4]</a></li></ul> 
     </li><li><a href="#33_Self_Attention_61" rel="nofollow">3.3 Self Attention</a></li><li><ul><li><a href="#331_non_local_attention_5_63" rel="nofollow">3.3.1 non local attention [5]</a></li><li><a href="#332_GCNet_6_70" rel="nofollow">3.3.2 GCNet [6]</a></li><li><a href="#333_dual_attention_7_76" rel="nofollow">3.3.3 dual attention [7]</a></li></ul> 
     </li><li><a href="#34__82" rel="nofollow">3.4 空间+通道</a></li><li><ul><li><a href="#341_BAM_8_84" rel="nofollow">3.4.1 BAM [8]</a></li><li><a href="#342_scSE_9_91" rel="nofollow">3.4.2 scSE [9]</a></li></ul> 
    </li></ul> 
    </li><li><a href="#_97" rel="nofollow">参考文献</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h4><a id="_1"></a>一、背景</h4> 
<p>注意力机制可有效提高模型对特征的提取能力，进而提高模型精度。本文首先对经典的三种注意力学习方法进行介绍，后结合自己一点点浅薄认知，对注意力机制后续的改进方向进行归纳，希望对大家能有帮助。</p> 
<h4><a id="_5"></a>二、前置知识</h4> 
<h5><a id="21__7"></a>2.1 通道注意力</h5> 
<p><img src="https://images2.imgbox.com/7d/3c/H2Bgk9Mx_o.png" alt="在这里插入图片描述"></p> 
<p>对特征图进行全局平均池化，后经过两层全连接层，最后使用Sigmoid输出0-1之间的权重</p> 
<h5><a id="22__13"></a>2.2 空间注意力</h5> 
<p><img src="https://images2.imgbox.com/36/2e/eMnRmFg2_o.png" alt="在这里插入图片描述"></p> 
<p>​ 将特征图进行压缩，得到空间方向上的权重图</p> 
<h5><a id="23_selfattention_18"></a>2.3 self-attention</h5> 
<p><img src="https://images2.imgbox.com/35/d0/fmn9Eben_o.png" alt="在这里插入图片描述"></p> 
<p>这里借助了Non-local Neural Networks中的一张图。self-attention本质上是一种空间注意机制，如上图所示，需要求解一个[THW, THW]的矩阵，该矩阵中的每一行，表示原特征图中的一点与其余点的关系</p> 
<h4><a id="_24"></a>三、各种改进版本</h4> 
<p>将改进的注意力机制主要分为四类</p> 
<ul><li>跨特征：构建不同的特征表达，后进行融合</li><li>分组：对特征图按通道分组后，再使用注意力机制</li><li>self-attention：本质上，self-attention就是一系列矩阵运算，对运算过程中的某些步骤进行优化</li><li>空间+通道：很自然的想法，同时使用两种注意力机制</li></ul> 
<h5><a id="31__33"></a>3.1 跨特征</h5> 
<h6><a id="311_BiSeNet_1_35"></a>3.1.1 BiSeNet [1]</h6> 
<p><img src="https://images2.imgbox.com/09/de/GGs1MbQH_o.png" alt="在这里插入图片描述"></p> 
<p>对不同层次的特征使用通道注意力机制进行融合。这应该属于应用创新，没有构建新的注意力机制，而是将老的注意力机制应用到特征融合方向</p> 
<h6><a id="312_SKNet_2_41"></a>3.1.2 SKNet [2]</h6> 
<p><img src="https://images2.imgbox.com/83/8e/1oGimIql_o.png" alt="在这里插入图片描述"></p> 
<p>使用不同感受野卷积核构建多分支特征，将这些特征 add 后计算不同分支的同道注意力系数，后沿着通道方向进行加权求和</p> 
<h5><a id="32__47"></a>3.2 分组</h5> 
<h6><a id="321_SGNet_3_49"></a>3.2.1 SGNet [3]</h6> 
<p><img src="https://images2.imgbox.com/03/c9/GOzTTouE_o.png" alt="在这里插入图片描述"></p> 
<p>对每个组，先计算向量x的平均值（全局平均池化），后将利用该向量对特征图沿着通道 方向加权求和得到 空间注意力，再归一化，后经sigmoid函数输出</p> 
<h6><a id="322_SANet_4_55"></a>3.2.2 SANet [4]</h6> 
<p><img src="https://images2.imgbox.com/3c/17/iWS992sm_o.png" alt="在这里插入图片描述"></p> 
<p>将特征沿着通道分组，对每一组，再分成 空间注意力 和 通道注意力。对空间注意力，使用Group normalization实现。将分组结果进行拼接，后使用类似ShufflfleNet v2的方法进行channel shuffle</p> 
<h5><a id="33_Self_Attention_61"></a>3.3 Self Attention</h5> 
<h6><a id="331_non_local_attention_5_63"></a>3.3.1 non local attention [5]</h6> 
<p><img src="https://images2.imgbox.com/9b/8e/Wsnhr5xC_o.png" alt="在这里插入图片描述"></p> 
<p>定义了不同形式计算向量相似性的函数，提出self attention是non local attention 的特例</p> 
<h6><a id="332_GCNet_6_70"></a>3.3.2 GCNet [6]</h6> 
<p><img src="https://images2.imgbox.com/ae/2a/YfPpQHHb_o.png" alt="在这里插入图片描述"></p> 
<p>指出non local attention不同位置的attention map基本一致，只计算C<em>1</em>1的特征图</p> 
<h6><a id="333_dual_attention_7_76"></a>3.3.3 dual attention [7]</h6> 
<p><img src="https://images2.imgbox.com/46/fb/r2BoZSdR_o.png" alt="在这里插入图片描述"></p> 
<p>并联non local attention 和 GCnet</p> 
<h5><a id="34__82"></a>3.4 空间+通道</h5> 
<h6><a id="341_BAM_8_84"></a>3.4.1 BAM [8]</h6> 
<p><img src="https://images2.imgbox.com/3a/41/FmRSiBQ0_o.png" alt="在这里插入图片描述"></p> 
<p>并联，attention map先相加（利用了广播机制），后与原特征图相乘</p> 
<h6><a id="342_scSE_9_91"></a>3.4.2 scSE [9]</h6> 
<p><img src="https://images2.imgbox.com/36/b2/0PVk6p8D_o.png" alt="在这里插入图片描述"></p> 
<p>并联，attention map先各自相乘，后取最大值得到最终输出</p> 
<h4><a id="_97"></a>参考文献</h4> 
<p><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Changqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.pdf" rel="nofollow">[1] BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a></p> 
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Selective_Kernel_Networks_CVPR_2019_paper.pdf" rel="nofollow">[2] Selective Kernel Networks</a></p> 
<p><a href="https://arxiv.org/pdf/1905.09646.pdf" rel="nofollow">[3] Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks</a></p> 
<p><a href="https://arxiv.org/pdf/2102.00240.pdf" rel="nofollow">[4] SA-NET: SHUFFLE ATTENTION FOR DEEP CONVOLUTIONAL NEURAL NETWORKS</a></p> 
<p><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf" rel="nofollow">[5] Non-local Neural Networks</a></p> 
<p><a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Cao_GCNet_Non-Local_Networks_Meet_Squeeze-Excitation_Networks_and_Beyond_ICCVW_2019_paper.pdf" rel="nofollow">[6] GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</a></p> 
<p><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.pdf" rel="nofollow">[7] Dual Attention Network for Scene Segmentation</a></p> 
<p><a href="https://arxiv.org/pdf/1807.06514.pdf" rel="nofollow">[8] BAM: Bottleneck Attention Module</a></p> 
<p><a href="https://arxiv.org/pdf/1808.08127.pdf" rel="nofollow">[9] Recalibrating Fully Convolutional Networks with Spatial and Channel ‘Squeeze &amp; Excitation’ Blocks</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1b8ab4b481b25282d116b0339bad8366/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">微信小程序，bindtap 的语法格式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/004798b10c6f857d7bf74b11e2d9f01a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于SpringBoot的服装生产管理系统的设计与实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>