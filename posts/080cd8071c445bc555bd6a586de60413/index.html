<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka核心概念、优势、应用场景与基本架构 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Kafka核心概念、优势、应用场景与基本架构" />
<meta property="og:description" content="一、 Kafka介绍 Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多生产者、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。
主要应用场景是：日志收集系统和消息系统。
Kafka主要设计目标如下：
以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。同时支持离线数据处理和实时数据处理。支持在线水平扩展 有两种主要的消息传递模式：点对点传递模式、发布-订阅模式。大部分的消息系统选用发布-订阅模式。Kafka就是一种发布-订阅模式。
对于消息中间件，消息分推拉两种模式。Kafka只有消息的拉取，没有推送，可以通过轮询实现消息的推送。
Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行。Kafka集群中按照主题分类管理，一个主题可以有多个分区，一个分区可以有多个副本分区。每个记录由一个键，一个值和一个时间戳组成。 Kafka具有四个核心API：
Producer API：允许应用程序将记录流发布到一个或多个Kafka主题。Consumer API：允许应用程序订阅一个或多个主题并处理为其生成的记录流。Streams API：允许应用程序充当流处理器，使用一个或多个主题的输入流，并生成一个或多
个输出主题的输出流，从而有效地将输入流转换为输出流。Connector API：允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者
或使用者。例如，关系数据库的连接器可能会捕获对表的所有更改。 二、Kafka优势 高吞吐量：单机每秒处理几十上百万的消息量。即使存储了许多TB的消息，它也保持稳定的性能。高性能：单节点支持上千个客户端，并保证零停机和零数据丢失。持久化数据存储：将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。 零拷贝顺序读，顺序写利用Linux的页缓存 分布式系统，易于向外扩展。所有的Producer、Broker和Consumer都会有多个，均为分布式
的。无需停机即可扩展机器。多个Producer、Consumer可能是不同的应用。可靠性 - Kafka是分布式，分区，复制和容错的。客户端状态维护：消息被处理的状态是在Consumer端维护，而不是由server端维护。当失败
时能自动平衡。支持online和offline的场景。支持多种客户端语言。Kafka支持Java、.NET、PHP、Python等多种语言。 三、 Kafka应用场景 日志收集：一个公司可以用Kafka可以收集各种服务的Log，通过Kafka以统一接口服务的方式开放给各种Consumer；
消息系统：解耦生产者和消费者、缓存消息等；
用户活动跟踪：Kafka经常被用来记录Web用户或者App用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到Kafka的Topic中，然后消费者通过订阅这些Topic来做实时的监控分析，亦可保存到数据库；
运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；
流式处理：比如Spark Streaming和Storm。
四、基本架构 1、消息和批次 Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。消息由字节数组组成。
消息有键，键也是一个字节数组。当消息以一种可控的方式写入不同的分区时，会用到键。
为了提高效率，消息被分批写入Kafka。批次就是一组消息，这些消息属于同一个主题和分区。
把消息分成批次可以减少网络开销。批次越大，单位时间内处理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据的传输和存储能力，但是需要更多的计算处理。
2、模式 消息模式（schema）有许多可用的选项，以便于理解。如JSON和XML，但是它们缺乏强类型处理能力。Kafka的许多开发者喜欢使用Apache Avro。Avro提供了一种紧凑的序列化格式，模式和消息体分开。当模式发生变化时，不需要重新生成代码，它还支持强类型和模式进化，其版本既向前兼容，也向后兼容。
数据格式的一致性对Kafka很重要，因为它消除了消息读写操作之间的耦合性。
3、主题和分区 Kafka的消息通过主题进行分类。主题可比是数据库的表或者文件系统里的文件夹。主题可以被分为若干分区，一个主题通过分区分布于Kafka集群中，提供了横向扩展的能力。
4、生产者和消费者 生产者创建消息。消费者消费消息。
一个消息被发布到一个特定的主题上。
生产者在默认情况下把消息均衡地分布到主题的所有分区上：
直接指定消息的分区根据消息的key散列取模得出分区轮询指定分区。 消费者通过偏移量来区分已经读过的消息，从而消费消息。
消费者是消费组的一部分。消费组保证每个分区只能被一个消费者使用，避免重复消费。
5、broker和集群 一个独立的Kafka服务器称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。单个broker可以轻松处理数千个分区以及每秒百万级的消息量。
每个集群都有一个broker是集群控制器（自动从集群的活跃成员中选举出来）。
控制器负责管理工作：
将分区分配给broker监控broker 集群中一个分区属于一个broker，该broker称为分区首领。
一个分区可以分配给多个broker，此时会发生分区复制。
分区的复制提供了消息冗余，高可用。副本分区不负责处理消息的读写。
五、核心概念 1、Producer 生产者创建消息。
该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的 segment 文件中。
一般情况下，一个消息会被发布到一个特定的主题上。
默认情况下通过轮询把消息均衡地分布到主题的所有分区上。在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区 2、Consumer 消费者读取消息。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/080cd8071c445bc555bd6a586de60413/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-26T16:30:20+08:00" />
<meta property="article:modified_time" content="2022-07-26T16:30:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka核心概念、优势、应用场景与基本架构</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_Kafka_0"></a>一、 Kafka介绍</h3> 
<p>Kafka是最初由Linkedin公司开发，是一个分布式、分区的、多副本的、多生产者、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等等，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p> 
<p>主要应用场景是：日志收集系统和消息系统。</p> 
<p>Kafka主要设计目标如下：</p> 
<ul><li>以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</li><li>高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。</li><li>支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。</li><li>同时支持离线数据处理和实时数据处理。</li><li>支持在线水平扩展</li></ul> 
<p><img src="https://images2.imgbox.com/a2/6c/veyYK6IF_o.png" alt="在这里插入图片描述"><br> 有两种主要的消息传递模式：<strong>点对点传递模式、发布-订阅模式</strong>。大部分的消息系统选用发布-订阅模式。<strong>Kafka就是一种发布-订阅模式</strong>。</p> 
<p>对于消息中间件，消息分推拉两种模式。<strong>Kafka只有消息的拉取</strong>，没有推送，可以通过轮询实现消息的推送。</p> 
<ol><li>Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行。</li><li>Kafka集群中按照主题分类管理，一个主题可以有多个分区，一个分区可以有多个副本分区。</li><li>每个记录由一个键，一个值和一个时间戳组成。</li></ol> 
<p>Kafka具有四个核心API：</p> 
<ol><li>Producer API：允许应用程序将记录流发布到一个或多个Kafka主题。</li><li>Consumer API：允许应用程序订阅一个或多个主题并处理为其生成的记录流。</li><li>Streams API：允许应用程序充当流处理器，使用一个或多个主题的输入流，并生成一个或多<br> 个输出主题的输出流，从而有效地将输入流转换为输出流。</li><li>Connector API：允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者<br> 或使用者。例如，关系数据库的连接器可能会捕获对表的所有更改。</li></ol> 
<h3><a id="Kafka_31"></a>二、Kafka优势</h3> 
<ol><li>高吞吐量：单机每秒处理几十上百万的消息量。即使存储了许多TB的消息，它也保持稳定的性能。</li><li>高性能：单节点支持上千个客户端，并保证零停机和零数据丢失。</li><li>持久化数据存储：将消息持久化到磁盘。通过将数据持久化到硬盘以及replication防止数据丢失。 
  <ul><li>零拷贝</li><li>顺序读，顺序写</li><li>利用Linux的页缓存</li></ul> </li><li>分布式系统，易于向外扩展。所有的Producer、Broker和Consumer都会有多个，均为分布式<br> 的。无需停机即可扩展机器。多个Producer、Consumer可能是不同的应用。</li><li>可靠性 - Kafka是分布式，分区，复制和容错的。</li><li>客户端状态维护：消息被处理的状态是在Consumer端维护，而不是由server端维护。当失败<br> 时能自动平衡。</li><li>支持online和offline的场景。</li><li>支持多种客户端语言。Kafka支持Java、.NET、PHP、Python等多种语言。</li></ol> 
<h3><a id="_Kafka_46"></a>三、 Kafka应用场景</h3> 
<ol><li> <p>日志收集：一个公司可以用Kafka可以收集各种服务的Log，通过Kafka以统一接口服务的方式开放给各种Consumer；</p> </li><li> <p>消息系统：解耦生产者和消费者、缓存消息等；</p> </li><li> <p>用户活动跟踪：Kafka经常被用来记录Web用户或者App用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到Kafka的Topic中，然后消费者通过订阅这些Topic来做实时的监控分析，亦可保存到数据库；</p> </li><li> <p>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；</p> </li><li> <p>流式处理：比如Spark Streaming和Storm。</p> </li></ol> 
<h4><a id="_55"></a>四、基本架构</h4> 
<h4><a id="1_56"></a>1、消息和批次</h4> 
<p>Kafka的数据单元称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。消息由字节数组组成。</p> 
<p>消息有键，键也是一个字节数组。当消息以一种可控的方式写入不同的分区时，会用到键。</p> 
<p>为了提高效率，消息被分批写入Kafka。批次就是一组消息，这些消息属于同一个主题和分区。</p> 
<p>把消息分成批次可以减少网络开销。批次越大，单位时间内处理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据的传输和存储能力，但是需要更多的计算处理。</p> 
<h4><a id="2_65"></a>2、模式</h4> 
<p>消息模式（schema）有许多可用的选项，以便于理解。如JSON和XML，但是它们缺乏强类型处理能力。Kafka的许多开发者喜欢使用Apache Avro。Avro提供了一种紧凑的序列化格式，模式和消息体分开。当模式发生变化时，不需要重新生成代码，它还支持强类型和模式进化，其版本既向前兼容，也向后兼容。</p> 
<p>数据格式的一致性对Kafka很重要，因为它消除了消息读写操作之间的耦合性。</p> 
<h4><a id="3_70"></a>3、主题和分区</h4> 
<p>Kafka的消息通过主题进行分类。主题可比是数据库的表或者文件系统里的文件夹。主题可以被分为若干分区，一个主题通过分区分布于Kafka集群中，提供了横向扩展的能力。</p> 
<p><img src="https://images2.imgbox.com/a4/ac/cXQME4KF_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4_74"></a>4、生产者和消费者</h4> 
<p>生产者创建消息。消费者消费消息。</p> 
<p>一个消息被发布到一个特定的主题上。</p> 
<p>生产者在默认情况下把消息均衡地分布到主题的所有分区上：</p> 
<ol><li>直接指定消息的分区</li><li>根据消息的key散列取模得出分区</li><li>轮询指定分区。</li></ol> 
<p>消费者通过偏移量来区分已经读过的消息，从而消费消息。</p> 
<p>消费者是消费组的一部分。消费组保证每个分区只能被一个消费者使用，避免重复消费。<br> <img src="https://images2.imgbox.com/59/c4/rQBDUD97_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="5broker_88"></a>5、broker和集群</h4> 
<p>一个独立的Kafka服务器称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。单个broker可以轻松处理数千个分区以及每秒百万级的消息量。</p> 
<p><img src="https://images2.imgbox.com/e5/da/tVA5ahJl_o.png" alt="在这里插入图片描述"><br> 每个集群都有一个broker是集群控制器（自动从集群的活跃成员中选举出来）。<br> 控制器负责管理工作：</p> 
<ul><li>将分区分配给broker</li><li>监控broker</li></ul> 
<p>集群中一个分区属于一个broker，该broker称为分区首领。</p> 
<p>一个分区可以分配给多个broker，此时会发生分区复制。</p> 
<p>分区的复制提供了消息冗余，高可用。副本分区不负责处理消息的读写。</p> 
<h3><a id="_103"></a>五、核心概念</h3> 
<h4><a id="1Producer_104"></a>1、Producer</h4> 
<p>生产者创建消息。</p> 
<p>该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息追加到当前用于追加数据的 segment 文件中。</p> 
<p>一般情况下，一个消息会被发布到一个特定的主题上。</p> 
<ol><li>默认情况下通过轮询把消息均衡地分布到主题的所有分区上。</li><li>在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。</li><li>生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区</li></ol> 
<h4><a id="2Consumer_114"></a>2、Consumer</h4> 
<p>消费者读取消息。</p> 
<ol><li>消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。</li><li>消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在Zookeeper 或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失。</li><li>消费者是消费组的一部分。群组保证每个分区只能被一个消费者使用。</li><li>如果一个消费者失效，消费组里的其他消费者可以接管失效消费者的工作，再平衡，分区重新分配。</li></ol> 
<p><img src="https://images2.imgbox.com/15/55/x123L1u1_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3Broker_124"></a>3、Broker</h4> 
<p>一个独立的Kafka 服务器被称为broker。</p> 
<p>broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。</p> 
<ol><li>如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。</li><li>如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</li><li>如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</li></ol> 
<p>broker 是集群的组成部分。每个集群都有一个broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。</p> 
<p>控制器负责管理工作，包括将分区分配给broker 和监控broker。</p> 
<p>在集群中，一个分区从属于一个broker，该broker 被称为分区的首领</p> 
<p><img src="https://images2.imgbox.com/c7/06/mxeWvmWy_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4Topic_141"></a>4、Topic</h4> 
<p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。</p> 
<p>物理上不同Topic的消息分开存储。</p> 
<p>主题就好比数据库的表，尤其是分库分表之后的逻辑表。</p> 
<h4><a id="5_Partition_148"></a>5、 Partition</h4> 
<ol><li>主题可以被分为若干个分区，一个分区就是一个提交日志。</li><li>消息以追加的方式写入分区，然后以先入先出的顺序读取。</li><li>无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。</li><li>Kafka 通过分区来实现数据冗余和伸缩性。</li><li>在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。<br> <img src="https://images2.imgbox.com/c8/85/PLnSKGpa_o.png" alt="在这里插入图片描述"></li></ol> 
<h4><a id="6Replicas_155"></a>6、Replicas</h4> 
<p>Kafka 使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。那些副本被保存在broker 上，每个broker 可以保存成百上千个属于不同主题和分区的副本。</p> 
<p>副本有以下两种类型：</p> 
<ol><li>首领副本<br> 每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。</li><li>跟随者副本<br> 首领以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求，它们唯一的任务就是从首领那里复制消息，保持与首领一致的状态。如果首领发生崩溃，其中的一个跟随者会被提升为新首领。</li></ol> 
<h4><a id="7Offset_164"></a>7、Offset</h4> 
<ol><li>生产者Offset<br> 消息写入的时候，每一个分区都有一个offset，这个offset就是生产者的offset，同时也是这个分区的最新最大的offset。<br> 有些时候没有指定某一个分区的offset，这个工作kafka帮我们完成。</li></ol> 
<p><img src="https://images2.imgbox.com/61/61/xZdsTjSR_o.png" alt="在这里插入图片描述"><br> 2. 消费者Offset<br> <img src="https://images2.imgbox.com/f3/48/bbJefw4I_o.png" alt="在这里插入图片描述"><br> 这是某一个分区的offset情况，生产者写入的offset是最新最大的值是12，而当Consumer A进行消费时，从0开始消费，一直消费到了9，消费者的offset就记录在9，Consumer B就纪录在了11。等下一次他们再来消费时，他们可以选择接着上一次的位置消费，当然也可以选择从头消费，或者跳到最近的记录并从“现在”开始消费。</p> 
<h4><a id="8__174"></a>8、 副本</h4> 
<p>Kafka通过副本保证高可用。副本分为首领副本(Leader)和跟随者副本(Follower)。</p> 
<p>跟随者副本包括同步副本和不同步副本，在发生首领副本切换的时候，只有同步副本可以切换为首领副本。</p> 
<ol><li>AR<br> 分区中的所有副本统称为AR（Assigned Repllicas）。<br> AR=ISR+OSR</li><li>ISR<br> 所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度”是指可以忍受的滞后范围，这个范围可以通过参数进行配置。</li><li>OSR<br> 与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas)。在正常情况下，所有的follower副本都应该与leader副本保持一定程度的同步，即AR=ISR,OSR集合为空。</li><li>HW<br> HW是High Watermak的缩写， 俗称高水位，它表示了一个特定消息的偏移量（offset），消费之只能拉取到这个offset之前的消息。</li><li>LEO<br> LEO是Log End Offset的缩写，它表示了当前日志文件中下一条待写入消息的offset</li></ol> 
<p><img src="https://images2.imgbox.com/d3/23/8A8iNjoY_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/24f35f61dd8d0c0b8cbc9594bed24008/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SSH原理与使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4087d1c87f7f96325cc04d2954b7e7ac/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">（二）vsftpd服务配置多用户多目录权限</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>