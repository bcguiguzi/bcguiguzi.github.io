<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>计算机视觉领域2019年,计算机视觉领域2019推荐论文列表 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="计算机视觉领域2019年,计算机视觉领域2019推荐论文列表" />
<meta property="og:description" content="1. Deep High-Resolution Representation Learning for Human Pose Estimation
该论文在提出了一个新的网络High-Resolution Network (HRNet)，可以学到空间精度高语义强的高分辨率表。该网络设计的不同于其他主流网络的有两大关键点：一直保持高分辨率表征；并联不同分辨率的卷积分支。在人体骨架点检测以及目标检测、图像语义分割、人脸 关键点检测等视觉问题上取得了领先的结果，被同行广泛接受和使用。该论文发表在CVPR 2019。
开源地址：https://github.com/HRNet
https://github.com/leoxiaobin/deep-high-resolution-net.pytorch
2. VL-BERT: Pre-training of Generic Visual-Linguistic Representations
该文发表于ICLR 2020，是最早提出图像和文本联合预训练模型的论文之一。研究员提出了一种新的通用的多模态预训练模型VL-BERT，该模型采用简单而强大的Transformer模型作为主干网络，并将其输入扩展为同时包含视觉与语言输入的多模态形式，适用于绝大多数视觉语义下游任务。为了让VL-BERT模型利用更为通用的特征表示，研究员在大规模图片描述生成数据集Conceptual Captions中进行VL-BERT的预训练，实验证明此预训练过程可以显著提高下游的视觉语义任务的效果，包含视觉常识推理、视觉问答与引用表达式理解等。
3. A Relation Network Based Approach to Curved Text Detection
该论文创新地提出了一套基于关系网络(Relation Network)的新型文字检测框架，有效提升了通用文本行检测的准确率。该论文发表在ICDAR 2019会上。
4. An Anchor-free Region Proposal Network for Faster R-CNN-based Text Detection Approaches
该论文提出了一种称为anchor-free RPN的物体检测算法来解决经典RPN算法无法有效预测任意方向文本框的问题。该算法不仅在单词级别的文字检测任务上取得很好的结果，而且类似思想在当前物体检测领域也成为主流。该论文发表在IJDAR期刊上。
6. Compressing CNN-DBLSTM Models for OCR with Teacher-Student Learning and Tucker Decomposition
该论文提出了一种针对CNN-DBLSTM模型中运算代价最大的CNN部分进行压缩加速的方法，即首先在LSTM部分的指导下，对CNN部分进行知识蒸馏，然后利用Tucker分解算法，对CNN进行进一步压缩和加速，由此得到的模型运行时相比原始模型加速14倍，解决了部署难题。该论文发表在Pattern Recognition期刊上。
7. An Open Vocabulary OCR System with Hybrid Word-Subword Language Models" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/08cea5409598019288f2297ec37ddf9b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-07-30T09:50:58+08:00" />
<meta property="article:modified_time" content="2021-07-30T09:50:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">计算机视觉领域2019年,计算机视觉领域2019推荐论文列表</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>1. Deep High-Resolution Representation Learning for Human Pose Estimation</p> 
 <p>该论文在提出了一个新的网络High-Resolution Network (HRNet)，可以学到空间精度高语义强的高分辨率表。该网络设计的不同于其他主流网络的有两大关键点：一直保持高分辨率表征；并联不同分辨率的卷积分支。在人体骨架点检测以及目标检测、图像语义分割、人脸 关键点检测等视觉问题上取得了领先的结果，被同行广泛接受和使用。该论文发表在CVPR 2019。</p> 
 <p>开源地址：https://github.com/HRNet</p> 
 <p>https://github.com/leoxiaobin/deep-high-resolution-net.pytorch</p> 
 <p>2. VL-BERT: Pre-training of Generic Visual-Linguistic Representations</p> 
 <p>该文发表于ICLR 2020，是最早提出图像和文本联合预训练模型的论文之一。研究员提出了一种新的通用的多模态预训练模型VL-BERT，该模型采用简单而强大的Transformer模型作为主干网络，并将其输入扩展为同时包含视觉与语言输入的多模态形式，适用于绝大多数视觉语义下游任务。为了让VL-BERT模型利用更为通用的特征表示，研究员在大规模图片描述生成数据集Conceptual Captions中进行VL-BERT的预训练，实验证明此预训练过程可以显著提高下游的视觉语义任务的效果，包含视觉常识推理、视觉问答与引用表达式理解等。</p> 
 <p>3. A Relation Network Based Approach to Curved Text Detection</p> 
 <p>该论文创新地提出了一套基于关系网络(Relation Network)的新型文字检测框架，有效提升了通用文本行检测的准确率。该论文发表在ICDAR 2019会上。</p> 
 <p>4. An Anchor-free Region Proposal Network for Faster R-CNN-based Text Detection Approaches</p> 
 <p>该论文提出了一种称为anchor-free RPN的物体检测算法来解决经典RPN算法无法有效预测任意方向文本框的问题。该算法不仅在单词级别的文字检测任务上取得很好的结果，而且类似思想在当前物体检测领域也成为主流。该论文发表在IJDAR期刊上。</p> 
 <p>6. Compressing CNN-DBLSTM Models for OCR with Teacher-Student Learning and Tucker Decomposition</p> 
 <p>该论文提出了一种针对CNN-DBLSTM模型中运算代价最大的CNN部分进行压缩加速的方法，即首先在LSTM部分的指导下，对CNN部分进行知识蒸馏，然后利用Tucker分解算法，对CNN进行进一步压缩和加速，由此得到的模型运行时相比原始模型加速14倍，解决了部署难题。该论文发表在Pattern Recognition期刊上。</p> 
 <p>7. An Open Vocabulary OCR System with Hybrid Word-Subword Language Models</p> 
 <p>该论文提出了一种以词与子词为基本语言单元的混合语言模型，来解决光学字符识别(OCR)中的集外词(Out of Vocabulary, OOV)问题。该论文发表在ICDAR 2017 会上。</p> 
 <p>8. Relation Networks for Object Detection</p> 
 <p>在CVPR 2018上，该论文提出了一种即插即用的物体关系模块，第一次实现了完全端到端的物体检测器，该方法也是自注意力模型在视觉领域最早的应用之一。</p> 
 <p>9. Learning Region Features for Object Detection</p> 
 <p>在ECCV 2018上，该论文给出了区域特征提取的通用表达式，并提出了一个完全可学习的区域特征提取方法。</p> 
 <p>10. Local Relation Networks for Image Recognition</p> 
 <p>在ICCV 2019上，该论文提出了一种新的完全无需卷积的神经网络，在ImageNet图像分类基准数据集上取得了超越卷积神经网络的准确率。</p> 
 <p>12. An Empirical Study of Spatial Attention Mechanisms in Deep Networks</p> 
 <p>在ICCV 2019上，研究员提出了一种关于空间注意力机制的通用表达形式，并分析了这一通用表达形式中不同的表达项在各种视觉任务上的表现，为今后空间注意力机制的应用提供参考。</p> 
 <p>13. Deep Metric Transfer for Label Propagation with Limited Annotated Data</p> 
 <p>该论文提出了一种新的半监督学习/迁移学习/小样本学习范式，该范式的核心是利用无监督预训练方法来获得初始图像特征，其在半监督学习上取得近20%(绝对值)的准确率提升，文章发表在ICCVW 2019上。</p> 
 <p>14. Deformable ConvNets v2: More Deformable, Better Results</p> 
 <p>在CVPR 2019上，该论文提出了更强的可变形卷积网络，相比标准卷积其能广泛且显著提升各种视觉感知任务的准确率，包括图像分类，物体检测，语义分割，物体跟踪等等，例如在COCO物体检测基准测试中，相比相同条件下的标准卷积网络能取得近7个点的提升。</p> 
 <p>15. RepPoints: Point Set Representation for Object Detection</p> 
 <p>边界框是视觉物体表示的标准方法，在ICCV 2019上，该论文提出了一种基于点集来替代边界框的物体表示新方法，这一新方法具有更强的表示能力和可解释性。基于这一新的表示，得到了当时最好的无锚点检测器。这一表示方法最近还被推广到实例分割和人体姿态估计中。</p> 
 <p>16. A Twofold Siamese Network for Real-Time Object Tracking</p> 
 <p>该文章发表在CVPR 2018上，提出了双路孪生网络进行视觉物体跟踪的方案，简称为SA-Siam，其中S代表的是语义(Semantic)分支，而A则代表外观(Appearance)分支。两个分支既独立又互补，取得了极佳的跟踪效果。</p> 
 <p>17. SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking</p> 
 <p>在CVPR 2019上，该文章提出了双阶段匹配和创新的串并联结构实现物体的鲁棒、精准跟踪。SPM跟踪器在粗匹配阶段侧重语义理解，在细匹配阶段侧重外观表达，并通过不同训练方式获得了理想的平衡。</p> 
 <p>18. Unsupervised High-Resolution Depth Learning from Videos With Dual Networks</p> 
 <p>文章发表在ICCV 2019上，提出了基于双网络结构的深度估计学习架构，使用较深的网络提取低分辨率输入图像中的全局特征信息，使用较浅的网络提取高分辨输入图像中的细节特征信息，再将二者结合用来估计高分辨率的深度。与以往方法相比，该方法以更低的计算量获取了更好的深度估计效果，特别是对于图像的精细区域和远距离区域等对分辨率敏感区域的深度估计结果提升显著。</p> 
 <p>19. Moving Indoor: Unsupervised Video Depth Learning in Challenging Environments</p> 
 <p>在ICCV 2019上，该文章提出了更为鲁棒的光流重建监督信号，以解决难度更大的室内场景下的无监督深度估计。与传统的图像重建信号相比，针对纹理缺失严重的室内场景，利用稀疏到稠密的光流估计方法获取稳定的光流估计，并将光流信息输入相机估计网络克服相机运动复杂的难题，从而实现了深度布局更为复杂多样的室内场景下的稳定的深度估计。</p> 
 <p>20. Cross View Fusion for 3D Human Pose Estimation</p> 
 <p>文章发表在ICCV 2019上，提出了首个跨摄像头的特征融合网络，通过将“容易”视角的特征融合到“困难”视角，有效地解决了遮挡问题。在Benchmark数据集上显著降低了三维姿态的估计误差。</p> 
 <p>21. Optimizing Network Structure for 3D Human Pose Estimation</p> 
 <p>在ICCV 2019上，该文章提出了基于人体模型的网络Locally Connected Network，该网络参数量少，能够有效缓解Over-fitting。</p> 
 <p>23. Part-Aligned Bilinear Representations for Person Re-identification</p> 
 <p>该文在作者前面的工作弱监督 Deeply-Learned Part-Aligned Representations(https://arxiv.org/pdf/1707.07256.pdf)基础上，引进了人体姿态来帮助人体部件对齐，提升了行人重识别性能。该文发表在ECCV 2018。</p> 
 <p>24. Semantics-Aligned Representation Learning for Person Re-identification</p> 
 <p>本文即将发表在AAAI 2020上，提出了基于语义对齐的特征学习网络进行行人重识别。我们通过引入对人体空间语义对齐的全视图的重建任务，实现了赋予网络由单(视角)张图像预测全视角人体外观的能力，解决了行人重识别中图像间空间语义不对齐的难题。</p> 
 <p>25. Uncertainty-aware Multi-shot Knowledge Distillation for Image-based Object Re-identification</p> 
 <p>将发表在AAAI 2020上，通过对同一目标的不同图片的信息的联合学习，获取更全面的对该目标的特征表达，并利用Teacher-Student网络来针对性地将学到的更全面的信息传递给学生网络(单张图像为输入)，实现了测试阶段仅需要单张图片作为输入，但更全面和高判别力的特征提取。</p> 
 <p>26. Mask-Guided Portrait Editing with Conditional GANs</p> 
 <p>文章发表于CVPR 2019，本模型解决了人脸合成中的三个问题：多样性，高质量和可控性。在本文中，研究员们提出了一个基于cGAN的框架，可以分别对眼睛、鼻子、嘴、皮肤和头发进行编辑。我们的模型有许多应用，例如人脸编辑，改变发型，放大眼睛，或者使其微笑。此外，研究员们可以局部修改现有人脸的外观。</p> 
 <p>27. Learning Pyramid Context Encoder Network for High-Quality Image Inpainting</p> 
 <p>论文发表CVPR 2019， 基于“由深到浅，多次补全”的构想，提出了一种金字塔式注意力机制的上下文编码网络，可以生成语义合理且纹理细节丰富的图像内容。</p> 
 <p>28. Learning 2D Temporal Adjacent Network for Moment Localization with Natural Language</p> 
 <p>论文发表在AAAI 2020，提出了时序信息处理问题中一种全新的建模思路——二维时间图，在基于自然语言描述的视频内容定位和视频内人体动作检测两个任务上验证了其有效性。</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7e6b94dd6cdb900aa08665b79087ef1b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">win10打开视频显示服务器运行失败,windows10系统无法播放GoPro视频的解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e185b415727887767094abe9360c8c2f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">推荐几个非常棒的学习计算机语言的网站</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>