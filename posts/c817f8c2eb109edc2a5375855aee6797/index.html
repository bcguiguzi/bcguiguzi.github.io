<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Requests-翻页请求实现 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Requests-翻页请求实现" />
<meta property="og:description" content="翻页请求实现 继https://blog.csdn.net/ssslq/article/details/130747686之后，本篇详述在获取了页面第一页之后，如何获取剩余页的标题内容。
网页：https://books.toscrape.com
找规律 同样还是进行页面的检查，切到网络一栏，找到头部对应的URL。
然后切到第二页，再去观察URL是否变化：
现在发现后面多了路径/catalogue/page-2.html，第二页对应了2.html，那么第一页是否是对应了1.html，试验一下：
发现使用了1.html之后返回到了首页，也就是第一页，现在大概明白了，每一页都可以使用X.html进行访问。这个页面总共有50页可以进行选择，既然第一页的书名已经进行了输出，那如果要访问50页，那就需要使用循环进行输出。
仅第一页代码 from bs4 import BeautifulSoup import requests headers = { &#34;User-Agent&#34;:&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36&#34; }#请求头改成自己的 url = &#34;https://books.toscrape.com/catalogue/page-1.html&#34; responce = requests.get(url,headers=headers).text soup = BeautifulSoup(responce,&#34;html.parser&#34;) all_title = soup.findAll(&#34;h3&#34;) for i in all_title: title = i.find(&#34;a&#34;) print(title.string) 加循环后的代码 from bs4 import BeautifulSoup import requests headers = { &#34;User-Agent&#34;:&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/c817f8c2eb109edc2a5375855aee6797/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-18T16:36:29+08:00" />
<meta property="article:modified_time" content="2023-05-18T16:36:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Requests-翻页请求实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>翻页请求实现</h2> 
<p>继<a href="https://blog.csdn.net/ssslq/article/details/130747686">https://blog.csdn.net/ssslq/article/details/130747686</a>之后，本篇详述在获取了页面第一页之后，如何获取剩余页的标题内容。<br> 网页：<a href="https://books.toscrape.com" rel="nofollow">https://books.toscrape.com</a></p> 
<h3><a id="_3"></a>找规律</h3> 
<p>同样还是进行页面的检查，切到网络一栏，找到头部对应的URL。<img src="https://images2.imgbox.com/cc/76/ZA9VniZI_o.png" alt="在这里插入图片描述"><br> 然后切到第二页，再去观察URL是否变化：<br> <img src="https://images2.imgbox.com/9b/57/5eYL4SZq_o.png" alt="在这里插入图片描述"><br> 现在发现后面多了路径/catalogue/page-2.html，第二页对应了2.html，那么第一页是否是对应了1.html，试验一下：<br> <img src="https://images2.imgbox.com/ab/d9/WjUIxKhU_o.png" alt="在这里插入图片描述"><br> 发现使用了1.html之后返回到了首页，也就是第一页，现在大概明白了，每一页都可以使用X.html进行访问。这个页面总共有50页可以进行选择，既然第一页的书名已经进行了输出，那如果要访问50页，那就需要使用循环进行输出。<br> <img src="https://images2.imgbox.com/87/dc/r4jwyCe3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_11"></a>仅第一页代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token keyword">import</span> requests

headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36"</span>
<span class="token punctuation">}</span><span class="token comment">#请求头改成自己的</span>
url <span class="token operator">=</span> <span class="token string">"https://books.toscrape.com/catalogue/page-1.html"</span>

responce <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span><span class="token punctuation">.</span>text

soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>responce<span class="token punctuation">,</span><span class="token string">"html.parser"</span><span class="token punctuation">)</span>

all_title <span class="token operator">=</span> soup<span class="token punctuation">.</span>findAll<span class="token punctuation">(</span><span class="token string">"h3"</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> all_title<span class="token punctuation">:</span>

    title <span class="token operator">=</span> i<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span>title<span class="token punctuation">.</span>string<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_36"></a>加循环后的代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token keyword">import</span> requests

headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span><span class="token string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36"</span>
<span class="token punctuation">}</span><span class="token comment">#请求头改成自己的</span>

<span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">51</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    url <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"https://books.toscrape.com/catalogue/page-</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>j<span class="token punctuation">}</span></span><span class="token string">.html"</span></span>

    responce <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span><span class="token punctuation">.</span>text
    
    soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>responce<span class="token punctuation">,</span><span class="token string">"html.parser"</span><span class="token punctuation">)</span>
    
    all_title <span class="token operator">=</span> soup<span class="token punctuation">.</span>findAll<span class="token punctuation">(</span><span class="token string">"h3"</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> all_title<span class="token punctuation">:</span>
    
        title <span class="token operator">=</span> i<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">)</span>
        
        <span class="token keyword">print</span><span class="token punctuation">(</span>title<span class="token punctuation">.</span>string<span class="token punctuation">)</span>

</code></pre> 
<p>代码注释：</p> 
<ol><li> <p><code>from bs4 import BeautifulSoup</code>: 导入BeautifulSoup库，这是为了使用其中的解析和提取功能。</p> </li><li> <p><code>import requests</code>: 导入requests库，这是为了发送HTTP请求获取网页内容。</p> </li><li> <p><code>headers = {...}</code>: 定义了一个字典类型的变量<code>headers</code>，其中包含了请求头信息。这个请求头信息中设置了User-Agent字段，模拟浏览器发送请求。</p> </li><li> <p><code>for j in range(1,51):</code>: 这是一个循环语句，从1到50循环遍历，用于处理多个页面。</p> </li><li> <p><code>url = f"https://books.toscrape.com/catalogue/page-{j}.html"</code>: 根据循环变量<code>j</code>的值构建每个页面的URL地址。<code>f-string</code>用于在字符串中插入变量的值。</p> </li><li> <p><code>response = requests.get(url, headers=headers).text</code>: 发送HTTP GET请求到指定的URL，并获取响应对象。<code>.text</code>将响应内容以文本形式返回。将获取到的响应文本赋值给<code>response</code>变量。</p> </li><li> <p><code>soup = BeautifulSoup(response, "html.parser")</code>: 使用BeautifulSoup库将获取到的响应文本进行解析，创建一个BeautifulSoup对象。传入参数<code>response</code>作为要解析的文档内容，以及解析器类型"html.parser"。</p> </li><li> <p><code>all_title = soup.findAll("h3")</code>: 使用BeautifulSoup对象的<code>findAll</code>方法，查找所有<code>&lt;h3&gt;</code>标签，并将结果存储在变量<code>all_title</code>中。<code>findAll</code>返回一个列表，其中包含了所有匹配的标签。</p> </li><li> <p><code>for i in all_title:</code>: 对于<code>all_title</code>列表中的每个元素进行迭代。</p> </li><li> <p><code>title = i.find("a")</code>: 在当前迭代的<code>&lt;h3&gt;</code>标签中，使用<code>find</code>方法查找第一个<code>&lt;a&gt;</code>标签，并将结果存储在变量<code>title</code>中。</p> </li><li> <p><code>print(title.string)</code>: 打印<code>title</code>标签的文本内容，即书籍的标题。使用<code>.string</code>获取标签内的文本。</p> </li></ol> 
<p>这段代码的作用是从多个页面中爬取书籍标题信息，并将其打印出来。通过循环遍历不同的页面，每个页面的URL地址中的页码部分会随着循环变量<code>j</code>的值而改变。代码使用requests库发送HTTP请求获取网页内容，然后使用BeautifulSoup库解析网页并提取所需信息。最后通过循环打印出每个页面中的书籍标题。</p> 
<p>具体爬还要多实践，才能越来越熟练。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2def154fe72e1e199ac64f5a2076c09b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CompletableFuture的正常，异常，timeout和cancel</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/647ee0f76e7a0d112ec5c570b5028587/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">云发布的Docker部署文档</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>