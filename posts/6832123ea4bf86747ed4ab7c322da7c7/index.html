<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[CS231n-assignment2] Python从零实现的CNN在CIFAR-10上的实验报告 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[CS231n-assignment2] Python从零实现的CNN在CIFAR-10上的实验报告" />
<meta property="og:description" content="1. CS231n课程 CS231n是斯坦福大学李飞飞团队的一门关于卷积神经网络CNN的课程，这个课程从KNN和线性分类器讲到普通的神经网络，再将到卷积神经网络的实现，以及一些实用的技术如Dropout、Batch Normalization等，整个课程下来后会对CNN有个比较全面的了解。这个课程通俗易懂，是入门深度学习的良心课程，不仅图文结合阐述了网络正向和反向传播的过程，还会介绍一些在实用中的应用的trick如训练过程的梯度检查、如何判断学习率大小、如何判断过拟合等等，以及相应的解决方法
官方网站：http://cs231n.github.io/ 知乎中文翻译：https://zhuanlan.zhihu.com/p/21930884
1.2 Assignment 2 使用 配套CS231n课程的有两次作业，作业2主要有四部分内容：全连接层的实现、Batch Normalization、Dropout和卷积层的实现，CS231n有作业的初始模板，可以在此下载，模板里已经填好了实现这些网络的部分代码，学习者只需要在特定的方法中填写自己的代码即可，例如下面全连接层的forward方法，只需理解了课程笔记后按照提示在TODO中填写代码，填写完后，模板中还提供了方法来检查你代码的正确性：运行IPython notebook，这个notebook会引导你如何填写代码并测试代码，最后会在CIFAR-10数据集上测试你的CNN的准确性。
def affine_forward(x, w, b): &#34;&#34;&#34; Computes the forward pass for an affine (fully-connected) layer. The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N examples, where each example x[i] has shape (d_1, ..., d_k). We will reshape each input into a vector of dimension D = d_1 * ... * d_k, and then transform it to an output vector of dimension M." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/6832123ea4bf86747ed4ab7c322da7c7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-06-05T19:13:45+08:00" />
<meta property="article:modified_time" content="2017-06-05T19:13:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[CS231n-assignment2] Python从零实现的CNN在CIFAR-10上的实验报告</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2 id="1-cs231n课程">1. CS231n课程</h2> 
<p>CS231n是斯坦福大学李飞飞团队的一门关于卷积神经网络CNN的课程，这个课程从KNN和线性分类器讲到普通的神经网络，再将到卷积神经网络的实现，以及一些实用的技术如Dropout、Batch Normalization等，整个课程下来后会对CNN有个比较全面的了解。这个课程通俗易懂，是入门深度学习的良心课程，不仅图文结合阐述了网络正向和反向传播的过程，还会介绍一些在实用中的应用的trick如训练过程的梯度检查、如何判断学习率大小、如何判断过拟合等等，以及相应的解决方法</p> 
<p>官方网站：<a href="http://cs231n.github.io/" rel="nofollow">http://cs231n.github.io/</a> <br> 知乎中文翻译：<a href="https://zhuanlan.zhihu.com/p/21930884" rel="nofollow">https://zhuanlan.zhihu.com/p/21930884</a></p> 
<h3 id="12-assignment-2-使用">1.2 Assignment 2 使用</h3> 
<p>配套CS231n课程的有两次作业，作业2主要有四部分内容：全连接层的实现、Batch Normalization、Dropout和卷积层的实现，CS231n有作业的初始模板，可以<a href="http://cs231n.stanford.edu/assignments/2016/winter1516_assignment2.zip" rel="nofollow">在此</a>下载，模板里已经填好了实现这些网络的部分代码，学习者只需要在特定的方法中填写自己的代码即可，例如下面全连接层的forward方法，只需理解了课程笔记后按照提示在TODO中填写代码，填写完后，模板中还提供了方法来检查你代码的正确性：运行IPython notebook，这个notebook会引导你如何填写代码并测试代码，最后会在<a href="http://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow">CIFAR-10</a>数据集上测试你的CNN的准确性。</p> 
<pre class="prettyprint"><code class=" hljs coffeescript">def affine_forward(x, w, b):
  <span class="hljs-string">"""
  Computes the forward pass for an affine (fully-connected) layer.

  The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N
  examples, where each example x[i] has shape (d_1, ..., d_k). We will
  reshape each input into a vector of dimension D = d_1 * ... * d_k, and
  then transform it to an output vector of dimension M.

  Inputs:
  - x: A numpy array containing input data, of shape (N, d_1, ..., d_k)
  - w: A numpy array of weights, of shape (D, M)
  - b: A numpy array of biases, of shape (M,)

  Returns a tuple of:
  - out: output, of shape (N, M)
  - cache: (x, w, b)
  """</span>
  out = None
  <span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">#####
  # TODO: Implement the affine forward pass. Store the result in out. You     #
  # will need to reshape the input into rows.                                 #
  ###</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">##</span>
  pass
  <span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">#####
  #                             END OF YOUR CODE                              #
  ###</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">######</span><span class="hljs-comment">##</span>
  cache = (x, w, b)
  <span class="hljs-keyword">return</span> out, cache</code></pre> 
<p>本文对作业中填写的代码参照了<a href="http://www.jianshu.com/p/9c4396653324" rel="nofollow">CS231n (winter 2016) : Assignment2 - 简书</a>，完整的代码位于<a href="https://github.com/PENGZhaoqing/cs231n-assignment2">Github</a>，运行前请参考CS231n的Readme，Readme中详细介绍了环境的搭建、数据集的下载，如何使用IPython，以及相应的编译过程（如果要用Cpython加速训练过程的话）</p> 
<p>请先下载初始模板，搭建Python环境，下载数据集，运行IPython，然后参考notebook中的提示，填写相应代码。由于各个部分的代码在简书和Github中已有，不再累述。下面主要说一些在CIFAR-10数据库上通过改变CNN网络结构参数提高准确率的心得</p> 
<h2 id="2-在cifar-10上的表现">2. 在CIFAR-10上的表现</h2> 
<h3 id="21-简单两层神经网络">2.1 简单两层神经网络</h3> 
<p>当完成<a href="https://github.com/PENGZhaoqing/cs231n-assignment2/blob/master/FullyConnectedNets.ipynb">Part 1：全连接神经网络</a>后，notebook会提示在CIFAR-10上跑一下，此时若代码实现正常，在测试集上基本上可以达到50%-55%的准确率，网络结构为简单两层，具体请见Github中的<code>classifiers/fc_net.py</code>，下面总结实战中的一些小的trick：</p> 
<p><strong>Trick 1： 如何测试我们实现的模型有效性：小数据集过拟合</strong>： 如何判断我们的方法到能不能work，根据notebook里的提示，可以在一个很小的数据集上跑几个epoch，观察我们的模型是否能够对训练集很好的过拟合，而测试集准确率很低，具体是：在训练集这个100张图片里，是否能够实现99%-100%准确率的判断，而在测试集中另外的100张图片有比较低的准确率（10%左右），这里的模型指我们手动实现的算法</p> 
<p><strong>Trick 2： 如何判断对层的实现是否正确：梯度检查</strong>： 在将我们的算法应用到正式的数据集上之前，需要对实现的层进行解析梯度和数值梯度的比较，具体方法在notebook里，数值梯度是微调1e-6参数获得的差值除以改变量1e-6得到的，而解析梯度是我们实现代码反向传播的输出（因为我们对层的更新都是根据求导法则来的，所以是梯度的解析值），将这两个梯度值比较，观察相对误差，能判断对这个层的实现有没有问题，相对误差在1e-7或者更小是很好的结果，若相对误差达到了1e-2，通常你的实现就有问题。但是，网络越深，相对误差会累计，在10层的网络里若有1e-2的相对误差，那也是可以的。除了梯度检查，notebook中提供了参考值用来检查你实现的权值更新准则如SGD+Momentum、RMSProp、Adam</p> 
<p><strong>Trick 3： 如何判断权值和偏移量参数的初始化是否正确：</strong> 初始化对训练过程也是非常重要的，所以我们需要对训练过程进行检查，当正则强度为0时，对于CIFAR-10的softmax输出的分类器（初始权值w为0.01量级的随机数，初始偏移b为0），一般初始的loss function的值为2.302，这是因为初始时分类器对每一类的概率期望为0.1（共有10类），因此softmax损失函数值为对于正确分类概率的负对数：-ln(0.1)=2.302</p> 
<p><strong>Trick 4： 如何判断学习率是否合适：</strong> 在训练过程中，需要对loss值进行实时地打印，可以判断当前训练的状态：高的学习率高会使损失值下降很快，然后停止在一个比较高的位置（相对最优），这是因为参数每次更新过大，导致在最优点附近震荡，但始终无法达到最优点，而过高的学习率会直接使损失值递增。过于低的学习率会导致损失值下降很慢，训练过程太长，引用笔记中的一张图来理解：</p> 
<p><img src="https://images2.imgbox.com/1c/52/rnAsZs39_o.png" alt="这里写图片描述" title=""></p> 
<p><strong>Trick 5： 如何判断模型的过拟合程度：</strong> 在训练过程中，我们还需要对每个epoch中的训练集和测试集的准确率进行打印，能够确定模型是否过拟合或者欠拟合，若训练集准确率一直大幅度高于验证集，说明此时模型过拟合，对训练集有过好的分类能力导致无法在验证集上进行比较好的分类，解决的方法可以增大正则化强度，如增大L2正则惩罚，增加dropout的随机失活率等。如果训练集一直小幅度低于验证集，说明此时稍微过拟合，而如果训练集和验证集的准确率不相上下，说明此时模型有点欠拟合，没有很好地学习到特征，此时可以调整模型参数如层的深度等，引用笔记中的一张图说明：</p> 
<p><img src="https://images2.imgbox.com/49/6e/6VmM9Fo4_o.jpg" alt="这里写图片描述" title=""></p> 
<p><strong>Trick 6： 如何判断训练中出现的梯度消散问题：</strong> 我们知道，当网络的层数过于深以后，会出现梯度消散的情况，也就是回传到前几层的梯度值很小，导致前面几层的参数无法更新。对此，我们可以打印前几层网络权值参数w的更新比例，经验结论是这个更新比例在1e-3比较比较好，若这个值太大，说明学习率太高；若这个值很小到1e-7，说明参数w基本上不会变，发生了梯度消散，解决方法为：1）使用Batch Normalization归一化每层之间的输出，2）激活函数改用线性ReLU，3）还有可能是学习率太低，4）减少网络层数</p> 
<p><strong>Trick 7： 如何判断训练过程是否稳定和有效：</strong> 若数据为图像数据，那么可以把第一层的权重进行可视化，观察模型是否学习到了比较的好的特征，notebook里内置了相关可视化的方法，若特征图中颜色杂乱无规律且充满噪音，说明训练过程未收敛（学习率太高）或者正则化惩罚不够，引用笔记中的图来解释，下图中的右图为比较好的特征，平滑而且种类繁多，说明训练过程有效且稳定</p> 
<p><img src="https://images2.imgbox.com/f6/3e/gvazY677_o.png" alt="这里写图片描述" title=""></p> 
<p><strong>Trick 8： 如何进行有效的数据预处理：</strong> 在实际应用中CNN比较多的是减均值法和归一化，其他的处理方法为PCA和白化（Whitening）：PCA能消除数据的相关性，使数据的分布在基准值上；白化则可看成是把数据在各个特征方向上进行拉伸压缩变化，使之服从均值为零的高斯分布，具体参考[知乎]（<a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" rel="nofollow">https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit</a>）</p> 
<h3 id="22-卷积神经网络">2.2 卷积神经网络</h3> 
<h4 id="221-三层简单cnn">2.2.1 三层简单CNN</h4> 
<p>在写<a href="https://github.com/PENGZhaoqing/cs231n-assignment2/blob/master/ConvolutionalNetworks.ipynb">Part 2：卷积神经网络</a>之前，会先完成Dropout和Batch Normalization这两部分。在完成了Part 2后，notebook会用<code>classifiers/cnn.py</code> 中一个三层的简单的卷积神经网络来跑CIFAR-10，最终的表现在测试集上达到55-59%这样一个结果，比普通的神经网络高了几个百分点，这个网络结构如下：</p> 
<p><img src="https://images2.imgbox.com/5e/da/tnGvwQFn_o.png" alt="这里写图片描述" title=""></p> 
<h4 id="222-稍微复杂点的cnn">2.2.2 稍微复杂点的CNN</h4> 
<p>基于这个naive的CNN，我再加入一个卷积层和一个全连接层，去掉了Pool层，因为size为2的Pool层会使图像压缩至四分之一，而FICAR的图像大小为32*32，经过一个Pool后变成了16*16，信息损失太大，所以去掉Pool，考虑使用卷积层的stride=2或者3来压缩图像：</p> 
<pre class="prettyprint"><code class=" hljs brainfuck"> <span class="hljs-comment">INPUT</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">CONV</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span><span class="hljs-title">]</span><span class="hljs-comment">*2</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">FC</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span><span class="hljs-title">]</span><span class="hljs-comment">*2</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">FC/OUT</span></code></pre> 
<p>此时在测试集上的精度大概能达到60-65%的程度，然后各种修改卷积层的padding，stride，filter_num参数，大概能提高到67%左右，而训练集精度基本上可以达到90%，说明模型有点过拟合，下一步考虑使用Dropout。</p> 
<h4 id="223-多层小卷积层cnndropout">2.2.3 多层小卷积层CNN+Dropout</h4> 
<p>2.上述网络卷积层的过滤器尺寸始终未6或者7，相对于32*32的图像来说确实是一个比较大的尺寸，然而多层的小size的卷积层效果要比大的size的卷积层好：</p> 
<blockquote> 
 <p>现在，我们以3个3x3的卷积层和1个7x7的卷积层为例，加以对比说明。从下图可以看出，这两种方法最终得到的activation map大小是一致的，但3个3x3的卷积层明显更好： <br> 1)、3层的非线性组合要比1层线性组合提取出的特征具备更高的表达能力； <br> 2)、3层小size的卷积层的参数数量要少，3x3x3&lt;7x7； <br> 3)、同样的，为了便于反向传播时的梯度计算，我们需要保留很多中间梯度，3层小size的卷积层需要保留的中间梯度更少。 <br> <img src="https://images2.imgbox.com/d0/00/Rq8V0305_o.png" alt="这里写图片描述" title=""> <br> 来自<a href="http://www.jianshu.com/p/9c4396653324" rel="nofollow">简书</a></p> 
</blockquote> 
<p>因此，我使用小的卷积层，两个卷积层的过滤器都为filter_size=(3,3)，使用stride=2来压缩图像；同时在输出层前一层加入了Dropout防止过拟合，随机失活率p=0.8，网络结构如下：</p> 
<pre class="prettyprint"><code class=" hljs brainfuck"> <span class="hljs-comment">INPUT</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">CONV</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span><span class="hljs-title">]</span><span class="hljs-comment">*2</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">FC</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">FC</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">DropOut</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">FC/OUT</span></code></pre> 
<p>此时在测试集上的精度大概能达到65-70%左右的程度，训练集精度在很多次epoch后还是维持在80%以上，这时的调整包括再次增加一个全连接层，但是精度还是不能很好提高，遇到了瓶颈，这时可以考虑加入Batch Normalization了。</p> 
<h4 id="224-分析大杀器resnets">2.2.4 分析大杀器ResNets</h4> 
<p>然后我去CIFAR数据集查好解决方案，看到了2015年最好的网络结构<a href="https://github.com/fish145/ResNet-on-Cifar10">ResNets</a>，能达到93%+的精度，这个网络最深能达到110层，而且在20层的时候就能达到91%了。我们考虑20层简单的情况:</p> 
<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">INPUT</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">CONV</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">BatchNorm</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span><span class="hljs-title">]</span><span class="hljs-comment">*19</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">POOL</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">FC/OUT</span></code></pre> 
<p>这个网络的特点为：每一卷积层都使用小的过滤器filter_size=(3,3)，分阶段调整stride步长值：分别在第8层和第13层调整stride=2来压缩图像，其他卷积层的步长stride都1，而且每层卷积层后都会跟一个BatchNormal防止梯度弥散。通过分析这个网络，可以看出：</p> 
<ol><li><p>其实在stride&gt;1的时候，stride跟pool一样，只保留了上个网络部分的信息，能起到压缩图像内容。</p></li><li><p>zero-padding的作用不只是起到一个折中的方案：填补空白区域使卷积过程能够顺利进行，方便从过滤器能从初始位置以步长为单位可以刚好滑倒末尾位置，它的另外一个作用是为了保持图像的尺寸不变，根据公式output_size=（input_size+2*padding-filter_size）/stride+1，我们以input_size=32, padding=1, filter_size=3, stride=1 来计算卷积后的图像大小output_size=(32-2*1-3)/1+1=32，<strong>可以看出输入图像和卷积后的图像大小并没有改变，这也就是ResNets为什么能在32*32这么小的图像上卷积100多次的原因了，而且只靠stride=2来压缩图像两次</strong>。</p></li></ol> 
<p>对于ImageNet这样256*256图像的数据来说，怎么设置stride、padding、filter_size可能没有这么讲究，但是对于CIFAR小图像来说，如何巧妙地设计这些参数就有很大用处了，是深层网络必须的考虑的事</p> 
<h4 id="225-最后的挣扎">2.2.5 最后的挣扎</h4> 
<p>根据上面的分析，我最后挣扎了一下，因为机器不可能跑这么多层网络，还是采用了经典的CNN网络模型：</p> 
<pre class="prettyprint"><code class=" hljs brainfuck"><span class="hljs-comment">INPUT</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">CONV</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">CONV</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">POOL</span><span class="hljs-title">]</span><span class="hljs-comment">*2</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">FC</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span><span class="hljs-title">]</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">DROPOUT</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-title">[</span><span class="hljs-comment">FC</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">RELU</span><span class="hljs-title">]</span> <span class="hljs-literal">-</span><span class="hljs-literal">-</span>&gt; <span class="hljs-comment">FC/OUT</span></code></pre> 
<p>四个卷积层三个全连接，每个卷积层fliter_size=(3,3)， stride=1，padding=1，重新使用pool压缩图像，以下是我的最终参数，可以在<code>classfiers/cnn_custom</code> 里查看：</p> 
<pre class="prettyprint"><code class=" hljs avrasm">weight_scale=<span class="hljs-number">0.01</span>, L2 regularization=<span class="hljs-number">0.0005</span>, dropout=<span class="hljs-number">0.8</span>, batch_size=<span class="hljs-number">100</span>, optimizer=adam, learning_rate=<span class="hljs-number">0.001</span>

<span class="hljs-label">INPUT:</span> input_dim=(<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>)
<span class="hljs-label">CONV1:</span> filters=<span class="hljs-number">64</span>, filter_size=(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),stride=<span class="hljs-number">1</span>, pad=<span class="hljs-number">1</span>
<span class="hljs-label">CONV2:</span> filters=<span class="hljs-number">64</span>, filter_size=(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), stride=<span class="hljs-number">1</span>, pad=<span class="hljs-number">1</span>
<span class="hljs-label">POOL2:</span> pool_height= <span class="hljs-number">2</span>, pool_width= <span class="hljs-number">2</span>, stride= <span class="hljs-number">2</span>
<span class="hljs-label">CONV3:</span> filters=<span class="hljs-number">64</span>, filter_size=(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>),stride=<span class="hljs-number">1</span>, pad=<span class="hljs-number">1</span>
<span class="hljs-label">CONV4:</span> filters=<span class="hljs-number">64</span>, filter_size=(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>), stride=<span class="hljs-number">1</span>, pad=<span class="hljs-number">1</span>
<span class="hljs-label">POOL4:</span> pool_height= <span class="hljs-number">2</span>, pool_width= <span class="hljs-number">2</span>, stride= <span class="hljs-number">2</span>
<span class="hljs-label">FC5:</span> <span class="hljs-number">512</span> neurons
<span class="hljs-label">FC6:</span> <span class="hljs-number">64</span> neurons
<span class="hljs-label">FC7:</span> <span class="hljs-number">10</span> outputs</code></pre> 
<p>最终结果能拿到77%左右的测试集精度，90%+的训练集精度，未来的提高点在于每层加入Batch Normalization，因为BN需要额外的计算量还挺大的（自己实现的话），所以没有加上。最好的方案是跟ResNets一样，用小卷积层并扩展深度至20层以上。</p> 
<p><img src="https://images2.imgbox.com/c9/c1/dpk0fkTr_o.png" alt="这里写图片描述" title=""></p> 
<p>下面给出我第一层卷积层权值w的可视化，因为是3*3，好像并看不出来什么，但是相比刚开始训练的时候要好的很多，不信你可以在训练完1个epoch时就可视化看看</p> 
<p><img src="https://images2.imgbox.com/5c/a1/s3tHnBKA_o.png" alt="这里写图片描述" title=""></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/efa0c24758651f71a35ab77534d5d06a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[CF808F] Card Game（最大流，最大点权独立集，二分）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/11345a756f6ba1c52952eb459dbf9667/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Globalize —— jQuery 官方国际化/本地化插件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>