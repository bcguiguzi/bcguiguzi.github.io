<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python.Scrapy爬取当当网畅销图书保存csv格式详细教程 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python.Scrapy爬取当当网畅销图书保存csv格式详细教程" />
<meta property="og:description" content="初步了解scrapy框架爬虫的使用。
前言：
需要安装一下第三方库 在win下 pip install scrapy pip install bs4 在mac下把pip改成pip3即可 文章目录 一、创建scrapy项目二、代码实现——编辑爬虫——1.——2. 修改两个文件 三、运行爬虫四、保存为csv文件 一、创建scrapy项目 在cmd运行里输入（随便找个盘）
scrapy startproject dangdang
如上图创建成功，接下来在编译器中打开文件
这些文件都是自动生成的 来解释说明一下部分文件
二、代码实现——编辑爬虫 ——1. 接下来创建爬虫项目book.py(注意在spiders文件夹下创建)
在book.py里填写爬虫代码
import scrapy import bs4 from ..items import DangdangItem # 需要引用DangdangItem，它在items里面。因为是items在book.py的上一级目录，..items这是一个固定用法。 class DangdangSpider(scrapy.Spider): #定义一个爬虫类DoubanSpider。 name = &#39;dangdang&#39; allowed_domains = [&#39;http://bang.dangdang.com&#39;] start_urls = [] for x in range(1, 4): url = &#39;http://bang.dangdang.com/books/bestsellers/01.00.00.00.00.00-year-2019-0-1-1&#39; &#43; str(x) start_urls.append(url) def parse(self, response): #parse是默认处理response的方法。 soup = bs4.BeautifulSoup(response.text, &#39;html.parser&#39;) elements = soup." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/f6b5bef059929c25fcc4d59cb4ddf6b2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-03T18:09:45+08:00" />
<meta property="article:modified_time" content="2020-12-03T18:09:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python.Scrapy爬取当当网畅销图书保存csv格式详细教程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>初步了解scrapy框架爬虫的使用。<br> <img src="https://images2.imgbox.com/5a/3c/nJMPCW08_o.png" alt="在这里插入图片描述"></p> 
<p><em><strong>前言</strong></em>：</p> 
<pre><code>需要安装一下第三方库
在win下
pip install scrapy
pip install bs4
在mac下把pip改成pip3即可
</code></pre> 
<h3><a id="_16"></a></h3> 
<font color="#999AAA"> </font> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_16" rel="nofollow"></a></li></ul> 
  </li><li><a href="#scrapy_28" rel="nofollow">一、创建scrapy项目</a></li><li><a href="#_46" rel="nofollow">二、代码实现——编辑爬虫</a></li><li><ul><li><a href="#1_48" rel="nofollow">——1.</a></li><li><a href="#2__81" rel="nofollow">——2. 修改两个文件</a></li></ul> 
  </li><li><a href="#_115" rel="nofollow">三、运行爬虫</a></li><li><a href="#csv_133" rel="nofollow">四、保存为csv文件</a></li></ul> 
</div> 
<p></p> 
<hr size='1"' color="#000000"> 
<h2><a id="scrapy_28"></a>一、创建scrapy项目</h2> 
<blockquote> 
 <p>在cmd运行里输入（随便找个盘）</p> 
 <p>scrapy startproject dangdang</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/21/ae/V4hcVlQH_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>如上图创建成功，接下来在编译器中打开文件</p> 
 <p><img src="https://images2.imgbox.com/c8/f0/qeM2IHQt_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<blockquote> 
 <p>这些文件都是自动生成的 来解释说明一下部分文件</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/77/31/F9UXw2Y2_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_46"></a>二、代码实现——编辑爬虫</h2> 
<h3><a id="1_48"></a>——1.</h3> 
<p>接下来创建爬虫项目book.py(注意在spiders文件夹下创建)<br> <img src="https://images2.imgbox.com/56/1e/DjA5xoh3_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>在book.py里填写爬虫代码</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">import</span> scrapy
<span class="token keyword">import</span> bs4
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> DangdangItem
<span class="token comment"># 需要引用DangdangItem，它在items里面。因为是items在book.py的上一级目录，..items这是一个固定用法。</span>
<span class="token keyword">class</span> <span class="token class-name">DangdangSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#定义一个爬虫类DoubanSpider。</span>
    name <span class="token operator">=</span> <span class="token string">'dangdang'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://bang.dangdang.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        url <span class="token operator">=</span> <span class="token string">'http://bang.dangdang.com/books/bestsellers/01.00.00.00.00.00-year-2019-0-1-1'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        start_urls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#parse是默认处理response的方法。</span>
        soup <span class="token operator">=</span> bs4<span class="token punctuation">.</span>BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>
        elements <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'ul'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">"bang_list clearfix bang_list_mode"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> element <span class="token keyword">in</span> elements<span class="token punctuation">:</span>
            item <span class="token operator">=</span> DangdangItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">"name"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span>
            item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">"publisher_info"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text
            item<span class="token punctuation">[</span><span class="token string">'price'</span><span class="token punctuation">]</span> <span class="token operator">=</span> element<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">"price"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'span'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">"price_n"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text
            <span class="token keyword">yield</span> item<span class="token comment">#   #yield item是把获得的item传递给引擎。</span>
</code></pre> 
<h3><a id="2__81"></a>——2. 修改两个文件</h3> 
<p>接下来打开setting.py文件修改<strong>请求头</strong>和<strong>爬虫协议</strong><br> <img src="https://images2.imgbox.com/4c/04/nLIKD2Rd_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>改成这样：（也就是取消遵守爬虫协议）</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/9d/33/zr5sy1te_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>代码如下</p> 
</blockquote> 
<pre><code class="prism language-python">Crawl responsibly by identifying yourself <span class="token punctuation">(</span><span class="token operator">and</span> your website<span class="token punctuation">)</span> on the user<span class="token operator">-</span>agent
USER_AGENT <span class="token operator">=</span> <span class="token string">'~~Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'</span><span class="token operator">~</span><span class="token operator">~</span> （请求头改成自己的）
Obey robots<span class="token punctuation">.</span>txt rules
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
</code></pre> 
<p><strong>最后一步</strong></p> 
<blockquote> 
 <p>打开item.py文件修改</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/8b/40/II1dSnAU_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>添加以下参数：</p> 
</blockquote> 
<pre><code class="prism language-python">	name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    price <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>如图：<br> <img src="https://images2.imgbox.com/1e/e6/CkihCA7x_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<h2><a id="_115"></a>三、运行爬虫</h2> 
<blockquote> 
 <p>创建main.py(通过这个运行整个爬虫程序)</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/ed/b1/6ErhQi91_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>我们需要知道在Scrapy中有一个可以控制终端命令的模块cmdline，能操控终端<br> 但是此方法需要传入列表的参数。</p> 
</blockquote> 
<p><strong>填入</strong>：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline
cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'scrapy'</span><span class="token punctuation">,</span><span class="token string">'crawl'</span><span class="token punctuation">,</span><span class="token string">'dangdang'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>运行这个main.py就成功了！</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/1f/4a/M3rbBaIR_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="csv_133"></a>四、保存为csv文件</h2> 
<blockquote> 
 <p>要是想把爬取内容以表格形式保存</p> 
 <p>三行代码就可以解决，这也是scrapy的方便之处。</p> 
 <p>打开settings.py文件，在末尾添加代码：</p> 
</blockquote> 
<pre><code class="prism language-python">FEED_URI<span class="token operator">=</span><span class="token string">'./%(name)s.csv'</span>
FEED_FORMAT<span class="token operator">=</span><span class="token string">'csv'</span>
FEED_EXPORT_ENCODING<span class="token operator">=</span><span class="token string">'ansi'</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/22/43/P5C77tGr_o.png" alt="在这里插入图片描述">看起来美观很多。</p> 
<p><strong>运行过程中可能会有各种报错，也是正常的，不要紧，一步步debug就会成功的。</strong></p> 
<p><strong>谢谢支持~</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c62d8713b2a8f4719bcd70aca7fd3993/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Logback日志无法按天分割问题小记</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fff466a49437cc45cdee9b469e01e59f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">笔记本外接显示器没有声音</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>