<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[TensorFlow系列-12]：TensorFlow基础 - 张量线性运算（点乘、叉乘） - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[TensorFlow系列-12]：TensorFlow基础 - 张量线性运算（点乘、叉乘）" />
<meta property="og:description" content="作者主页(文火冰糖的硅基工坊)：https://blog.csdn.net/HiWangWenBing
本文网址：https://blog.csdn.net/HiWangWenBing/article/details/119644102
目录
第1章 Tensor运算概述
1.1 概述
1.3 “in place“运算 ：不支持
1.4 Tensor的广播机制: 不同维度的张量运算
1.5 环境准备
1.6 张量的线性代数运算
第2章 向量的点乘：tf.multiply(x, y）
第3章 向量的内积(是基础)：不支持
3.1 定义
3.2 向量内积的几何意义
3.3 代码示例 -- 不支持
第4章 向量的叉乘 -- 不支持
4.1 定义
4.2 几何意义
4.3 代码示例： Tensorflow不支持
第5章 矩阵的内积运算(对应)：inner() -- 不支持
5.1 矩阵内积的定义
5.2 代码示例 - 不支持
第6章 矩阵的外积/叉乘运算: tf.matmul(x, y）
6.1 矩阵外积（矩阵乘积）的定义 （矩阵相乘）
6.2代码示例
第1章 Tensor运算概述 https://tensorflow.google.cn/api_docs/python/tf
1.1 概述 TensorFlow提供了大量的张量运算，基本上可以对标Numpy多维数组的运算，以支持对张量的各种复杂的运算。
这些操作运算中大多是对数组中每个元素执行相同的函数运算，并获得每个元素函数运算的结果序列，这些序列生成一个新的同维度的数组。
1.2 运算分类" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/431f5787408be4c3bdf64f02d302a5f3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-12T16:47:50+08:00" />
<meta property="article:modified_time" content="2021-08-12T16:47:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[TensorFlow系列-12]：TensorFlow基础 - 张量线性运算（点乘、叉乘）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p> 作者主页(<a href="https://blog.csdn.net/HiWangWenBing" id="uid">文火冰糖的硅基工坊</a>)：<a href="https://blog.csdn.net/HiWangWenBing">https://blog.csdn.net/HiWangWenBing</a></p> 
<p>本文网址：<a href="https://blog.csdn.net/HiWangWenBing/article/details/119644102">https://blog.csdn.net/HiWangWenBing/article/details/119644102</a></p> 
<hr> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E7%AC%AC1%E7%AB%A0%20Tensor%E8%BF%90%E7%AE%97%E6%A6%82%E8%BF%B0-toc" style="margin-left:40px;"><a href="#%E7%AC%AC1%E7%AB%A0%20Tensor%E8%BF%90%E7%AE%97%E6%A6%82%E8%BF%B0" rel="nofollow"> 第1章 Tensor运算概述</a></p> 
<p id="1.1%20%E6%A6%82%E8%BF%B0-toc" style="margin-left:80px;"><a href="#1.1%20%E6%A6%82%E8%BF%B0" rel="nofollow">1.1 概述</a></p> 
<p id="1.3%20%C2%A0%E2%80%9Cin%20place%E2%80%9C%E8%BF%90%E7%AE%97-toc" style="margin-left:80px;"><a href="#1.3%20%C2%A0%E2%80%9Cin%20place%E2%80%9C%E8%BF%90%E7%AE%97" rel="nofollow">1.3  “in place“运算 ：不支持</a></p> 
<p id="1.4%C2%A0Tensor%E7%9A%84%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6%3A%20%E4%B8%8D%E5%90%8C%E7%BB%B4%E5%BA%A6%E7%9A%84tensor%E5%AE%9E%E4%BE%8B%E8%BF%90%E7%AE%97-toc" style="margin-left:80px;"><a href="#1.4%C2%A0Tensor%E7%9A%84%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6%3A%20%E4%B8%8D%E5%90%8C%E7%BB%B4%E5%BA%A6%E7%9A%84tensor%E5%AE%9E%E4%BE%8B%E8%BF%90%E7%AE%97" rel="nofollow">1.4 Tensor的广播机制: 不同维度的张量运算</a></p> 
<p id="1.5%20%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-toc" style="margin-left:80px;"><a href="#1.5%20%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87" rel="nofollow">1.5 环境准备</a></p> 
<p id="1.6%20%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E8%BF%90%E7%AE%97-toc" style="margin-left:80px;"><a href="#1.6%20%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E8%BF%90%E7%AE%97" rel="nofollow">1.6 张量的线性代数运算</a></p> 
<p id="%E7%AC%AC2%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E7%82%B9%E4%B9%98%EF%BC%9Atf.multiply(x%2C%20y%EF%BC%89-toc" style="margin-left:40px;"><a href="#%E7%AC%AC2%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E7%82%B9%E4%B9%98%EF%BC%9Atf.multiply%28x%2C%20y%EF%BC%89" rel="nofollow">第2章 向量的点乘：tf.multiply(x, y）</a></p> 
<p id="%C2%A0%E7%AC%AC2%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E7%82%B9%E4%B9%98(%E6%98%AF%E5%9F%BA%E7%A1%80)%EF%BC%9Adot()-toc" style="margin-left:40px;"><a href="#%C2%A0%E7%AC%AC2%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E7%82%B9%E4%B9%98%28%E6%98%AF%E5%9F%BA%E7%A1%80%29%EF%BC%9Adot%28%29" rel="nofollow">第3章 向量的内积(是基础)：<span style="color:#fe2c24;">不支持</span></a></p> 
<p id="2.1%20%E5%AE%9A%E4%B9%89-toc" style="margin-left:80px;"><a href="#2.1%20%E5%AE%9A%E4%B9%89" rel="nofollow">3.1 定义</a></p> 
<p id="2.2%20%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89-toc" style="margin-left:80px;"><a href="#2.2%20%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89" rel="nofollow">3.2 向量内积的几何意义</a></p> 
<p id="2.3%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-toc" style="margin-left:80px;"><a href="#2.3%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B" rel="nofollow">3.3 代码示例 -- 不支持</a></p> 
<p id="%E7%AC%AC3%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E5%8F%89%E4%B9%98-toc" style="margin-left:40px;"><a href="#%E7%AC%AC3%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E5%8F%89%E4%B9%98" rel="nofollow">第4章 向量的叉乘 -- <span style="color:#fe2c24;">不支持</span></a></p> 
<p id="3.1%20%E5%AE%9A%E4%B9%89-toc" style="margin-left:80px;"><a href="#3.1%20%E5%AE%9A%E4%B9%89" rel="nofollow">4.1 定义</a></p> 
<p id="3.2%20%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89-toc" style="margin-left:80px;"><a href="#3.2%20%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89" rel="nofollow">4.2 几何意义</a></p> 
<p id="3.3%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-toc" style="margin-left:80px;"><a href="#3.3%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B" rel="nofollow">4.3 代码示例： Tensorflow不支持</a></p> 
<p id="%E7%AC%AC4%E7%AB%A0%C2%A0%20%E7%9F%A9%E9%98%B5%E7%9A%84%E5%86%85%E7%A7%AF%E8%BF%90%E7%AE%97(%E5%AF%B9%E5%BA%94)%EF%BC%9Ainner()-toc" style="margin-left:40px;"><a href="#%E7%AC%AC4%E7%AB%A0%C2%A0%20%E7%9F%A9%E9%98%B5%E7%9A%84%E5%86%85%E7%A7%AF%E8%BF%90%E7%AE%97%28%E5%AF%B9%E5%BA%94%29%EF%BC%9Ainner%28%29" rel="nofollow">第5章  矩阵的内积运算(对应)：inner()  -- <span style="color:#fe2c24;">不支持</span></a></p> 
<p id="4.1%20%E7%9F%A9%E9%98%B5%E5%86%85%E7%A7%AF%E7%9A%84%E5%AE%9A%E4%B9%89-toc" style="margin-left:80px;"><a href="#4.1%20%E7%9F%A9%E9%98%B5%E5%86%85%E7%A7%AF%E7%9A%84%E5%AE%9A%E4%B9%89" rel="nofollow">5.1 矩阵内积的定义</a></p> 
<p id="4.2%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-toc" style="margin-left:80px;"><a href="#4.2%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B" rel="nofollow">5.2 代码示例 - 不支持</a></p> 
<p id="%E7%AC%AC5%E7%AB%A0%20%E7%9F%A9%E9%98%B5%E7%9A%84%E5%A4%96%E7%A7%AF%E8%BF%90%E7%AE%97%3A%C2%A0matmul()-toc" style="margin-left:40px;"><a href="#%E7%AC%AC5%E7%AB%A0%20%E7%9F%A9%E9%98%B5%E7%9A%84%E5%A4%96%E7%A7%AF%E8%BF%90%E7%AE%97%3A%C2%A0matmul%28%29" rel="nofollow">第6章 矩阵的外积/叉乘运算: tf.matmul(x, y）</a></p> 
<p id="5.1%20%E7%9F%A9%E9%98%B5%E5%A4%96%E7%A7%AF%EF%BC%88%E7%9F%A9%E9%98%B5%E4%B9%98%E7%A7%AF%EF%BC%89%E7%9A%84%E5%AE%9A%E4%B9%89%20%EF%BC%88%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98%EF%BC%89-toc" style="margin-left:80px;"><a href="#5.1%20%E7%9F%A9%E9%98%B5%E5%A4%96%E7%A7%AF%EF%BC%88%E7%9F%A9%E9%98%B5%E4%B9%98%E7%A7%AF%EF%BC%89%E7%9A%84%E5%AE%9A%E4%B9%89%20%EF%BC%88%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98%EF%BC%89" rel="nofollow">6.1 矩阵外积（矩阵乘积）的定义 （矩阵相乘）</a></p> 
<p id="5.2%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-toc" style="margin-left:80px;"><a href="#5.2%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B" rel="nofollow">6.2代码示例</a></p> 
<hr id="hr-toc"> 
<hr> 
<h3 id="%E7%AC%AC1%E7%AB%A0%20Tensor%E8%BF%90%E7%AE%97%E6%A6%82%E8%BF%B0"> 第1章 Tensor运算概述</h3> 
<p><a href="https://tensorflow.google.cn/api_docs/python/tf" rel="nofollow">https://tensorflow.google.cn/api_docs/python/tf</a></p> 
<h4 id="1.1%20%E6%A6%82%E8%BF%B0">1.1 概述</h4> 
<p>TensorFlow提供了大量的张量运算，基本上可以对标Numpy多维数组的运算，以支持对张量的各种复杂的运算。</p> 
<p>这些操作运算中大多是对数组中每个元素执行相同的函数运算，并获得每个元素函数运算的结果序列，这些序列生成一个新的同维度的数组。</p> 
<p><img alt="" height="240" src="https://images2.imgbox.com/69/3a/8OjT3DYz_o.png" width="279"></p> 
<p></p> 
<p><strong>1.2 运算分类</strong></p> 
<p><strong>（1）算术运算</strong>：加、减、系数乘、系数除</p> 
<p><strong>（2）函数运算</strong>：sin，cos</p> 
<p><strong>（3）取整运算：</strong>上取整、下取整</p> 
<p><strong>（4）统计运算</strong>：最大值、最小值、均值</p> 
<p><strong>（5）比较运算：大于，等于，小于、排序</strong></p> 
<p><strong>（6）线性代数运算：矩阵、点乘、叉乘</strong></p> 
<p></p> 
<h4 id="1.3%20%C2%A0%E2%80%9Cin%20place%E2%80%9C%E8%BF%90%E7%AE%97">1.3  <strong>“in place“运算</strong> ：不支持</h4> 
<h4 id="1.4%C2%A0Tensor%E7%9A%84%E5%B9%BF%E6%92%AD%E6%9C%BA%E5%88%B6%3A%20%E4%B8%8D%E5%90%8C%E7%BB%B4%E5%BA%A6%E7%9A%84tensor%E5%AE%9E%E4%BE%8B%E8%BF%90%E7%AE%97">1.4 Tensor的广播机制: 不同维度的张量运算</h4> 
<h4 id="1.5%20%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">1.5 环境准备</h4> 
<pre><code>#环境准备
import numpy as np
import tensorflow as tf
print("hello world")
print("tensorflow version:", tf.__version__)</code></pre> 
<h4 id="1.6%20%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E8%BF%90%E7%AE%97">1.6 张量的线性代数运算</h4> 
<p>（1）点乘：multiply(a,b）=》张量</p> 
<p>（2）内积: inner(a,b) =》标量     # tensorflow不支持</p> 
<p>（3）叉乘：matmul(a,b)  =》 张量</p> 
<p><span style="color:#fe2c24;"><strong>备注：在矩阵的各种运算中，Tensorflow比Pytorch的函数库要少很多。</strong></span></p> 
<p></p> 
<h3 id="%E7%AC%AC2%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E7%82%B9%E4%B9%98%EF%BC%9Atf.multiply(x%2C%20y%EF%BC%89">第2章 向量的点乘：tf.multiply(x, y）</h3> 
<p><strong>向量的点乘定义：</strong>按位相乘，不相加</p> 
<pre><code class="language-python"># 代码示例

#向量的点乘（点积）运算: 对应元素相乘
print("向量：")
a = tf.constant([1,2,3])
b = tf.constant([1,2,1])
print(a)
print(b)

print("\n点乘")
c= tf.multiply(a,b) #对应元素相乘
print(c)   </code></pre> 
<pre><code class="language-html hljs">向量：
tf.Tensor([1 2 3], shape=(3,), dtype=int32)
tf.Tensor([1 2 1], shape=(3,), dtype=int32)

点乘
tf.Tensor([1 4 3], shape=(3,), dtype=int32)</code></pre> 
<p></p> 
<h3 id="%C2%A0%E7%AC%AC2%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E7%82%B9%E4%B9%98(%E6%98%AF%E5%9F%BA%E7%A1%80)%EF%BC%9Adot()">第3章 向量的<strong>内积</strong>(是基础)：<span style="color:#fe2c24;">不支持</span></h3> 
<h4 id="2.1%20%E5%AE%9A%E4%B9%89"><strong>3.1 定义</strong></h4> 
<p>概括地说，向量的<strong>内积</strong>（点乘/数量积）。</p> 
<p>对两个向量执行点乘运算，就是对这两个向量对应位一一相乘之后<strong>求和</strong>的操作，如下所示，对于向量a和向量b：</p> 
<p> <img alt="" height="139" src="https://images2.imgbox.com/de/65/amj1NUA3_o.png" width="455"></p> 
<p><strong>注意：</strong></p> 
<ul><li><strong> 这里要求一维向量a和向量b的行列数相同。</strong></li><li><strong>点乘的结果是一个标量(数量而不是向量)</strong></li></ul> 
<p></p> 
<h4 id="2.2%20%E5%90%91%E9%87%8F%E5%86%85%E7%A7%AF%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89"><strong>3.2 向量内积的几何意义</strong></h4> 
<p><img alt="" height="229" src="https://images2.imgbox.com/a1/89/SEn0cXTn_o.png" width="355"></p> 
<p><strong>（1）可用于计算计算两个向量之间的夹角.</strong></p> 
<p><img alt="" height="96" src="https://images2.imgbox.com/3a/74/Oe6rU5fN_o.png" width="214"></p> 
<p>   θ=arccos⁡(a∙b/|a||b|)</p> 
<p><strong>（2）b向量在a向量方向上的投影与a相乘</strong></p> 
<p><img alt="" height="107" src="https://images2.imgbox.com/79/6f/60XiBcdL_o.png" width="272"></p> 
<p> |a| = 所有元素的平方和开根号，实际上就是向量a的长度。</p> 
<p> |b| = 所有元素的平方和开根号，实际上就是向量b的长度。</p> 
<p>a.b = a1*b1 + a2*b2 ..... an*bn</p> 
<p><strong>（3）是否正交指示：</strong></p> 
<p>如果点乘的结果为0，则表示a在b上的投影为0，表示a和b是正交的。</p> 
<p>如果正交，表示这两个向量不相干。</p> 
<p></p> 
<h4 id="2.3%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">3.3 代码示例 -- 不支持</h4> 
<p></p> 
<h3 id="%E7%AC%AC3%E7%AB%A0%20%E5%90%91%E9%87%8F%E7%9A%84%E5%8F%89%E4%B9%98">第4章 向量的叉乘 -- <span style="color:#fe2c24;">不支持</span></h3> 
<h4 id="3.1%20%E5%AE%9A%E4%B9%89">4.1 定义</h4> 
<p>两个向量的外积，又叫叉乘、叉积向量积，其运算结果是一个<strong>向量</strong>而不是一个标量。</p> 
<p>并且两个向量的外积与这两个向量组成的坐标平面<strong>垂直</strong>。</p> 
<p><strong>定义</strong>：向量<strong>a</strong>与<strong>b</strong>的外积<strong>a</strong>×<strong>b</strong>是一个向量，其长度等于|<strong>a</strong>×<strong>b</strong>| = |<strong>a</strong>||<strong>b</strong>|sin∠(<strong>a</strong>,<strong>b</strong>)，其方向正交于<strong>a</strong>与<strong>b</strong>。并且，(<strong>a</strong>,<strong>b</strong>,<strong>a</strong>×<strong>b</strong>)构成右手系。 <br> 特别地，<strong>0</strong>×<strong>a</strong> = <strong>a</strong>×<strong>0</strong> = <strong>0</strong>.此外，对任意向量<strong>a</strong>，自身相乘<strong>a</strong>×<strong>a</strong>=<strong>0</strong>。</p> 
<p>对于向量a和向量b：</p> 
<p><img alt="" height="66" src="https://images2.imgbox.com/58/06/YFnnbFa8_o.png" width="144"></p> 
<p id="a%E5%92%8Cb%E7%9A%84%E5%A4%96%E7%A7%AF%E5%85%AC%E5%BC%8F%E4%B8%BA%EF%BC%88%E5%BE%97%E5%88%B0%E7%9A%84%E6%98%AF%E5%8E%9F%E5%85%88%E7%BB%B4%E5%BA%A6%E7%9A%84%E5%90%91%E9%87%8F%EF%BC%89%EF%BC%9A"><strong>a和b的外积公式为（得到的是原先维度的向量）：</strong></p> 
<p><img alt="" height="126" src="https://images2.imgbox.com/92/a9/8IO5ts1c_o.png" width="662"></p> 
<h4 id="3.2%20%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89">4.2 几何意义</h4> 
<p>在三维几何中，向量a和向量b的外积结果是一个向量，有个更通俗易懂的叫法是<strong>法向量</strong>，该向量垂直于a和b向量构成的平面。</p> 
<p>在3D图像学中，外积的概念非常有用，可以通过两个向量的外积，生成第三个垂直于a，b的法向量，从而构建X、Y、Z坐标系。如下图所示：</p> 
<p><img alt="" height="268" src="https://images2.imgbox.com/89/bb/JvdO0UOD_o.png" width="299"></p> 
<h4 id="3.3%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">4.3 代码示例： Tensorflow不支持</h4> 
<p></p> 
<h3 id="%E7%AC%AC4%E7%AB%A0%C2%A0%20%E7%9F%A9%E9%98%B5%E7%9A%84%E5%86%85%E7%A7%AF%E8%BF%90%E7%AE%97(%E5%AF%B9%E5%BA%94)%EF%BC%9Ainner()">第5章  矩阵的内积运算(对应)：inner()  -- <span style="color:#fe2c24;">不支持</span></h3> 
<h4 id="4.1%20%E7%9F%A9%E9%98%B5%E5%86%85%E7%A7%AF%E7%9A%84%E5%AE%9A%E4%B9%89">5.1 矩阵内积的定义</h4> 
<p>两个<strong>相同维度</strong>的矩阵a和b，a和b<strong>矩阵的内积</strong>时相同位置的<strong>向量的内积</strong>。</p> 
<p><strong>（1）向量向量内积</strong></p> 
<p><img alt="" height="127" src="https://images2.imgbox.com/56/67/oRDnwT13_o.png" width="411"></p> 
<p><strong> （2）向量矩阵的内积：</strong></p> 
<p> <img alt="" height="215" src="https://images2.imgbox.com/69/5f/46C1s5Wg_o.png" width="626"></p> 
<h4 id="4.2%20%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">5.2 代码示例 - 不支持</h4> 
<p></p> 
<h3 id="%E7%AC%AC5%E7%AB%A0%20%E7%9F%A9%E9%98%B5%E7%9A%84%E5%A4%96%E7%A7%AF%E8%BF%90%E7%AE%97%3A%C2%A0matmul()">第6章 矩阵的外积/叉乘运算: tf.matmul(x, y）</h3> 
<h4 id="5.1%20%E7%9F%A9%E9%98%B5%E5%A4%96%E7%A7%AF%EF%BC%88%E7%9F%A9%E9%98%B5%E4%B9%98%E7%A7%AF%EF%BC%89%E7%9A%84%E5%AE%9A%E4%B9%89%20%EF%BC%88%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98%EF%BC%89">6.1 矩阵外积（矩阵乘积）的定义 （矩阵相乘）</h4> 
<p><a href="https://baike.baidu.com/item/%E7%9F%A9%E9%98%B5/18069" rel="nofollow">矩阵</a>相乘最重要的方法是一般矩阵乘积。它只有在第一个矩阵的列数（column）和第二个矩阵的行数（row）相同时才有意义。</p> 
<p><strong>（1）向量的乘积</strong></p> 
<p><img alt="" height="106" src="https://images2.imgbox.com/eb/03/jcV1aTbW_o.png" width="341"></p> 
<p><strong>（2）矩阵的乘积</strong></p> 
<p><img alt="" height="451" src="https://images2.imgbox.com/02/cf/bySKrxQ5_o.png" width="678"></p> 
<h4 id="5.2%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B">6.2代码示例</h4> 
<pre><code class="language-python"># 代码示例：

# 矩阵的外积、叉乘：交叉相乘
print("矩阵：1*3")
a = tf.constant([[1,2,3]])  # 相当于1* N
print(a)

print("矩阵：3*1")
b = tf.constant([[0],[1],[0]]) # 相当于N * 1
print(b)

print("叉乘: 1*1")
c = tf.matmul(a,b)  # 等价于 1*0+2*1+3*0
print(c)

print("\n矩阵：2*3")
a = tf.constant([[1,2,3], [4,5,6]])
print(a)
print("\n矩阵：3*2")
b = tf.constant([[0,1], [1,1], [1,1]])
print(b)
print("叉乘: 2*2")
c = tf.matmul(a,b) # X * N VS N * Y =&gt; X * Y
print(c)
</code></pre> 
<pre><code class="language-python">输出：

矩阵：1*3
tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)
矩阵：3*1
tf.Tensor(
[[0]
 [1]
 [0]], shape=(3, 1), dtype=int32)
叉乘: 1*1
tf.Tensor([[2]], shape=(1, 1), dtype=int32)

矩阵：2*3
tf.Tensor(
[[1 2 3]
 [4 5 6]], shape=(2, 3), dtype=int32)

矩阵：3*2
tf.Tensor(
[[0 1]
 [1 1]
 [1 1]], shape=(3, 2), dtype=int32)
叉乘: 2*2
tf.Tensor(
[[ 5  6]
 [11 15]], shape=(2, 2), dtype=int32)
​
</code></pre> 
<p></p> 
<p></p> 
<hr> 
<p>作者主页(<a href="https://blog.csdn.net/HiWangWenBing">文火冰糖的硅基工坊</a>)：<a href="https://blog.csdn.net/HiWangWenBing">https://blog.csdn.net/HiWangWenBing</a></p> 
<p>本文网址：<a href="https://blog.csdn.net/HiWangWenBing/article/details/119644102">https://blog.csdn.net/HiWangWenBing/article/details/119644102</a></p> 
<p><img alt="" src="https://images2.imgbox.com/89/27/wjJxneZt_o.jpg"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1175251f7f00bcf1e1ac0ae9ec05faea/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">el-input type=number 去除聚焦时的上下箭头</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cb8a715e3ef27a9cd905353f7d080cea/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pro e打开服务器文件,Pro/E要打开文件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>