<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python爬取51jobs之数据清洗(3) - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python爬取51jobs之数据清洗(3)" />
<meta property="og:description" content="前面已经用get_webpage方法获取网站，下面说一说如何从网站信息中过滤出我想要的信息(招聘公司，招聘信息，薪水)。
以一个公司招聘网站为例子，
ur=‘https://jobs.51job.com/hangzhou-jgq/104504900.html?s=01&amp;t=0’ ’我们要获取这3个地方的文本信息
首先导入requests模块，写上请求头
import requests import re from bs4 import BeautifulSoup def data_cleaning(): user_agent = &#39;Mozilla/4.0 (compatible;MSIE 5.5; Windows NT)&#39; headers = { &#39;User-Agent&#39;: user_agent } url = &#34;https://jobs.51job.com/hangzhou-jgq/104504900.html?s=01&amp;t=0&#34; r = requests.get(url, headers) soup = BeautifulSoup(r.text, &#39;html.parser&#39;, exclude_encodings=&#34;utf-8&#34;) 上面都是爬虫基础的，随便百度一下就行，简单来说，soup就是你在网页按F12出来的HTML代码。
接着在利用正则，BS4模块获取目的信息
整理如下：
def data_cleaning(): .... # 省略之前写的 # 1，公司名称 sname = soup.find_all(class_=&#39;catn&#39;)[0][&#39;title&#39;] # 2，职位信息 directory = soup.find_all(class_=&#39;bmsg job_msg inbox&#39;)[0] # 返回一个&lt;class &#39;bs4.element.Tag&#39;&gt; # TypeError: &#39;NoneType&#39; object is not callable job_datas = str(directory)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/fa97ee79d06a9a84be8a5b31e54a56be/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-02-15T13:10:42+08:00" />
<meta property="article:modified_time" content="2019-02-15T13:10:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python爬取51jobs之数据清洗(3)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p> </p> 
<p>前面已经用get_webpage方法获取网站，下面说一说如何从网站信息中过滤出我想要的信息(招聘公司，招聘信息，薪水)。</p> 
<p>以一个公司招聘网站为例子，</p> 
<pre><code class="language-html hljs">ur=‘https://jobs.51job.com/hangzhou-jgq/104504900.html?s=01&amp;t=0’</code></pre> 
<p>’我们要获取这3个地方的文本信息</p> 
<p><img alt="" class="has" height="845" src="https://images2.imgbox.com/3b/61/OiblS9Hn_o.png" width="761"></p> 
<p>首先导入requests模块，写上请求头</p> 
<pre class="has"><code>import requests
import re
from bs4 import BeautifulSoup


def data_cleaning():
    user_agent = 'Mozilla/4.0 (compatible;MSIE 5.5; Windows NT)'
    headers = {
        'User-Agent': user_agent
    }
    url = "https://jobs.51job.com/hangzhou-jgq/104504900.html?s=01&amp;t=0"
    r = requests.get(url, headers)
    soup = BeautifulSoup(r.text, 'html.parser', exclude_encodings="utf-8")</code></pre> 
<p>上面都是爬虫基础的，随便百度一下就行，简单来说，soup就是你在网页按F12出来的HTML代码。</p> 
<p>接着在利用正则，BS4模块获取目的信息</p> 
<p>整理如下：</p> 
<pre class="has"><code>def data_cleaning():
    ....  # 省略之前写的
    # 1，公司名称
    sname = soup.find_all(class_='catn')[0]['title']  
    # 2，职位信息
    directory = soup.find_all(class_='bmsg job_msg inbox')[0]  # 返回一个&lt;class 'bs4.element.Tag'&gt;
    # TypeError: 'NoneType' object is not callable
    job_datas = str(directory).replace("\n", "")
    pattern = re.compile('&lt;div class="bmsg job_msg inbox"&gt;(.*?)&lt;div', re.S)
    job_data = re.findall(pattern, job_datas)
    job_data = job_data[0].replace('&lt;p&gt;', '').replace('&lt;/p&gt;','\n')
    # 3，月薪
    job_salary = soup.find_all(class_='cn')[0].strong.text
    return  sname,job_data,job_salary
</code></pre> 
<blockquote> 
 <p>值得注意的是：</p> 
 <p>job_datas = str(directory).replace("\n", "")</p> 
 <p>首先：directory = soup.find_all(class_='bmsg job_msg inbox')[0]返回的是一个元素，到底在Python里面算什么（NoneType），反正不是字符串，所以首先要将directory转换为字符串</p> 
 <p>然后directory其实还有很多换行符“/n”在你调试的时候并不会显示，但你在正则匹配的时候它又确确实实存在，所以为了方便消除换行符，用字符串的replace方法</p> 
</blockquote> 
<p>后续只要将sname，job_data,job_salary存入MySQL数据库就算基本OK了。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e75bebd1db7f99b47e432899ee5886ff/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">知识图谱赵军学习笔记（一）--概论</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/edb4aea8f60f242559ccb2d905ac6de6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">flutter深入研究之GestureDetector</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>