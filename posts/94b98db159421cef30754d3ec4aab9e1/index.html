<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>半监督学习：MixMatch - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="半监督学习：MixMatch" />
<meta property="og:description" content="MixMatch: A Holistic Approach to Semi-Supervised Learning
官方代码---tensorflow版本
pytorch版
论文 2.1以上的内容都是简介，概述这里就不进行讲解。 2.1 Consistency Regularization 一致性正则 这个技巧是什么意思，就是说对一张图片进行2种不同的数据增强后，给模型预测，预测的y1和y2，这y1和y2的结果要一致。为什么说是正则，因为添加了扰动噪声，为什么说一致性，因为预测出来的y1和y2要一致。
那在半监督中这y1和y2的loss如何计算？论文中：
就是y1和y2用MSE_loss均方差loss 在pytorch中是F.mse_loss。
代码实现：Lu = F.mse_loss(output_u,trg_u)
pytorch版的这个更加粗暴
2.2 Entropy Minimization---熵最小化 信息熵越小，含有的信息量就越大
分类模型在计算loss的时候才用交叉熵loss；如果输出的值比较implicitly（含蓄模糊）那么对计算loss的时候有影响。所以论文中提出自己的方法”sharpening(类似图片的锐化操作)“
pt = p**(1/args.T) targets_u = pt / pt.sum(dim=1, keepdim=True) targets_u = targets_u.detach() 2.3 Traditional Regularization -- 传统的正则方法 简单的说就是论文说他会用到L2正则去优化模型参数和mixup数据增强
3 MixMatch 从这里开始就正式开始讲述论文的方法了，
X是标注了的数据图片，X′ 是X进行数据增强后的图片，U是没标注的数据图片，U′是对U进行数据增强后的进行猜测后的标签（也就是进行了模型预测），T,K,a都是超参数
说的是标注了的图片如何求loss是用交叉熵
Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1)) 说的是没标注的图片如何求loss
Lu = torch.mean((probs_u - targets_u)**2) 总的loss就等于两者相加 def linear_rampup(current, rampup_length=args.epochs): if rampup_length == 0: return 1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/94b98db159421cef30754d3ec4aab9e1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-01T13:44:44+08:00" />
<meta property="article:modified_time" content="2022-03-01T13:44:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">半监督学习：MixMatch</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><a class="link-info" href="https://arxiv.org/abs/1905.02249" rel="nofollow" title="MixMatch: A Holistic Approach to Semi-Supervised Learning">MixMatch: A Holistic Approach to Semi-Supervised Learning</a></p> 
<p><a class="link-info" href="https://github.com/google-research/mixmatch" title="官方代码">官方代码</a>---tensorflow版本</p> 
<p><a class="link-info" href="https://github.com/YU1ut/MixMatch-pytorch" title="pytorch版">pytorch版</a></p> 
<h2>论文</h2> 
<h2>2.1以上的内容都是简介，概述这里就不进行讲解。</h2> 
<h2>2.1 Consistency Regularization 一致性正则</h2> 
<p>这个技巧是什么意思，就是说对一张图片进行2种不同的数据增强后，给模型预测，预测的y1和y2，这y1和y2的结果要一致。为什么说是正则，因为添加了扰动噪声，为什么说一致性，因为预测出来的y1和y2要一致。</p> 
<p>那在半监督中这y1和y2的loss如何计算？论文中：</p> 
<p><img alt="" height="92" src="https://images2.imgbox.com/b8/6e/cTmzvFqR_o.png" width="1019"></p> 
<p>就是y1和y2用MSE_loss均方差loss  在pytorch中是F.mse_loss。</p> 
<p>代码实现：Lu = F.mse_loss(output_u,trg_u)</p> 
<p>pytorch版的这个更加粗暴</p> 
<p><img alt="" height="255" src="https://images2.imgbox.com/7a/f6/XFZMjtNz_o.png" width="890"></p> 
<h2>2.2 Entropy Minimization---熵最小化</h2> 
<p>信息熵越小，含有的信息量就越大</p> 
<p>分类模型在计算loss的时候才用交叉熵loss；如果输出的值比较implicitly（含蓄模糊）那么对计算loss的时候有影响。所以论文中提出自己的方法”sharpening(类似图片的锐化操作)“</p> 
<p><img alt="" height="176" src="https://images2.imgbox.com/9f/d1/x3QJqene_o.png" width="401"></p> 
<p>           </p> 
<pre><code>pt = p**(1/args.T)
targets_u = pt / pt.sum(dim=1, keepdim=True)
targets_u = targets_u.detach() </code></pre> 
<h2>2.3 Traditional Regularization -- 传统的正则方法</h2> 
<p>简单的说就是论文说他会用到L2正则去优化模型参数和mixup数据增强</p> 
<h2>3 MixMatch</h2> 
<p>从这里开始就正式开始讲述论文的方法了，</p> 
<p><img alt="" height="53" src="https://images2.imgbox.com/29/a6/jzEIhye8_o.png" width="464"></p> 
<p>X是标注了的数据图片，X′ 是X进行数据增强后的图片，U是没标注的数据图片，U′是对U进行数据增强后的进行<span style="color:#fe2c24;">猜测后</span>的标签（也就是进行了模型预测），T,K,a都是超参数</p> 
<p><img alt="" height="99" src="https://images2.imgbox.com/2a/f9/laM2cIzp_o.png" width="505"></p> 
<p>说的是标注了的图片如何求loss是用交叉熵</p> 
<pre><code>Lx = -torch.mean(torch.sum(F.log_softmax(outputs_x, dim=1) * targets_x, dim=1))</code></pre> 
<p> <img alt="" height="89" src="https://images2.imgbox.com/c4/d7/Zv8h3vZl_o.png" width="553"></p> 
<p>说的是没标注的图片如何求loss</p> 
<pre><code>Lu = torch.mean((probs_u - targets_u)**2)</code></pre> 
<p> <img alt="" height="54" src="https://images2.imgbox.com/3a/a5/RZW4uEx1_o.png" width="255"></p> 
<p>总的loss就等于两者相加 </p> 
<pre><code>def linear_rampup(current, rampup_length=args.epochs):
    if rampup_length == 0:
        return 1.0
    else:
        current = np.clip(current / rampup_length, 0.0, 1.0)
        return float(current)
Loss = Lx+Lu* linear_rampup(epoch)</code></pre> 
<h2>3.1 Data Augmentation---数据增强</h2> 
<p>有标签的数据，只做一次增广，  ˆxb = Augment(xb)，没有标签的数据，要做 K 次增广，ub,k = Augment(ub),k ∈(1,...,K)</p> 
<h2>3.2 Label Guessing---标签猜测</h2> 
<p><img alt="" height="114" src="https://images2.imgbox.com/a6/b7/VRmhztBo_o.png" width="427"></p> 
<p>对无标注的数据进行猜测，先进行K次数据增强，然后用模型预测这K个，然后进行求平均</p> 
<pre><code>outputs_u = model(inputs_u)
outputs_u2 = model(inputs_u2)
p = (torch.softmax(outputs_u, dim=1) + torch.softmax(outputs_u2, dim=1)) / 2</code></pre> 
<p> <img alt="" height="665" src="https://images2.imgbox.com/e8/e7/FDzgTPmk_o.png" width="1200"></p> 
<p>整个算法流程algorithm</p> 
<h2>Sharpening</h2> 
<p><img alt="" height="116" src="https://images2.imgbox.com/41/a5/LYVTxyCJ_o.png" width="414"></p> 
<p>sharpening是如何实现的呢</p> 
<pre><code>pt = p**(1/args.T)
targets_u = pt / pt.sum(dim=1, keepdim=True)</code></pre> 
<h2> 3.3 MixUp</h2> 
<p>我个人觉得这个部分是这个论文的主要内容</p> 
<p><img alt="" height="60" src="https://images2.imgbox.com/04/b5/qTiWgyz3_o.png" width="231"></p> 
<p>先获取λ   因为a=0.75  那么beta分布为：</p> 
<p><img alt="" height="446" src="https://images2.imgbox.com/aa/f3/HclfOwpF_o.png" width="632"></p> 
<p>大部分值都是0到1之间</p> 
<p><img alt="" height="149" src="https://images2.imgbox.com/d8/7f/yFUdIRRR_o.png" width="323"></p> 
<p>而后用这个公式计算mixup后的x和p</p> 
<pre><code>l = np.random.beta(args.alpha, args.alpha)
l = max(l, 1-l)

idx = torch.randperm(all_inputs.size(0))
input_a, input_b = all_inputs, all_inputs[idx]
target_a, target_b = all_targets, all_targets[idx]

mixed_input = l * input_a + (1 - l) * input_b
mixed_target = l * target_a + (1 - l) * target_b</code></pre> 
<p>all_inputs = torch.cat[有标记的x，无标记的u，无标记的u2]</p> 
<p>all_targets = torch.cat[y，无标记的y，无标记的y2]</p> 
<pre><code># model forward
mixuped_logits = model(mixed_input)  # [3*N,10]
logits_x = mixuped_logits[:HP.batch_size]  # [N,10]
logits_u = mixuped_logits[HP.batch_size:]  # [2*N,10]</code></pre> 
<p>最后分别计算loss最后加起来。然后进行反向传播</p> 
<h3>3.4 Loss Function--loss函数</h3> 
<p>这个在前面说过了，</p> 
<h3>3.5 Hyperparameters---超参数</h3> 
<p>之前前面提到的T=0.5 K=2 a=0.75</p> 
<pre>λU=np.clip(a=max_v * (step / MAX_STEP), a_min=0, a_max=max_v)</pre> 
<p>λU 采用不超过a=0.75  随着训练步数的增加而增加到0.75就不增加了</p> 
<h2>4 Experiments---实验结果</h2> 
<p>这个部分就是说用了本论文的方法后，取得了不得了的效果，就不用怎么细讲了，简单说一下</p> 
<p><img alt="" height="326" src="https://images2.imgbox.com/4f/42/8V5acF7b_o.png" width="1200"></p> 
<p>只用了2000个标注好的图片就达到了和全监督训练是差不多的水平。就是非常的牛，非常的state of the art </p> 
<h3>4.1 Implementation details</h3> 
<p>这里提了一下，用到了EMA（exponential moving average）指数移动平均</p> 
<p><img alt="" height="315" src="https://images2.imgbox.com/32/45/T12GN8NB_o.png" width="362"></p> 
<pre><code>class WeightEMA:
    def __init__(self, model, ema_model, alpha=0.999):
        self.model = model
        self.ema_model = ema_model
        self.alpha = alpha
        self.params = list(model.state_dict().values())
        self.ema_params = list(ema_model.state_dict().values())
        self.weight_decacy = 0.0004

        for param, ema_param in zip(self.params, self.ema_params):
            param.data.copy_(ema_param) # 是把ema_param的产生copy 给param

    def step(self):
        for param, ema_param in zip(self.params, self.ema_params):
            if ema_param.dtype == torch.float32:  # model weights only!
                ema_param.mul_(self.alpha)
                ema_param.add_(param * (1 - self.alpha))
                # apply weight
                param.mul_((1 - self.weight_decacy))</code></pre> 
<h2>代码</h2> 
<p><a class="link-info" href="https://github.com/carlsummer/MixMatch" title="我自己搜索出来的代码上传到了我的github上分享给大家">我自己搜索出来的代码上传到了我的github上分享给大家</a></p> 
<p>这个代码和前面大师的pytorch版本也是差不多的。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a96c8dbe36607d4686686e327fb76b93/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43; 五子棋 面向对象实现</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6a69771c77cba4fbcdb3f7c8d7b05f90/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ubuntu中screen使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>