<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GPT 模型介绍 | GPT3 / GPT3.5 &#43; Flask | Github源码链接 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GPT 模型介绍 | GPT3 / GPT3.5 &#43; Flask | Github源码链接" />
<meta property="og:description" content="1. 模型介绍 Chatgpt 使用与 InstructGPT相同的方法，使用来自人类反馈的强化学习 (RLHF) 来训练该模型，但数据收集设置略有不同。我们使用监督微调训练了一个初始模型：人类 AI 训练员提供对话，他们在对话中扮演双方——用户和 AI 助手。我们让培训师可以访问模型编写的建议，以帮助他们撰写回复。我们将这个新的对话数据集与 InstructGPT 数据集混合，我们将其转换为对话格式。
为了创建强化学习的奖励模型，我们需要收集比较数据，其中包含两个或多个按质量排序的模型响应。为了收集这些数据，我们收集了 AI 培训师与聊天机器人的对话。我们随机选择了一条模型编写的消息，抽取了几个备选的完成方式，并让 AI 培训师对它们进行排名。使用这些奖励模型，我们可以使用近端策略优化来微调模型 。模型可以学习用自然语言表达对其自身答案的不确定性——无需使用模型逻辑。当给出问题时，模型会生成答案和置信度（例如“90% 置信度”或“高置信度”）。这些级别映射到经过良好校准的概率。该模型还在分布变化下保持适度校准，并且对自身答案的不确定性敏感，而不是模仿人类的例子。
2. 模型结构 ChatGPT的基本模型结构：
输入嵌入层（Input Embedding Layer）：
输入嵌入层将文本序列中的每个单词转换成一个高维向量。这些向量的维度通常是几百维，其中每个维度代表单词的一个特定特征。ChatGPT使用预训练的词嵌入向量作为输入，这些向量基于大规模的文本语料库训练得到。
多层Transformer编码器（Multi-layer Transformer Encoder）：
在编码器中，模型将输入序列的嵌入向量通过一系列的自注意力（Self-Attention）和前馈神经网络（Feed-Forward Neural Networks）进行非线性变换。自注意力机制使模型能够自适应地学习输入序列中不同单词之间的依赖关系。在这个过程中，模型将输入序列的嵌入向量逐层传递到下一个编码器层，每层中向量的维度都会被扩大，以提取更多的语义信息。
多层Transformer解码器（Multi-layer Transformer Decoder）：
在解码器中，模型将编码器的输出和上下文信息（如聊天对话历史）通过一系列的自注意力和前馈神经网络进行非线性变换，生成下一个文本序列。在生成期间，模型会根据之前生成的所有单词和输入序列的信息，预测下一个单词的概率分布，并将概率最高的单词作为下一个单词输出。生成的单词向量也会被传递到下一层，每层中向量的维度都会被缩小，以逐渐将生成的序列转换成更高层次的语义表示。
头部层（Head Layer）：
在模型的顶部，可以添加不同的头部层，以使模型适用于不同的自然语言处理任务。例如，对于聊天机器人任务，可以添加一个生成头部层，将模型的输出作为自然语言回复。对于文本分类任务，可以添加一个分类头部层，将模型的输出作为文本分类的概率分布。头部层通常是由全连接层（Fully Connected Layer）和softmax函数组成，以将模型的输出转换成相应的目标格式。
在训练期间，ChatGPT模型使用自回归的方式，即从左到右逐个生成文本。每个时间步生成的单词基于之前生成的所有单词和输入序列的信息。而在生成期间，ChatGPT模型使用了自注意力机制，能够在不同的上下文中自适应地学习语言模型。
3. Openai API &#43; Flask Github 源代码 GPT 3 &#43; Flask (text-davinci-003 API):
https://github.com/redemptionwxy/GPT3-API-Flask-Python_Chat_Website
GPT 3.5 &#43; Flask (gpt-3.5-turbo API ):
https://github.com/redemptionwxy/ChatGPT-API-Flask-Website" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/9c47e0e06580ff42724ca74fb643d61b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-08T20:51:59+08:00" />
<meta property="article:modified_time" content="2023-03-08T20:51:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GPT 模型介绍 | GPT3 / GPT3.5 &#43; Flask | Github源码链接</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="1__0"></a>1. 模型介绍</h2> 
<p>Chatgpt 使用与 InstructGPT相同的方法，使用来自人类反馈的强化学习 (RLHF) 来训练该模型，但数据收集设置略有不同。我们使用监督微调训练了一个初始模型：人类 AI 训练员提供对话，他们在对话中扮演双方——用户和 AI 助手。我们让培训师可以访问模型编写的建议，以帮助他们撰写回复。我们将这个新的对话数据集与 InstructGPT 数据集混合，我们将其转换为对话格式。</p> 
<p>为了创建强化学习的奖励模型，我们需要收集比较数据，其中包含两个或多个按质量排序的模型响应。为了收集这些数据，我们收集了 AI 培训师与聊天机器人的对话。我们随机选择了一条模型编写的消息，抽取了几个备选的完成方式，并让 AI 培训师对它们进行排名。使用这些奖励模型，我们可以使用近端策略优化来微调模型 。模型可以学习用自然语言表达对其自身答案的不确定性——无需使用模型逻辑。当给出问题时，模型会生成答案和置信度（例如“90% 置信度”或“高置信度”）。这些级别映射到经过良好校准的概率。该模型还在分布变化下保持适度校准，并且对自身答案的不确定性敏感，而不是模仿人类的例子。</p> 
<h2><a id="2__5"></a>2. 模型结构</h2> 
<p>ChatGPT的基本模型结构：</p> 
<ol><li> <p>输入嵌入层（Input Embedding Layer）：<br> 输入嵌入层将文本序列中的每个单词转换成一个高维向量。这些向量的维度通常是几百维，其中每个维度代表单词的一个特定特征。ChatGPT使用预训练的词嵌入向量作为输入，这些向量基于大规模的文本语料库训练得到。</p> </li><li> <p>多层Transformer编码器（Multi-layer Transformer Encoder）：<br> 在编码器中，模型将输入序列的嵌入向量通过一系列的自注意力（Self-Attention）和前馈神经网络（Feed-Forward Neural Networks）进行非线性变换。自注意力机制使模型能够自适应地学习输入序列中不同单词之间的依赖关系。在这个过程中，模型将输入序列的嵌入向量逐层传递到下一个编码器层，每层中向量的维度都会被扩大，以提取更多的语义信息。</p> </li><li> <p>多层Transformer解码器（Multi-layer Transformer Decoder）：<br> 在解码器中，模型将编码器的输出和上下文信息（如聊天对话历史）通过一系列的自注意力和前馈神经网络进行非线性变换，生成下一个文本序列。在生成期间，模型会根据之前生成的所有单词和输入序列的信息，预测下一个单词的概率分布，并将概率最高的单词作为下一个单词输出。生成的单词向量也会被传递到下一层，每层中向量的维度都会被缩小，以逐渐将生成的序列转换成更高层次的语义表示。</p> </li><li> <p>头部层（Head Layer）：<br> 在模型的顶部，可以添加不同的头部层，以使模型适用于不同的自然语言处理任务。例如，对于聊天机器人任务，可以添加一个生成头部层，将模型的输出作为自然语言回复。对于文本分类任务，可以添加一个分类头部层，将模型的输出作为文本分类的概率分布。头部层通常是由全连接层（Fully Connected Layer）和softmax函数组成，以将模型的输出转换成相应的目标格式。</p> </li></ol> 
<p>在训练期间，ChatGPT模型使用自回归的方式，即从左到右逐个生成文本。每个时间步生成的单词基于之前生成的所有单词和输入序列的信息。而在生成期间，ChatGPT模型使用了自注意力机制，能够在不同的上下文中自适应地学习语言模型。</p> 
<h2><a id="3_Openai_API__Flask_Github__22"></a>3. Openai API + Flask Github 源代码</h2> 
<p>GPT 3 + Flask (text-davinci-003 API):<br> <a href="https://github.com/redemptionwxy/GPT3-API-Flask-Python_Chat_Website">https://github.com/redemptionwxy/GPT3-API-Flask-Python_Chat_Website</a></p> 
<p>GPT 3.5 + Flask (gpt-3.5-turbo API ):<br> <a href="https://github.com/redemptionwxy/ChatGPT-API-Flask-Website">https://github.com/redemptionwxy/ChatGPT-API-Flask-Website</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c92938407df5e54386ce736a150c4544/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JavaEE课程实践-Servlet的部署（tomcat服务器）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f3da16ac4a3a4ab3c661c69790f1d2a9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【微信小程序】-- 案例 - 本地生活（列表页面）（三十）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>