<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战&#43;细节） - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战&#43;细节）" />
<meta property="og:description" content="大家好，我是【同学小张】。持续学习，持续干货输出，关注我，跟我一起学AI大模型技能。
大多数LLM应用程序都有一个会话接口。会话的一个重要组成部分是能够参考会话早期的信息（上文信息）。这种存储过去互动信息的能力就称为“记忆（Memory）”。LangChain提供了许多用于向系统添加Memory的封装。
目前 LangChain 中大多数的Memory封装还都是测试版本。成熟的Memory主要是ChatMessageHistory。
0. 认识Memory Memory，通俗的讲，就是记录对话的上下文信息，在有需要的时候补充到用户的提问中去。看上图，简单说下Memory的使用流程：
当用户输入一个问题，首先从Memory中读取相关的上文信息（历史对话信息），然后组装成一个Prompt，调用大模型，大模型的回复作为历史对话信息保存在Memory中，供之后的对话使用。 下面让我们来看一看LangChain的Memory到底长什么样。
0. 对话上下文ConversationBufferMemory 这是最简单的Memory形式，保存形式类似是chat message的数组。
使用方法如下：
save_context 可以保存信息到memory中load_memory_variables 获取memory中的信息chat_memory.add_user_message和chat_memory.add_ai_message 也可以用来保存信息到memory中 from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory history = ConversationBufferMemory() history.save_context({&#34;input&#34;: &#34;你好啊&#34;}, {&#34;output&#34;: &#34;你也好啊&#34;}) print(history.load_memory_variables({})) history.save_context({&#34;input&#34;: &#34;你再好啊&#34;}, {&#34;output&#34;: &#34;你又好啊&#34;}) print(history.load_memory_variables({})) history.chat_memory.add_user_message(&#34;你在干嘛&#34;) history.chat_memory.add_ai_message(&#34;我在学习&#34;) print(history.load_memory_variables({})) ## 或者直接使用 ChatMessageHistory 添加memory，效果一样 # from langchain.memory import ChatMessageHistory # chat_history = ChatMessageHistory() # chat_history.add_user_message(&#34;你在干嘛&#34;) # chat_history.add_ai_message(&#34;我在学习&#34;) # print(history.load_memory_variables({})) 运行结果：
上面的结果，可以看到返回的信息永远都是以“history”开头的，怎么修改这个key呢？只需要修改下面一句，填入 memory_key 参数。
history = ConversationBufferMemory(memory_key=&#34;chat_history_with_同学小张&#34;) 运行结果：
返回的结果还有一点值得注意，那就是它目前返回的是一个json字符串，这是可以直接给LLMs对话输入的。但对于ChatModels对话，它接收的参数是Chat Messages数组。我们可以通过改变参数return_messages=True，让这个memory的返回变成Chat Messages数组。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/2788defe5a86d8e11438792fa307eb83/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-07T06:30:00+08:00" />
<meta property="article:modified_time" content="2024-02-07T06:30:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战&#43;细节）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p><strong>大家好，我是【同学小张】。持续学习，持续干货输出，关注我，跟我一起学AI大模型技能。</strong></p> 
</blockquote> 
<p>大多数LLM应用程序都有一个会话接口。会话的一个重要组成部分是能够参考会话早期的信息（上文信息）。这种存储过去互动信息的能力就称为“记忆（Memory）”。LangChain提供了许多用于向系统添加Memory的封装。</p> 
<blockquote> 
 <p>目前 LangChain 中大多数的Memory封装还都是测试版本。成熟的Memory主要是<code>ChatMessageHistory</code>。</p> 
</blockquote> 
<h3><a id="0_Memory_8"></a>0. 认识Memory</h3> 
<p><img src="https://images2.imgbox.com/e0/b4/SOUiRR7g_o.png" alt="在这里插入图片描述"></p> 
<p>Memory，通俗的讲，就是记录对话的上下文信息，在有需要的时候补充到用户的提问中去。看上图，简单说下Memory的使用流程：</p> 
<ul><li>当用户输入一个问题，首先从Memory中读取相关的上文信息（历史对话信息），然后组装成一个Prompt，调用大模型，大模型的回复作为历史对话信息保存在Memory中，供之后的对话使用。</li></ul> 
<p>下面让我们来看一看LangChain的Memory到底长什么样。</p> 
<h3><a id="0_ConversationBufferMemory_16"></a>0. 对话上下文<code>ConversationBufferMemory</code></h3> 
<p>这是最简单的Memory形式，保存形式类似是chat message的数组。<br> 使用方法如下：</p> 
<ul><li><code>save_context</code> 可以保存信息到memory中</li><li><code>load_memory_variables</code> 获取memory中的信息</li><li><code>chat_memory.add_user_message</code>和<code>chat_memory.add_ai_message</code> 也可以用来保存信息到memory中</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferMemory<span class="token punctuation">,</span> ConversationBufferWindowMemory

history <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span>
history<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"你好啊"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"你也好啊"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>history<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

history<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"你再好啊"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"你又好啊"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>history<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

history<span class="token punctuation">.</span>chat_memory<span class="token punctuation">.</span>add_user_message<span class="token punctuation">(</span><span class="token string">"你在干嘛"</span><span class="token punctuation">)</span>
history<span class="token punctuation">.</span>chat_memory<span class="token punctuation">.</span>add_ai_message<span class="token punctuation">(</span><span class="token string">"我在学习"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>history<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">## 或者直接使用 ChatMessageHistory 添加memory，效果一样</span>
<span class="token comment"># from langchain.memory import ChatMessageHistory</span>
<span class="token comment"># chat_history = ChatMessageHistory()</span>
<span class="token comment"># chat_history.add_user_message("你在干嘛")</span>
<span class="token comment"># chat_history.add_ai_message("我在学习")</span>
<span class="token comment"># print(history.load_memory_variables({}))</span>
</code></pre> 
<p>运行结果：</p> 
<p><img src="https://images2.imgbox.com/51/98/q4i3kKr5_o.png" alt="在这里插入图片描述"><br> 上面的结果，可以看到返回的信息永远都是以“history”开头的，怎么修改这个key呢？只需要修改下面一句，填入 <code>memory_key</code> 参数。</p> 
<pre><code class="prism language-python">history <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span>memory_key<span class="token operator">=</span><span class="token string">"chat_history_with_同学小张"</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<p><img src="https://images2.imgbox.com/12/62/e9nE00ag_o.png" alt="在这里插入图片描述"><br> 返回的结果还有一点值得注意，那就是它目前返回的是一个json字符串，这是可以直接给LLMs对话输入的。但对于ChatModels对话，它接收的参数是Chat Messages数组。我们可以通过改变参数<code>return_messages=True</code>，让这个memory的返回变成Chat Messages数组。</p> 
<pre><code class="prism language-python">history <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span>memory_key<span class="token operator">=</span><span class="token string">"chat_history_with_同学小张"</span><span class="token punctuation">,</span> return_messages<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<p>返回结果：</p> 
<p><img src="https://images2.imgbox.com/30/00/lm9A2ImJ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_kConversationBufferWindowMemory_68"></a>1. 只保留k个窗口的上下文：<code>ConversationBufferWindowMemory</code></h3> 
<p>ConversationBufferWindowMemory允许用户设置一个K参数，来限定每次从记忆中读取最近的K条记忆。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferWindowMemory

window <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
window<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"第一轮问"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"第一轮答"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
window<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"第二轮问"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"第二轮答"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
window<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"第三轮问"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"第三轮答"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>window<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<p><img src="https://images2.imgbox.com/e2/1a/hHwKVTBf_o.png" alt="在这里插入图片描述" width="400"></p> 
<h3><a id="2__Token_ConversationTokenBufferMemory_86"></a>2. 通过 Token 数控制上下文长度：<code>ConversationTokenBufferMemory</code></h3> 
<p>ConversationTokenBufferMemory允许用户指定最大的token长度，使得从记忆中取上文时不会超过token限制。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationTokenBufferMemory
memory <span class="token operator">=</span> ConversationTokenBufferMemory<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    max_token_limit<span class="token operator">=</span><span class="token number">45</span>
<span class="token punctuation">)</span>
memory<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"你好啊"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"你好，我是你的AI助手。"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
memory<span class="token punctuation">.</span>save_context<span class="token punctuation">(</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"你会干什么"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"我什么都会"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>memory<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/7d/df/DggVlkFX_o.png" alt="在这里插入图片描述" width="600"></p> 
<h3><a id="3__105"></a>3. 更多记忆类型</h3> 
<ul><li> <p>ConversationSummaryMemory: 对上下文做摘要</p> </li><li> <p>ConversationSummaryBufferMemory: 保存 Token 数限制内的上下文，对更早的做摘要</p> </li><li> <p>VectorStoreRetrieverMemory: 将 Memory 存储在向量数据库中，根据用户输入检索回最相关的部分</p> </li><li> <p>ConversationEntityMemory：保存一些实体信息，例如从输入中找出一个人名，保存这个人的信息。</p> </li></ul> 
<p><img src="https://images2.imgbox.com/8e/be/v2lMMQ2o_o.png" alt="在这里插入图片描述" width="600"></p> 
<h3><a id="4__116"></a>4. 总计</h3> 
<p>本文我们学习了 LangChain 的 Memory 记忆模块，可以看到它里面封装了很多的记忆类型，在项目中可以按需选用。但是也应该认识到，目前LangChain的记忆模块还不成熟，是测试版本。LangChain的快速迭代，需要我们时刻关注它的变化。</p> 
<blockquote> 
 <p><strong>如果觉得本文对你有帮助，麻烦点个赞和关注呗 ~~~</strong></p> 
</blockquote> 
<hr> 
<blockquote> 
 <ul><li>大家好，我是同学小张</li><li>欢迎 <strong>点赞 + 关注</strong> 👏，促使我<strong>持续学习</strong>，<strong>持续干货输出</strong>。</li><li>+v: <strong>jasper_8017</strong> 一起交流💬，一起进步💪。</li><li>微信公众号也可搜【同学小张】 🙏</li><li><strong><mark>踩坑不易，感谢关注和围观</mark></strong></li></ul> 
</blockquote> 
<p><strong><mark>本站文章一览：</mark></strong></p> 
<p><img src="https://images2.imgbox.com/3a/a8/KYvnWxY3_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8889bc409c3f24c655fa09b8911fbac7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Unix五种I/O模型（阻塞、非阻塞、多路复用、信号驱动、异步）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/44aa77e9f0aa328d25b6f436732fe89e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Nexus3之在Window中搭建Maven私服</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>