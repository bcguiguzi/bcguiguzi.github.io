<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>一文搞懂match、match_phrase与match_phrase_prefix的检索过程 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="一文搞懂match、match_phrase与match_phrase_prefix的检索过程" />
<meta property="og:description" content="一、在开始之前，完成数据准备： # 创建映射 PUT /tehero_index { &#34;settings&#34;: { &#34;index&#34;: { &#34;number_of_shards&#34;: 1, &#34;number_of_replicas&#34;: 1 } }, &#34;mappings&#34;: { &#34;_doc&#34;: { &#34;dynamic&#34;: false, &#34;properties&#34;: { &#34;id&#34;: { &#34;type&#34;: &#34;integer&#34; }, &#34;content&#34;: { &#34;type&#34;: &#34;keyword&#34;, &#34;fields&#34;: { &#34;ik_max_analyzer&#34;: { &#34;type&#34;: &#34;text&#34;, &#34;analyzer&#34;: &#34;ik_max_word&#34;, &#34;search_analyzer&#34;: &#34;ik_max_word&#34; }, &#34;ik_smart_analyzer&#34;: { &#34;type&#34;: &#34;text&#34;, &#34;analyzer&#34;: &#34;ik_smart&#34; } } }, &#34;name&#34;:{ &#34;type&#34;:&#34;text&#34; }, &#34;createAt&#34;: { &#34;type&#34;: &#34;date&#34; } } } } } # 导入测试数据 POST _bulk { &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/274b2217ed044bde16525b1a2c1c3825/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-22T20:49:18+08:00" />
<meta property="article:modified_time" content="2024-02-22T20:49:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">一文搞懂match、match_phrase与match_phrase_prefix的检索过程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>一、在开始之前，完成数据准备：</h3> 
<pre><code># 创建映射
PUT /tehero_index
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "number_of_replicas": 1
    }
  },
  "mappings": {
    "_doc": {
      "dynamic": false,
      "properties": {
        "id": {
          "type": "integer"
        },
        "content": {
          "type": "keyword",
          "fields": {
            "ik_max_analyzer": {
              "type": "text",
              "analyzer": "ik_max_word",
              "search_analyzer": "ik_max_word"
            },
            "ik_smart_analyzer": {
              "type": "text",
              "analyzer": "ik_smart"
            }
          }
        },
        "name":{
          "type":"text"
        },
        "createAt": {
          "type": "date"
        }
      }
    }
  }
}
# 导入测试数据
POST _bulk
{ "index" : { "_index" : "tehero_index", "_type" : "_doc", "_id" : "1" } }
{ "id" : 1,"content":"关注我,系统学编程" }
{ "index" : { "_index" : "tehero_index", "_type" : "_doc", "_id" : "2" } }
{ "id" : 2,"content":"系统学编程,关注我" }
{ "index" : { "_index" : "tehero_index", "_type" : "_doc", "_id" : "3" } }
{ "id" : 3,"content":"系统编程,关注我" }
{ "index" : { "_index" : "tehero_index", "_type" : "_doc", "_id" : "4" } }
{ "id" : 4,"content":"关注我,间隔系统学编程" }</code></pre> 
<h3>二、根据ik_smart分词和content字段建立倒排序索引</h3> 
<p>原始数据：</p> 
<blockquote> 
 <strong>{ "id" : 1,"content":"关注我,系统学编程" }</strong> 
 <br> 
 <strong>{ "id" : 2,"content":"系统学编程,关注我" }</strong> 
 <br> 
 <strong>{ "id" : 3,"content":"系统编程,关注我" }</strong> 
 <br> 
 <strong>{ "id" : 4,"content":"关注我,间隔系统学编程" }</strong> 
</blockquote> 
<p></p> 
<p class="img-center"><img alt="" height="564" src="https://images2.imgbox.com/00/14/1ry6x2jo_o.png" width="618"></p> 
<blockquote> 
 <strong>ps：如果看不懂上图，请先阅读学习：<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIxMjE3NjYwOQ%3D%3D%26mid%3D2247483805%26idx%3D1%26sn%3Dd890e383339c2fe5bf265b2d53a8a270%26chksm%3D974b5a13a03cd30558de75c891fc9d471f3477981f49b53c8bb26a84256d9e986e97f5d33808%26scene%3D21%23wechat_redirect" rel="nofollow" title="ElasticSearch系列05：倒排序索引与分词Analysis">ElasticSearch系列05：倒排序索引与分词Analysis</a></strong> 
</blockquote> 
<h3>三、match query 对应到mysql</h3> 
<blockquote> 
 <strong>昨天有小伙伴反馈说，match query 的实例写得太枯燥，建议和mysql对比讲解，今天它来了！</strong> 
</blockquote> 
<pre><code># DSL 语句
GET /tehero_index/_doc/_search
{
  "query":{
    "match":{
      "content.ik_smart_analyzer":"系统编程"
    }
  }
}</code></pre> 
<p>DSL执行步骤分析：</p> 
<ul><li>1）检索词“系统编程”被ik_smart分词器分词为<strong>两个Token【系统】【编程】；</strong></li><li>2）将这两个Token在【倒排索引】中，针对Token字段进行检索，<strong>等价于sql：【where Token = 系统 or Token = 编程】；</strong></li><li>3）对照图【数据的倒排序索引】，可见，<strong>该DSL能检索到所有文档，文档3的评分最高（因为它包含两个Token），其他3个文档评分相同。</strong></li></ul> 
<blockquote>
  有了对应到mysql 的例子，我想大家对match query 这个查询语句，就应该有一个很好的理解。那么接下来，开始学习今天的新知识： 
 <strong>match_phrase query 和match_phrase_prefix query</strong> 
</blockquote> 
<h3>四、match_phrase query</h3> 
<blockquote>
  match_phrase查询分 
 <strong>析文本并根据分析的文本创建一个短语查询。</strong>match_phrase  
 <strong>会将检索关键词分词</strong>。match_phrase的分词结果必 
 <strong>须在被检索字段的分词中都包含</strong>，而且 
 <strong>顺序必须相同，</strong>而且 
 <strong>默认必须都是连续的。</strong> 
</blockquote> 
<p>简单看个例子，与match query 对比下，就很好理解了：</p> 
<p><strong>使用 match_phrase 查询：</strong></p> 
<pre><code># 使用match_phrase查询，ik_smart分词
GET /tehero_index/_doc/_search
{
    "query": {
        "match_phrase": {
            "content.ik_smart_analyzer": {
            	"query": "关注我,系统学"
            }
        }
    }
}

# 结果：只有文档1
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.7370664,
    "hits": [
      {
        "_index": "tehero_index",
        "_type": "_doc",
        "_id": "1",
        "_score": 0.7370664,
        "_source": {
          "id": 1,
          "content": "关注我,系统学编程"
        }
      }
    ]
  }
}</code></pre> 
<p><strong>使用 match 查询：</strong></p> 
<pre><code># 使用match查询，ik_smart分词
GET /tehero_index/_doc/_search
{
    "query": {
        "match": {
            "content.ik_smart_analyzer": {
            	"query": "关注我,系统学"
            }
        }
    }
}
# 可以查询出所有结果</code></pre> 
<blockquote>
  分析：上面的例子使用的 
 <strong>分词器是ik_smart，</strong>所以 
 <strong>检索词“关注我，系统学”会被分词为3个Token【关注、我、系统学】</strong>；而文档1、文档2和文档4 的content被分词后 
 <strong>都包含这3个关键词</strong>，但是 
 <strong>只有文档1的Token的顺序和检索词一致，且连续</strong>。所以使用 match_phrase 查询 
 <strong>只能查询到文档1</strong>（ps：文档2 Token顺序不一致；文档4 Token不连续；文档3 Token没有完全包含）。 
 <strong>使用 match查询</strong>可以查询到所有文档，是因为所有文档 
 <strong>都有【关注、我】这两个Token</strong>。 
</blockquote> 
<ul><li><strong>4.1 match_phrase 核心参数：slop 参数-Token之间的位置距离容差值</strong></li></ul> 
<pre><code># 将上面的 match_phrase 查询新增一个 slop参数
GET /tehero_index/_doc/_search
{
    "query": {
        "match_phrase": {
            "content.ik_smart_analyzer": {
            	"query": "关注我,系统学",
            	"slop":1
            }
        }
    }
}
# 结果：文档1和文档4都被检索出来</code></pre> 
<blockquote> 
 <strong>分析：使用 analyze 接口 分析下文档4的Token</strong> 
</blockquote> 
<pre><code># 文档4 content 的分词
GET /_analyze
{
  "text": ["关注我,间隔系统学编程"],
  "analyzer": "ik_smart"
}
# 结果
{
  "tokens": [
    {
      "token": "关注",
      "start_offset": 0,
      "end_offset": 2,
      "type": "CN_WORD",
      "position": 0
    },
    {
      "token": "我",
      "start_offset": 2,
      "end_offset": 3,
      "type": "CN_CHAR",
      "position": 1
    },
    {
      "token": "间隔",
      "start_offset": 4,
      "end_offset": 6,
      "type": "CN_WORD",
      "position": 2
    },
    {
      "token": "系统学",
      "start_offset": 6,
      "end_offset": 9,
      "type": "CN_WORD",
      "position": 3
    },
    {
      "token": "编程",
      "start_offset": 9,
      "end_offset": 11,
      "type": "CN_WORD",
      "position": 4
    }
  ]
}</code></pre> 
<blockquote>
  通过分词测试，发现Token【我】与【系统学】的 
 <strong>position差值为1(</strong>等于slop的值 
 <strong>)</strong>， 
 <strong>所以文档4也被检索出来了。</strong> 
</blockquote> 
<p>ps：如果没看明白<strong>，那就来看下match_phrase query对应到mysql是怎样的吧！</strong></p> 
<p></p> 
<p class="img-center"><img alt="" height="564" src="https://images2.imgbox.com/32/61/m5quQLBX_o.png" width="618"></p> 
<ul><li><strong>4.2</strong><strong>match_phrase query</strong><strong>对应到mysql</strong></li></ul> 
<pre><code># DSL语句
GET /tehero_index/_doc/_search
{
  "query":{
    "match_phrase":{
      "content.ik_smart_analyzer":"系统编程"
    }
  }
}</code></pre> 
<p>DSL执行步骤分析：</p> 
<ul><li>1）检索词“系统编程”被分词为<strong>两个Token【系统，Position=0】【编程，Position=1】；</strong></li><li>2）倒排索引检索时，<strong>等价于sql：</strong>【where Token = 系统 and <strong>系统_Position=0</strong> and Token = 编程 and <strong>编程_Position=1</strong>】；</li><li>3）对照图【数据的倒排序索引】，只有文档3满足条件，所以该DSL语句只能查询到文档3。</li></ul> 
<h3>五、match_phrase_prefix query</h3> 
<blockquote>
  与match_phrase查询类似，但是 
 <strong>会对最后一个Token在倒排序索引列表中进行通配符搜索</strong>。Token的模糊匹配数控制： 
 <strong>max_expansions 默认值为50。</strong>我们使用 
 <strong>content.ik_smart_analyzer </strong>这个字段中的 
 <strong>【系统学】</strong>（文档1、2、4 包含）和 
 <strong>【系统】</strong>（文档3包含）这 
 <strong>两个Token</strong>来讲解match_phraseprefix 的用法：（因为 
 <strong>使用的是ik_smart分词器</strong>，所以【系统学】就只能被分词为一个Token） 
</blockquote> 
<pre><code># 1、先使用match_phrase查询，没有结果
GET tehero_index/_doc/_search
{
  "query": {
    "match_phrase": {
      "content.ik_smart_analyzer": {
        "query": "系"
      }
    }
  }
}

# 2、使用match_phrase_prefix查询， "max_expansions": 1，得到文档3
GET tehero_index/_doc/_search
{
  "query": {
    "match_phrase_prefix": {
      "content.ik_smart_analyzer": {
        "query": "系",
        "max_expansions": 1
      }
    }
  }
}

# 3、使用match_phrase_prefix查询， "max_expansions": 2，得到所有文档
GET tehero_index/_doc/_search
{
  "query": {
    "match_phrase_prefix": {
      "content.ik_smart_analyzer": {
        "query": "系",
        "max_expansions": 2
      }
    }
  }
}</code></pre> 
<blockquote>
  结果分析：【语句1】查不到结果，是因为 
 <strong>根据ik_smart分词器生成的倒排序索引中</strong>，所有文档中都 
 <strong>不包含Token【系】</strong>；【语句2】查询到文档3，是因为 
 <strong>文档3包含Token【系统】，同时</strong> "max_expansions": 1，所以 
 <strong>检索关键词【系】+ 1个通配符匹配</strong>，就可以匹配到 
 <strong>一个Token</strong>【系统】；【语句3】查询到所有文档，是因为"max_expansions": 2，所以 
 <strong>检索关键词【系】+ 2个通配符匹配</strong>，就可以匹配到 
 <strong>两个Token</strong>【系统、系统学】，所以就可以查询到所有。回忆下，之前所讲的es倒排序索引原理： 
 <strong>先分词创建倒排序索引，再检索倒排序索引得到文档</strong>，就很好理解了 
 <strong>。</strong> 
</blockquote> 
<p>注意："max_expansions"的<strong>值最小为1</strong>，<strong>哪怕你设置为0，依然会 + 1个通配符匹配；所以，</strong>尽量不要用该语句，因为，<strong>最后一个Token始终要去扫描大量的索引</strong>，<strong>性能可能会很差。</strong></p> 
<p></p> 
<p class="img-center"><img alt="" height="564" src="https://images2.imgbox.com/68/2f/M7uMeHPi_o.png" width="618"></p> 
<ul><li><strong>5.1 match_phrase_prefix query 对应到mysql</strong></li></ul> 
<pre><code>GET tehero_index/_doc/_search
{
  "query": {
    "match_phrase_prefix": {
      "content.ik_smart_analyzer": {
        "query": "系",
        "max_expansions": 1
      }
    }
  }
}</code></pre> 
<p>DSL执行步骤分析：</p> 
<ul><li>1）检索词“系”被分词为一个<strong>个Token【系】+ 1个通配符；</strong></li><li>2）倒排索引检索时，等价于sql：【where Token = 系 or Token <strong>like “系_”</strong>】；</li><li>3）对照图【数据的倒排序索引】，只有<strong>文档3满足条件包含Token【系统】</strong>，所以该DSL语句只能查询到文档3。</li></ul> 
<h3>六、总结</h3> 
<p>到此，我们已经学习了 Full text queries最常用的3种查询：</p> 
<blockquote> 
 <strong>1）match query</strong>：用于执行全文查询的标准查询，包括 
 <strong>模糊匹配和短语或接近查询。重要参数：控制Token之间的布尔关系：operator：or/and</strong> 
 <br> 
 <strong>2）match_phrase query：</strong>与match查询类似， 
 <strong>但用于匹配确切的短语或单词接近匹配。重要参数：Token之间的位置距离：slop 参数</strong> 
 <br> 
 <strong>3）match_phrase_prefix query：</strong>与match_phrase查询类似，但是会 
 <strong>对最后一个Token在倒排序索引列表中进行通配符搜索。重要参数：模糊匹配数控制：max_expansions 默认值50，最小值为1</strong> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cb418caea6fe767be7224367e68e9053/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">查找日期最相近的数据文件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/524e0cd2feeb51b258f5b064e2cfea22/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【EI会议征稿通知】2024年软件自动化与程序分析国际学术会议（SAPA 2024)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>