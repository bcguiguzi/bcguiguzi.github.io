<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>语义分割入门系列之 FCN（全卷积神经网络） - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="语义分割入门系列之 FCN（全卷积神经网络）" />
<meta property="og:description" content="FCN论文解读及代码分析 Fully Convolutional Networks for Semantic Segmentation FCN是卷积神经网络用于语义分割的开山之作，文章的出发点在于如何将普通的分类卷积神经网络用于语义分割网络。卷积神经网络在分类任务上取得了重大突破，因为随着卷积网络的层数加深，网络从图像中提取出越来越抽象的语义信息特征图的通道数越来越多，并且为了控制计算量，特征图的分辨率越来越小，并且最后还有全连接层做softmax预测，将整个图片的空间位置信息全部破坏。
FCN便从这方面入手，提出方案将普通分类卷积神经网络改造成能够进行语义分割的网络。下面来介绍FCN到底是如何做的。
1.修改分类器，使网络能够密集预测 如图所示，普通的分类神经网络最后的全连接层，输出的是该图片对应于每个分类的概率。将最后的全连接层全部替换成1x1的卷积卷积核，这样既实现全连接层的计算功能，又保持了特征图的空间分辨率，可以生成一个分类网络的热力图，热力图的分辨率很低，但是依然可以表示出让网络做出该判断的响应位置，这样就有了位置信息（很粗糙的位置信息）。并且，替换掉全连接层后带来的好处是，输入图片的尺寸可以是任意size的。
2. 深层与浅层的融合 上一步将全连接层替换成卷积层之后，特征响应的位置得以保留，但是网络最后特征图的尺寸已将很小（VGG经过5次下采样，resnet也经过5次下采样，最后一个特征图的分辨率是原图的2^5=32倍，虽然有特征响应的位置，但是无法对应到原图的精确位置），所以，FCN提出将深层的、分辨率粗糙的语义信息，与浅层的高分辨率的精细特征结合，以此来修复热力图的分辨率，使其不断上采样到原图尺寸，这样就得到了原图分辨率的结果。具体操作如下图：
图片来自：https://zhuanlan.zhihu.com/p/31428783，比论文原图更好理解
FCN32s是将最后一个特征图，直接上采样32倍（5次步长为2的3x3的反卷积操作），得到最后的分割结果。代码如下（pytorch实现）：其中pretrained_net表示的是backbone网络
class FCN32s(nn.Module): def __init__(self, pretrained_net, n_class): super().__init__() self.n_class = n_class self.pretrained_net = pretrained_net self.relu = nn.ReLU(inplace=True) self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1) self.bn1 = nn.BatchNorm2d(512) self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1) self.bn2 = nn.BatchNorm2d(256) self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1) self.bn3 = nn.BatchNorm2d(128) self.deconv4 = nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/02d3d15211dbca1fb64acad4dd797d2a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-01-06T20:45:37+08:00" />
<meta property="article:modified_time" content="2020-01-06T20:45:37+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">语义分割入门系列之 FCN（全卷积神经网络）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="FCN_0"></a>FCN论文解读及代码分析</h3> 
<h3><a id="Fully_Convolutional_Networks_for_Semantic_Segmentation_1"></a><strong>Fully Convolutional Networks for Semantic Segmentation</strong></h3> 
<p>FCN是卷积神经网络用于语义分割的开山之作，文章的出发点在于如何将普通的分类卷积神经网络用于语义分割网络。卷积神经网络在分类任务上取得了重大突破，因为随着卷积网络的层数加深，网络从图像中提取出越来越抽象的语义信息特征图的通道数越来越多，并且为了控制计算量，特征图的分辨率越来越小，并且最后还有全连接层做softmax预测，将整个图片的空间位置信息全部破坏。<br> FCN便从这方面入手，提出方案将普通分类卷积神经网络改造成能够进行语义分割的网络。下面来介绍FCN到底是如何做的。</p> 
<h4><a id="1_6"></a>1.修改分类器，使网络能够密集预测</h4> 
<p><img src="https://images2.imgbox.com/63/fe/jKIABId4_o.png" alt="在这里插入图片描述"><br> 如图所示，普通的分类神经网络最后的全连接层，输出的是该图片对应于每个分类的概率。将最后的全连接层全部替换成1x1的卷积卷积核，这样既实现全连接层的计算功能，又保持了特征图的空间分辨率，可以生成一个分类网络的热力图，热力图的分辨率很低，但是依然可以表示出让网络做出该判断的响应位置，这样就有了位置信息（很粗糙的位置信息）。并且，替换掉全连接层后带来的好处是，输入图片的尺寸可以是任意size的。</p> 
<h4><a id="2__10"></a>2. 深层与浅层的融合</h4> 
<p>上一步将全连接层替换成卷积层之后，特征响应的位置得以保留，但是网络最后特征图的尺寸已将很小（VGG经过5次下采样，resnet也经过5次下采样，最后一个特征图的分辨率是原图的2^5=32倍，虽然有特征响应的位置，但是无法对应到原图的精确位置），所以，FCN提出将深层的、分辨率粗糙的语义信息，与浅层的高分辨率的精细特征结合，以此来修复热力图的分辨率，使其不断上采样到原图尺寸，这样就得到了原图分辨率的结果。具体操作如下图：<br> <img src="https://images2.imgbox.com/d9/7e/nrsVUuCt_o.png" alt="图片转载于：https://zhuanlan.zhihu.com/p/31428783"><br> 图片来自：https://zhuanlan.zhihu.com/p/31428783，比论文原图更好理解<br> FCN32s是将最后一个特征图，直接上采样32倍（5次步长为2的3x3的反卷积操作），得到最后的分割结果。代码如下（pytorch实现）：其中pretrained_net表示的是backbone网络</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">FCN32s</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_net<span class="token punctuation">,</span> n_class<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>n_class <span class="token operator">=</span> n_class
        self<span class="token punctuation">.</span>pretrained_net <span class="token operator">=</span> pretrained_net
        self<span class="token punctuation">.</span>relu    <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn3     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn4     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn5     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> n_class<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>pretrained_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x5 <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'x5'</span><span class="token punctuation">]</span>  

        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv1<span class="token punctuation">(</span>x5<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv2<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv3<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv4<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn5<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv5<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>score<span class="token punctuation">)</span>                    

        <span class="token keyword">return</span> score 
</code></pre> 
<p>FCN16s则是将最后一个特征图（pool5的结果）用步长为2的3x3反卷积（参数可学）上采样一倍，得到的结果与pool4的结果相加，它们俩的分辨率相同，都是原图的1/16。这样得到的结果在通过16倍上采样得到与原图相同的分辨率。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">FCN16s</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_net<span class="token punctuation">,</span> n_class<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>n_class <span class="token operator">=</span> n_class
        self<span class="token punctuation">.</span>pretrained_net <span class="token operator">=</span> pretrained_net
        self<span class="token punctuation">.</span>relu    <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn3     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn4     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn5     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> n_class<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>pretrained_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x5 <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'x5'</span><span class="token punctuation">]</span>  
        x4 <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'x4'</span><span class="token punctuation">]</span>  

        score <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv1<span class="token punctuation">(</span>x5<span class="token punctuation">)</span><span class="token punctuation">)</span>               
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>score <span class="token operator">+</span> x4<span class="token punctuation">)</span>                      
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv2<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv3<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv4<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn5<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv5<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>score<span class="token punctuation">)</span>                   

        <span class="token keyword">return</span> score  
</code></pre> 
<p>FCN8s 则是将FCN16s中1/16的特征图，再次通过一个2倍的上采样，与pool3的结果相加，得到原图分辨率1/8的特征图，再通过8倍的上采样得到原图相同分辨率分割结果。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">FCN8s</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pretrained_net<span class="token punctuation">,</span> n_class<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>n_class <span class="token operator">=</span> n_class
        self<span class="token punctuation">.</span>pretrained_net <span class="token operator">=</span> pretrained_net
        self<span class="token punctuation">.</span>relu    <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn2     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn3     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn4     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>deconv5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> output_padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn5     <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> n_class<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>pretrained_net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x5 <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'x5'</span><span class="token punctuation">]</span>  
        x4 <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'x4'</span><span class="token punctuation">]</span>  
        x3 <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'x3'</span><span class="token punctuation">]</span>  

        score <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv1<span class="token punctuation">(</span>x5<span class="token punctuation">)</span><span class="token punctuation">)</span>              
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>score <span class="token operator">+</span> x4<span class="token punctuation">)</span>                      
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv2<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span>            
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>score <span class="token operator">+</span> x3<span class="token punctuation">)</span>                      
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv3<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv4<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>bn5<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>deconv5<span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        score <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>score<span class="token punctuation">)</span>                    

        <span class="token keyword">return</span> score  
</code></pre> 
<p>注意，以上步骤中的上采样全部都由3x3的反卷积操作完成，参数可学。<br> 三者效果如下：<br> <img src="https://images2.imgbox.com/50/b2/wEr0dR9u_o.png" alt="在这里插入图片描述"><br> 可见，直接上采样32倍的FCN32s效果最差，因为直接上采样太多倍导致结果粗糙，而后面逐步结合了浅层特征的网络结果效果则越来越好。<br> 后续很多工作延续了这个思想，从分类网络的结果开始逐步结合前面的浅层特征，以实现精细的分割。</p> 
<p>参考文献：Long J , Shelhamer E , Darrell T . Fully Convolutional Networks for Semantic Segmentation[J]. IEEE Transactions on Pattern Analysis &amp; Machine Intelligence, 2014, 39(4):640-651.</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6a82781ffaaccd07a284066cc9179743/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Flutter plugin not installed; 问题解决</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ff357687877aac1b8c46f81748c8cfb4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">QDockWidget</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>