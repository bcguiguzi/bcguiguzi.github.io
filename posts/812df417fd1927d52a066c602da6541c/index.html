<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>如何高效实现 MySQL 与 elasticsearch 的数据同步 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="如何高效实现 MySQL 与 elasticsearch 的数据同步" />
<meta property="og:description" content="MySQL 自身简单、高效、可靠，是又拍云内部使用最广泛的数据库。但是当数据量达到一定程度的时候，对整个 MySQL 的操作会变得非常迟缓。而公司内部 robin/logs 表的数据量已经达到 800w，后续又有全文检索的需求。这个需求直接在 MySQL 上实施是难以做到的。
原数据库的同步问题 由于传统的 mysql 数据库并不擅长海量数据的检索，当数据量到达一定规模时（估算单表两千万左右），查询和插入的耗时会明显增加。同样，当需要对这些数据进行模糊查询或是数据分析时，MySQL作为事务型关系数据库很难提供良好的性能支持。使用适合的数据库来实现模糊查询是解决这个问题的关键。
但是，切换数据库会迎来两个问题，一是已有的服务对现在的 MySQL 重度依赖，二是 MySQL 的事务能力和软件生态仍然不可替代，直接迁移数据库的成本过大。我们综合考虑了下，决定同时使用多个数据库的方案，不同的数据库应用于不同的使用场景。而在支持模糊查询功能的数据库中，elasticsearch 自然是首选的查询数据库。这样后续对业务需求的切换也会非常灵活。
那具体该如何实现呢？在又拍云以往的项目中，也有遇到相似的问题。之前采用的方法是在业务中编写代码，然后同步到 elasticsearch 中。具体是这样实施的：每个系统编写特定的代码，修改 MySQL 数据库后，再将更新的数据直接推送到需要同步的数据库中，或推送到队列由消费程序来写入到数据库中。
但这个方案有一些明显的缺点：
系统高耦合，侵入式代码，使得业务逻辑复杂度增加
方案不通用，每一套同步都需要额外定制，不仅增加业务处理时间，还会提升软件复复杂度
工作量和复杂度增加
在业务中编写同步方案，虽然在项目早期比较方便，但随着数据量和系统的发展壮大，往往最后会成为业务的大痛点。
解决思路及方案 调整架构 既然以往的方案有明显的缺点，那我们如何来解决它呢？优秀的解决方案往往是 “通过架构来解决问题“，那么能不能通过架构的思想来解决问题呢？
答案是可以的。我们可以将程序伪装成 “从数据库”，主库的增量变化会传递到从库，那这个伪装成 “从数据库” 的程序就能实时获取到数据变化，然后将增量的变化推送到消息队列 MQ，后续消费者消耗 MQ 的数据，然后经过处理之后再推送到各自需要的数据库。
这个架构的核心是通过监听 MySQL 的 binlog 来同步增量数据，通过基于 query 的查询旧表来同步旧数据，这就是本文要讲的一种异构数据库同步的实践。
改进数据库 经过深度的调研，成功得到了一套异构数据库同步方案，并且成功将公司生产环境下的 robin/logs 的表同步到了 elasticsearch 上。
首先对 MySQL 开启 binlog，但是由于 maxwell 需要的 binlog_format=row 原本的生产环境的数据库不宜修改。这里请教了海杨前辈，他提供了”从库联级“的思路，在从库中监听 binlog 绕过了操作生产环境重启主库的操作，大大降低了系统风险。
后续操作比较顺利，启动 maxwell 监听从库变化，然后将增量变化推送到 kafka ，最后配置 logstash 消费 kafka中的数据变化事件信息，将结果推送到 elasticsearch。配置 logstash需要结合表结构，这是整套方案实施的重点。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/812df417fd1927d52a066c602da6541c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-30T13:28:18+08:00" />
<meta property="article:modified_time" content="2023-06-30T13:28:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">如何高效实现 MySQL 与 elasticsearch 的数据同步</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>MySQL 自身简单、高效、可靠，是又拍云内部使用最广泛的数据库。但是当数据量达到一定程度的时候，对整个 MySQL 的操作会变得非常迟缓。而公司内部 robin/logs 表的数据量已经达到 800w，后续又有全文检索的需求。这个需求直接在 MySQL 上实施是难以做到的。</p> 
<h3 id="原数据库的同步问题">原数据库的同步问题</h3> 
<p>由于传统的 mysql 数据库并不擅长海量数据的检索，当数据量到达一定规模时（估算单表两千万左右），查询和插入的耗时会明显增加。同样，当需要对这些数据进行模糊查询或是数据分析时，MySQL作为事务型关系数据库很难提供良好的性能支持。使用适合的数据库来实现模糊查询是解决这个问题的关键。</p> 
<p>但是，切换数据库会迎来两个问题，一是已有的服务对现在的 MySQL 重度依赖，二是 MySQL 的事务能力和软件生态仍然不可替代，直接迁移数据库的成本过大。我们综合考虑了下，决定同时使用多个数据库的方案，不同的数据库应用于不同的使用场景。而在支持模糊查询功能的数据库中，elasticsearch 自然是首选的查询数据库。这样后续对业务需求的切换也会非常灵活。</p> 
<p>那具体该如何实现呢？在又拍云以往的项目中，也有遇到相似的问题。之前采用的方法是在业务中编写代码，然后同步到 elasticsearch 中。具体是这样实施的：每个系统编写特定的代码，修改 MySQL 数据库后，再将更新的数据直接推送到需要同步的数据库中，或推送到队列由消费程序来写入到数据库中。</p> 
<p>但这个方案有一些明显的缺点：</p> 
<ul><li> <p>系统高耦合，侵入式代码，使得业务逻辑复杂度增加</p> </li><li> <p>方案不通用，每一套同步都需要额外定制，不仅增加业务处理时间，还会提升软件复复杂度</p> </li><li> <p>工作量和复杂度增加</p> </li></ul> 
<p>在业务中编写同步方案，虽然在项目早期比较方便，但随着数据量和系统的发展壮大，往往最后会成为业务的大痛点。</p> 
<h3 id="解决思路及方案">解决思路及方案</h3> 
<h4 id="调整架构">调整架构</h4> 
<p>既然以往的方案有明显的缺点，那我们如何来解决它呢？优秀的解决方案往往是 “通过架构来解决问题“，那么能不能通过架构的思想来解决问题呢？</p> 
<p>答案是可以的。我们可以将程序伪装成 “从数据库”，主库的增量变化会传递到从库，那这个伪装成 “从数据库” 的程序就能实时获取到数据变化，然后将增量的变化推送到消息队列 MQ，后续消费者消耗 MQ 的数据，然后经过处理之后再推送到各自需要的数据库。</p> 
<p>这个架构的核心是通过监听 MySQL 的 binlog 来同步增量数据，通过基于 query 的查询旧表来同步旧数据，这就是本文要讲的一种异构数据库同步的实践。</p> 
<h4 id="改进数据库">改进数据库</h4> 
<p>经过深度的调研，成功得到了一套异构数据库同步方案，并且成功将公司生产环境下的 robin/logs 的表同步到了 elasticsearch 上。</p> 
<p>首先对 MySQL 开启 binlog，但是由于 maxwell 需要的 binlog_format=row 原本的生产环境的数据库不宜修改。这里请教了海杨前辈，他提供了”从库联级“的思路，在从库中监听 binlog 绕过了操作生产环境重启主库的操作，大大降低了系统风险。</p> 
<p>后续操作比较顺利，启动 maxwell 监听从库变化，然后将增量变化推送到 kafka ，最后配置 logstash 消费 kafka中的数据变化事件信息，将结果推送到 elasticsearch。配置 logstash需要结合表结构，这是整套方案实施的重点。</p> 
<p>这套方案使用到了kafka、maxwell、logstash、elasticsearch。其中 elasticsearch 与 kafka已经在生产环境中有部署，所以无需单独部署维护。而 logstash 与 maxwell 只需要修改配置文件和启动命令即可快速上线。整套方案的意义不仅在于成本低，而且可以大规模使用，公司内有 MySQL 同步到其它数据库的需求时，都可以上任。</p> 
<h4 id="成果展示前后对比">成果展示前后对比</h4> 
<p>使用该方案同步和业务实现同步的对比</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b7/b5/5Lj5wdwQ_o.png"></p> 
<p>写入到 elasticsearch 性能对比 (8核4G内存)</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/06/65/wh1QepA1_o.png"></p> 
<p>经过对比测试，800w 数据量全量同步，使用 logstash 写到 elasticsearch，实际需要大概 3 小时，而旧方案的写入时间需要 2.5 天。</p> 
<h3 id="方案实施细节">方案实施细节</h3> 
<p>接下来，我们来看看具体是如何实现的。</p> 
<p>本方案无需编写额外代码，非侵入式的，实现 MySQL 数据与 elasticsearch 数据库的同步。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/52/68/hxoV7SwE_o.png"></p> 
<p>下列是本次方案需要使用所有的组件：</p> 
<ul><li> <p>MySQL</p> </li><li> <p>Kafka</p> </li><li> <p>Maxwell（监听 binlog）</p> </li><li> <p>Logstash（将数据同步给 elasticsearch）</p> </li><li> <p>Elasticsearch</p> </li></ul> 
<h4 id="1-mysql配置">1. MySQL配置</h4> 
<p><strong>本次使用 MySQL 5.5 作示范，其他版本的配置可能稍许不同需要</strong></p> 
<p>首先我们需要增加一个数据库只读的用户，如果已有的可以跳过。</p> 
<pre><code>-- 创建一个 用户名为 maxwell 密码为 xxxxxx 的用户
CREATE USER 'maxwell'@'%' IDENTIFIED BY 'XXXXXX';
GRANT ALL ON maxwell.* TO 'maxwell'@'localhost';
GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE ON *.* TO 'maxwell'@'%';
</code></pre> 
<p>开启数据库的 <code>binlog</code>，修改 <code>mysql</code> 配置文件，注意 <code>maxwell</code> 需要的 <code>binlog</code> 格式必须是<code>row</code>。</p> 
<pre><code># /etc/mysql/my.cnf

[mysqld]
# maxwell 需要的 binlog 格式必须是 row
binlog_format=row

# 指定 server_id 此配置关系到主从同步需要按情况设置，
# 由于此mysql没有开启主从同步，这边默认设置为 1
server_id=1

# logbin 输出的文件名， 按需配置
log-bin=master
</code></pre> 
<p>重启 MySQL 并查看配置是否生效：</p> 
<pre><code>sudo systemctl restart mysqld
</code></pre> 
<pre><code>select @@log_bin;
-- 正确结果是 1
select @@binlog_format;
-- 正确结果是 ROW
</code></pre> 
<p>如果要监听的数据库开启了主从同步，并且不是主数据库，需要再从数据库开启 binlog 联级同步。</p> 
<pre><code># /etc/my.cnf

log_slave_updates = 1

</code></pre> 
<p>需要被同步到 elasticsearch 的表结构。</p> 
<pre><code>-- robin.logs
show create table robin.logs;

-- 表结构
CREATE TABLE `logs` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `content` text NOT NULL,
  `user_id` int(11) NOT NULL,
  `status` enum('SUCCESS','FAILED','PROCESSING') NOT NULL,
  `type` varchar(20) DEFAULT '',
  `meta` text,
  `created_at` bigint(15) NOT NULL,
  `idx_host` varchar(255) DEFAULT '',
  `idx_domain_id` int(11) unsigned DEFAULT NULL,
  `idx_record_value` varchar(255) DEFAULT '',
  `idx_record_opt` enum('DELETE','ENABLED','DISABLED') DEFAULT NULL,
  `idx_orig_record_value` varchar(255) DEFAULT '',
  PRIMARY KEY (`id`),
  KEY `created_at` (`created_at`)
) ENGINE=InnoDB AUTO_INCREMENT=8170697 DEFAULT CHARSET=utf8
</code></pre> 
<h4 id="2-maxwell-配置">2. Maxwell 配置</h4> 
<p><strong>本次使用 maxwell-1.39.2 作示范, 确保机器中包含 java 环境， 推荐 openjdk11</strong></p> 
<p><strong>下载 maxwell 程序</strong></p> 
<pre><code>wget https://github.com/zendesk/maxwell/releases/download/v1.39.2/maxwell-1.39.2.tar.gz
tar zxvf maxwell-1.39.2.tar.gz **&amp;&amp;**  cd maxwell-1.39.2
</code></pre> 
<p>maxwell 使用了两个数据库：</p> 
<ul><li> <p>一个是需要被监听binlog的数据库(只需要读权限)</p> </li><li> <p>另一个是记录maxwell服务状态的数据库，当前这两个数据库可以是同一个</p> </li></ul> 
<p>重要参数说明：</p> 
<ul><li> <p>host 需要监听binlog的数据库地址</p> </li><li> <p>port 需要监听binlog的数据库端口</p> </li><li> <p>user 需要监听binlog的数据库用户名</p> </li><li> <p>password 需要监听binlog的密码</p> </li><li> <p>replication_host 记录maxwell服务的数据库地址</p> </li><li> <p>replication_port 记录maxwell服务的数据库端口</p> </li><li> <p>replication_user 记录maxwell服务的数据库用户名</p> </li><li> <p>filter 用于监听binlog数据时过滤不需要的数据库数据或指定需要的数据库</p> </li><li> <p>producer 将监听到的增量变化数据提交给的消费者 (如 stdout、kafka)</p> </li><li> <p>kafka.bootstrap.servers kafka 服务地址</p> </li><li> <p>kafka_version kafka 版本</p> </li><li> <p>kafka_topic 推送到kafka的主题</p> </li></ul> 
<p><strong>启动 maxwell</strong></p> 
<p>注意，如果 kafka 配置了禁止自动创建主题，需要先自行在 kafka 上创建主题，kafka_version 需要根据情况指定, 此次使用了两张不同的库</p> 
<pre><code>./bin/maxwell 
        --host=mysql-maxwell.mysql.svc.cluster.fud3 
        --port=3306 
        --user=root 
        --password=password 
        --replication_host=192.168.5.38 
        --replication_port=3306 
        --replication_user=cloner 
        --replication_password=password
        --filter='exclude: *.*, include: robin.logs' 
        --producer=kafka 
        --kafka.bootstrap.servers=192.168.30.10:9092 
        --kafka_topic=maxwell-robinlogs --kafka_version=0.9.0.1
</code></pre> 
<h4 id="3-安装-logstash">3. 安装 Logstash</h4> 
<p>Logstash 包中已经包含了 openjdk，无需额外安装。</p> 
<pre><code>wget https://artifacts.elastic.co/downloads/logstash/logstash-8.5.0-linux-x86_64.tar.gz
tar zxvf logstash-8.5.0-linux-x86_64.tar.gz
</code></pre> 
<p>删除不需要的配置文件。</p> 
<pre><code>rm config/logstash.yml
</code></pre> 
<p>修改 logstash 配置文件，此处语法参考官方文档（<a href="https://www.elastic.co/guide/en/logstash/current/input-plugins.html%EF%BC%89" rel="nofollow" title="https://www.elastic.co/guide/en/logstash/current/input-plugins.html）">https://www.elastic.co/guide/en/logstash/current/input-plugins.html）</a> 。</p> 
<pre><code># config/logstash-sample.conf

input {
 kafka {
    bootstrap_servers =&gt; "192.168.30.10:9092"
    group_id =&gt; "main"
    topics =&gt; ["maxwell-robinlogs"]
 }
}

filter {
  json {
    source =&gt; "message"
  }

  # 将maxwell的事件类型转化为es的事件类型
  # 如增加 -&gt; index 修改-&gt; update
  translate {
    source =&gt; "[type]"
    target =&gt; "[action]"
    dictionary =&gt; {
      "insert" =&gt; "index"
      "bootstrap-insert" =&gt; "index"
      "update" =&gt; "update"
      "delete" =&gt; "delete"
    }
    fallback =&gt; "unknown"
  }

  # 过滤无效的数据
  if ([action] == "unknown") {
    drop {}
  }

  # 处理数据格式
  if [data][idx_host] {
    mutate {
      add_field =&gt; { "idx_host" =&gt; "%{[data][idx_host]}" }
    }
  } else {
    mutate {
      add_field =&gt; { "idx_host" =&gt; "" }
    }
  }

  if [data][idx_domain_id] {
    mutate {
      add_field =&gt; { "idx_domain_id" =&gt; "%{[data][idx_domain_id]}" }
    }
  } else {
    mutate {
      add_field =&gt; { "idx_domain_id" =&gt; "" }
    }
  }

  if [data][idx_record_value] {
    mutate {
      add_field =&gt; { "idx_record_value" =&gt; "%{[data][idx_record_value]}" }
    }
  } else {
    mutate {
      add_field =&gt; { "idx_record_value" =&gt; "" }
    }
  }
  
   if [data][idx_record_opt] {
    mutate {
      add_field =&gt; { "idx_record_opt" =&gt; "%{[data][idx_record_opt]}" }
    }
  } else {
    mutate {
      add_field =&gt; { "idx_record_opt" =&gt; "" }
    }
  }
 
  if [data][idx_orig_record_value] {
    mutate {
      add_field =&gt; { "idx_orig_record_value" =&gt; "%{[data][idx_orig_record_value]}" }
    }
  } else {
    mutate {
      add_field =&gt; { "idx_orig_record_value" =&gt; "" }
    }
  }
 
  if [data][type] {
    mutate {
      replace =&gt; { "type" =&gt; "%{[data][type]}" }
    }
  } else {
    mutate {
      replace =&gt; { "type" =&gt; "" }
    }
  }
 
  mutate {
    add_field =&gt; {
      "id" =&gt; "%{[data][id]}"
      "content" =&gt; "%{[data][content]}"
      "user_id" =&gt; "%{[data][user_id]}"
      "status" =&gt; "%{[data][status]}"
      "meta" =&gt; "%{[data][meta]}"
      "created_at" =&gt; "%{[data][created_at]}"
    }
    remove_field =&gt; ["data"]
  }

  mutate {
    convert =&gt; {
      "id" =&gt; "integer"
      "user_id" =&gt; "integer"
      "idx_domain_id" =&gt; "integer"
      "created_at" =&gt; "integer"
    }
  }

  # 只提炼需要的字段
  mutate {
    remove_field =&gt; [
      "message",
      "original",
      "@version",
      "@timestamp",
      "event",
      "database",
      "table",
      "ts",
      "xid",
      "commit",
      "tags"
    ]
   }
}

output {
  # 结果写到es
  elasticsearch {
    hosts =&gt; ["http://es-zico2.service.upyun:9500"]
    index =&gt; "robin_logs"
    action =&gt; "%{action}"
    document_id =&gt; "%{id}"
    document_type =&gt; "robin_logs"
  }

  # 结果打印到标准输出
  stdout {
    codec =&gt; rubydebug
  }
}
</code></pre> 
<p>执行程序：</p> 
<pre><code># 测试配置文件*
bin/logstash -f config/logstash-sample.conf --config.test_and_exit

# 启动*
bin/logstash -f config/logstash-sample.conf --config.reload.automatic
</code></pre> 
<h4 id="4-全量同步">4. 全量同步</h4> 
<p>完成启动后，后续的增量数据 maxwell 会自动推送给 logstash 最终推送到 elasticsearch ，而之前的旧数据可以通过 maxwell 的 bootstrap 来同步，往下面表中插入一条任务，那么 maxwell 会自动将所有符合条件的 where_clause 的数据推送更新。</p> 
<pre><code>INSERT INTO maxwell.bootstrap 
        ( database_name, table_name, where_clause, client_id ) 
values 
        ( 'robin', 'logs', 'id &gt; 1', 'maxwell' );
</code></pre> 
<p>SQL 复制 全屏</p> 
<p>后续可以在 elasticsearch 检测数据是否同步完成，可以先查看数量是否一致，然后抽样对比详细数据。</p> 
<pre><code># 检测 elasticsearch  中的数据量
GET robin_logs/robin_logs/_count
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1d0811fc7babf03a86ea64d2e2b90e20/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">如何使用Python内置缓存装饰器: @lru_cache，@cache 与 @cached_property</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5390d454d8a1b45a5e2c9a3361732cf2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">c&#43;&#43;分布式网络通信框架【万字拆解】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>