<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python】Pandas通过索引的方式去重df[~df.index.duplicated()] - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python】Pandas通过索引的方式去重df[~df.index.duplicated()]" />
<meta property="og:description" content="1.问题
在处理股票数据的时候，难免遇到去重的问题。对于以下数据，显然2020-01-04的数据重复了。
股票数据中，通常用date当成索引，一行数据的date应该都是唯一的。
import pandas as pd data = pd.DataFrame({&#39;date&#39;: [&#39;2020-01-04&#39;, &#39;2020-01-04&#39;, &#39;2020-01-05&#39;, &#39;2020-01-06&#39;], &#39;open&#39;: [102, 102,102, 105], &#39;close&#39;: [102, 102,102, 105]}).set_index(&#39;date&#39;) print(data) open close date 2020-01-04 102 102 2020-01-04 102 102 2020-01-05 102 102 2020-01-06 105 105 数据中2020-01-05的open和close与2020-01-04的是一样的，但date又不一样，因此这里不需要对2020-01-05的数据做去重处理的，只需要对2020-01-04的两条数据去重。
如果利用常规的去重方法 df.drop_duplicates()，就会遇到以下问题：
a = data print(a.drop_duplicates()) open close date 2020-01-04 102 102 2020-01-06 105 105 返回的结果相当于把2020-01-05也当重复项做去重处理了。也就是使用 df.drop_duplicates() 方法，是针对于列做去重处理。因为2020-01-05的open和close与2020-01-04的是一样，所以前3条数据被当成重复性处理，就保留了重复数据中的第一条。然而这个结果并不是我们想要的。
正确是做法是对索引去重。
2.解决方法
对索引去重，也只需要用一行代码：df[~df.index.duplicated()]
print(data[~data.index.duplicated()]) open close date 2020-01-04 102 102 2020-01-05 102 102 2020-01-06 105 105 这样的结果才是我们想要的。~df." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/812d0b163cb582791f5b9c95b4e8f0a5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-06T17:07:52+08:00" />
<meta property="article:modified_time" content="2022-12-06T17:07:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python】Pandas通过索引的方式去重df[~df.index.duplicated()]</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>1.问题</strong></p> 
<p>在处理股票数据的时候，难免遇到去重的问题。对于以下数据，显然2020-01-04的数据重复了。<br> 股票数据中，通常用date当成索引，一行数据的date应该都是唯一的。</p> 
<pre><code class="language-python">import pandas as pd

data = pd.DataFrame({'date': ['2020-01-04', '2020-01-04', '2020-01-05', '2020-01-06'], 'open': [102, 102,102, 105], 'close': [102, 102,102, 105]}).set_index('date')
print(data)</code></pre> 
<pre><code class="language-python">            open  close
date                   
2020-01-04   102    102
2020-01-04   102    102
2020-01-05   102    102
2020-01-06   105    105</code></pre> 
<p>数据中2020-01-05的open和close与2020-01-04的是一样的，但date又不一样，因此这里不需要对2020-01-05的数据做去重处理的，只需要对2020-01-04的两条数据去重。</p> 
<p>如果利用常规的去重方法 <strong>df.drop_duplicates()，</strong>就会遇到以下问题：</p> 
<pre><code class="language-python">a = data
print(a.drop_duplicates())</code></pre> 
<pre><code class="language-python">            open  close
date                   
2020-01-04   102    102
2020-01-06   105    105</code></pre> 
<p>返回的结果相当于把2020-01-05也当重复项做去重处理了。也就是使用 <strong>df.drop_duplicates() 方法，是针对于列做去重处理。</strong>因为2020-01-05的open和close与2020-01-04的是一样，所以前3条数据被当成重复性处理，就保留了重复数据中的第一条。然而这个结果并不是我们想要的。</p> 
<p><strong>正确是做法是对索引去重。</strong></p> 
<p></p> 
<p><strong>2.解决方法</strong></p> 
<p><strong>对索引去重，也只需要用一行代码：df[~df.index.duplicated()]</strong></p> 
<pre><code class="language-python">print(data[~data.index.duplicated()])</code></pre> 
<pre><code class="language-python">            open  close
date                   
2020-01-04   102    102
2020-01-05   102    102
2020-01-06   105    105</code></pre> 
<p>这样的结果才是我们想要的。<strong>~df.index.duplicated()</strong> 方法是只针对索引做去重，而不考虑列数据，与 <strong>df.drop_duplicates() </strong>相反。</p> 
<p></p> 
<p><strong>3.完整代码</strong></p> 
<pre><code class="language-python">import pandas as pd

data = pd.DataFrame(
    {'date': ['2020-01-04', '2020-01-04', '2020-01-05', '2020-01-06'], 'open': [102, 102,102, 105], 'close': [102, 102,102, 105]}).set_index(
    'date')
print(data)

a = data
print('去重--只匹配列，不匹配索引')
print(a.drop_duplicates())

print('去重--只匹配索引，不匹配列')
print(data[~data.index.duplicated()])</code></pre> 
<pre><code class="language-python">E:\Python\Python38-32\python.exe E:/python_project/test.py
            open  close
date                   
2020-01-04   102    102
2020-01-04   102    102
2020-01-05   102    102
2020-01-06   105    105
去重--只匹配列，不匹配索引
            open  close
date                   
2020-01-04   102    102
2020-01-06   105    105
去重--只匹配索引
            open  close
date                   
2020-01-04   102    102
2020-01-05   102    102
2020-01-06   105    105

Process finished with exit code 0</code></pre> 
<p><br>  </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4fe91c861adb76d9c061b33293bbcc97/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">qml踩坑系列——Scrollview和mouseArea冲突</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/eb3cb45fcc8c250359116b4ba21dd6c3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">树莓派 4 B 拨动开关控制风扇 Rasberry Pi 4 B Add Toggle Switch for the Fan</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>