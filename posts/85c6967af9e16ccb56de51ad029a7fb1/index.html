<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python量化交易学习笔记（42）——深度学习挖短线股2 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python量化交易学习笔记（42）——深度学习挖短线股2" />
<meta property="og:description" content="上篇文章介绍了深度学习挖短线股的数据预处理部分，本文将介绍模型训练的内容。
模型训练 模型训练过程主要参考Keras的官方示例Structured data classification from scratch(https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)，该示例展示了对结构化的数据进行分类，分别处理了特征为字符串、整形、浮点型的数据。对于当前我们所选用的股票训练特征而言，我们只需要处理浮点型特征。
首先，判断预处理后的数据是否存在，如果存在则直接读入，否则进行预处理计算：
for stk_code in stk_list: print(&#39;processing {}...&#39;.format(stk_code)) # 判断是否已经经过预处理（文件是否存在） data_file = &#39;./baostock/data_pre/{}.csv&#39;.format(stk_code) if os.path.exists(data_file): df = pd.read_csv(data_file) else: df = pd.read_csv(&#39;./baostock/data_ext/{}.csv&#39;.format(stk_code)) df = df[df[&#39;date&#39;] &lt;= &#39;2017-12-31&#39;] df = data_preprocessing(df, stk_code, FEATURE_N) 然后，依次获取特征的维度，分割训练集及验证集，将数据转为Dataset，并设置batch的大小。
# 特征维度 ft_num = df.shape[1] - 1 # 分割训练集与验证集 val_df = df.sample(frac=0.2, random_state=1337) train_df = df.drop(val_df.index) print( &#34;Using %d samples for training and %d for validation&#34; % (len(train_df), len(val_df)) ) # 生成tf." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/85c6967af9e16ccb56de51ad029a7fb1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-04T16:08:58+08:00" />
<meta property="article:modified_time" content="2023-10-04T16:08:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python量化交易学习笔记（42）——深度学习挖短线股2</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>上篇文章介绍了深度学习挖短线股的数据预处理部分，本文将介绍模型训练的内容。</p> 
<h4><a id="_1"></a>模型训练</h4> 
<p>模型训练过程主要参考Keras的官方示例Structured data classification from scratch(https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)，该示例展示了对结构化的数据进行分类，分别处理了特征为字符串、整形、浮点型的数据。对于当前我们所选用的股票训练特征而言，我们只需要处理浮点型特征。</p> 
<p>首先，判断预处理后的数据是否存在，如果存在则直接读入，否则进行预处理计算：</p> 
<pre><code class="prism language-python"><span class="token keyword">for</span> stk_code <span class="token keyword">in</span> stk_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'processing {}...'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 判断是否已经经过预处理（文件是否存在）</span>
    data_file <span class="token operator">=</span> <span class="token string">'./baostock/data_pre/{}.csv'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span>
    <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
        df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./baostock/data_ext/{}.csv'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">)</span>
        df <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'date'</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> <span class="token string">'2017-12-31'</span><span class="token punctuation">]</span>
        df <span class="token operator">=</span> data_preprocessing<span class="token punctuation">(</span>df<span class="token punctuation">,</span> stk_code<span class="token punctuation">,</span> FEATURE_N<span class="token punctuation">)</span>
</code></pre> 
<p>然后，依次获取特征的维度，分割训练集及验证集，将数据转为Dataset，并设置batch的大小。</p> 
<pre><code class="prism language-python">    <span class="token comment"># 特征维度</span>
    ft_num <span class="token operator">=</span> df<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>
    <span class="token comment"># 分割训练集与验证集</span>
    val_df <span class="token operator">=</span> df<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1337</span><span class="token punctuation">)</span>
    train_df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>val_df<span class="token punctuation">.</span>index<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"Using %d samples for training and %d for validation"</span>
        <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>val_df<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 生成tf.data.Dataset</span>
    train_ds <span class="token operator">=</span> dataframe_to_dataset<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span>
    val_ds <span class="token operator">=</span> dataframe_to_dataset<span class="token punctuation">(</span>val_df<span class="token punctuation">)</span>
    <span class="token comment"># 打包</span>
    train_ds <span class="token operator">=</span> train_ds<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
    val_ds <span class="token operator">=</span> val_ds<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
</code></pre> 
<p>在经过数据预处理后，我们得到的特征数据为220维（每日特征22维*10日），这些特征数据均为浮点型，参考Keras官方示例，我们调用方法encode_numerical_feature，将数据正则化为均值为0，标准差为1。</p> 
<pre><code class="prism language-python"><span class="token comment"># 浮点型特征数据正则化</span>
<span class="token keyword">def</span> <span class="token function">encode_numerical_feature</span><span class="token punctuation">(</span>feature<span class="token punctuation">,</span> name<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Create a Normalization layer for our feature</span>
    normalizer <span class="token operator">=</span> Normalization<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># Prepare a Dataset that only yields our feature</span>
    feature_ds <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> x<span class="token punctuation">[</span>name<span class="token punctuation">]</span><span class="token punctuation">)</span>
    feature_ds <span class="token operator">=</span> feature_ds<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># Learn the statistics of the data</span>
    normalizer<span class="token punctuation">.</span>adapt<span class="token punctuation">(</span>feature_ds<span class="token punctuation">)</span>
    <span class="token comment"># Normalize the input feature</span>
    encoded_feature <span class="token operator">=</span> normalizer<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>
    <span class="token keyword">return</span> encoded_feature
</code></pre> 
<pre><code class="prism language-python">    <span class="token comment"># 特征处理</span>
    all_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    ft_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>ft_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        name <span class="token operator">=</span> <span class="token string">'{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
        ki <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name<span class="token punctuation">)</span>
        all_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ki<span class="token punctuation">)</span>
        ft_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>encode_numerical_feature<span class="token punctuation">(</span>ki<span class="token punctuation">,</span> name<span class="token punctuation">,</span> train_ds<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>接着，我们对每只股票创建模型并进行训练，将训练的结果保存到本地。这里使用了最简单的全链接模型，各层节点均较少，以节省计算时间。即便使用了简单的模型，对2600多只股票进行训练，也花费2天多的时间。训练得到的每个模型大小约5MB。代码如下：</p> 
<pre><code class="prism language-python">    <span class="token comment"># 创建模型</span>
    all_features <span class="token operator">=</span> layers<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>ft_list<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>all_features<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    output <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>all_inputs<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">"adam"</span><span class="token punctuation">,</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 训练模型</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span>val_ds<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'./model/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>最后，需要且一定要做的工作是，清理每次循环内Keras训练单只股票模型所占用的内存。如果不添加下面这行代码的话，随着训练的进行，程序会把内存刷爆，导致程序崩溃。</p> 
<pre><code class="prism language-python">    <span class="token comment"># 清理内存</span>
    backend<span class="token punctuation">.</span>clear_session<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>以上就完成了使用Keras对股票进行训练的过程，完整代码见文末。后续将继续介绍使用训练得到的模型做预测以及进行量化回测的过程。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> os
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> layers
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> Normalization
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> CategoryEncoding
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StringLookup
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> backend

FEATURE_N <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># 浮点型特征数据正则化</span>
<span class="token keyword">def</span> <span class="token function">encode_numerical_feature</span><span class="token punctuation">(</span>feature<span class="token punctuation">,</span> name<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Create a Normalization layer for our feature</span>
    normalizer <span class="token operator">=</span> Normalization<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># Prepare a Dataset that only yields our feature</span>
    feature_ds <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> x<span class="token punctuation">[</span>name<span class="token punctuation">]</span><span class="token punctuation">)</span>
    feature_ds <span class="token operator">=</span> feature_ds<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># Learn the statistics of the data</span>
    normalizer<span class="token punctuation">.</span>adapt<span class="token punctuation">(</span>feature_ds<span class="token punctuation">)</span>
    <span class="token comment"># Normalize the input feature</span>
    encoded_feature <span class="token operator">=</span> normalizer<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>
    <span class="token keyword">return</span> encoded_feature

<span class="token comment"># 预处理，将n行数据作为输入特征</span>
<span class="token keyword">def</span> <span class="token function">data_preprocessing</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> stk_code<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    df <span class="token operator">=</span> df<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 删除无效数据列，保留特征数据</span>
    ft_df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'date'</span><span class="token punctuation">,</span> <span class="token string">'buy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 返回值</span>
    out_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 生成新特征数据</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> df<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 取n行数据</span>
        part_df <span class="token operator">=</span> ft_df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i <span class="token operator">-</span> n <span class="token punctuation">:</span> i<span class="token punctuation">]</span>
        <span class="token comment"># 将n行合并为一行</span>
        new_ft_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>part_df<span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        out_df <span class="token operator">=</span> out_df<span class="token punctuation">.</span>append<span class="token punctuation">(</span>new_ft_df<span class="token punctuation">)</span>
    out_df<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>n<span class="token punctuation">:</span>df<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'buy'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
    out_df <span class="token operator">=</span> out_df<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    out_df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'./baostock/data_pre/{}.csv'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">,</span> index <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> out_df

<span class="token keyword">def</span> <span class="token function">dataframe_to_dataset</span><span class="token punctuation">(</span>dataframe<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dataframe <span class="token operator">=</span> dataframe<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> dataframe<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"target"</span><span class="token punctuation">)</span>
    ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>Dataset<span class="token punctuation">.</span>from_tensor_slices<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>dataframe<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
    ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataframe<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> ds

stk_code_file <span class="token operator">=</span> <span class="token string">'./stk_data/dp_stock_list.csv'</span>
stk_list <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>stk_code_file<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'code'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
start_tag <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token keyword">for</span> stk_code <span class="token keyword">in</span> stk_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'processing {}...'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 判断是否已经经过预处理（文件是否存在）</span>
    data_file <span class="token operator">=</span> <span class="token string">'./baostock/data_pre/{}.csv'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span>
    <span class="token keyword">if</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
        df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./baostock/data_ext/{}.csv'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">)</span>
        df <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'date'</span><span class="token punctuation">]</span> <span class="token operator">&lt;=</span> <span class="token string">'2017-12-31'</span><span class="token punctuation">]</span>
        df <span class="token operator">=</span> data_preprocessing<span class="token punctuation">(</span>df<span class="token punctuation">,</span> stk_code<span class="token punctuation">,</span> FEATURE_N<span class="token punctuation">)</span>
    <span class="token comment"># 特征维度</span>
    ft_num <span class="token operator">=</span> df<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>
    <span class="token comment"># 分割训练集与验证集</span>
    val_df <span class="token operator">=</span> df<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1337</span><span class="token punctuation">)</span>
    train_df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>val_df<span class="token punctuation">.</span>index<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"Using %d samples for training and %d for validation"</span>
        <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_df<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>val_df<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 生成tf.data.Dataset</span>
    train_ds <span class="token operator">=</span> dataframe_to_dataset<span class="token punctuation">(</span>train_df<span class="token punctuation">)</span>
    val_ds <span class="token operator">=</span> dataframe_to_dataset<span class="token punctuation">(</span>val_df<span class="token punctuation">)</span>
    <span class="token comment"># 打包</span>
    train_ds <span class="token operator">=</span> train_ds<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
    val_ds <span class="token operator">=</span> val_ds<span class="token punctuation">.</span>batch<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span>
    <span class="token comment"># 特征处理</span>
    all_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    ft_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>ft_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        name <span class="token operator">=</span> <span class="token string">'{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
        ki <span class="token operator">=</span> keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name<span class="token punctuation">)</span>
        all_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ki<span class="token punctuation">)</span>
        ft_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>encode_numerical_feature<span class="token punctuation">(</span>ki<span class="token punctuation">,</span> name<span class="token punctuation">,</span> train_ds<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 创建模型</span>
    all_features <span class="token operator">=</span> layers<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>ft_list<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>all_features<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    output <span class="token operator">=</span> layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    model <span class="token operator">=</span> keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>all_inputs<span class="token punctuation">,</span> output<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">"adam"</span><span class="token punctuation">,</span> <span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 训练模型</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span>val_ds<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'./model/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>stk_code<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 清理内存</span>
    backend<span class="token punctuation">.</span>clear_session<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<hr> 
<p><strong>博客内容只用于交流学习，不构成投资建议，盈亏自负！</strong></p> 
<p>个人博客：http://coderx.com.cn/（优先更新）<br> 项目最新代码：https://gitee.com/sl/quant_from_scratch<br> 欢迎大家转发、留言。有微信群用于学习交流，感兴趣的读者请扫码加微信！<br> 如果认为博客对您有帮助，可以扫码进行捐赠，感谢！</p> 
<table><thead><tr><th align="center">微信二维码</th><th align="center">微信捐赠二维码</th></tr></thead><tbody><tr><td align="center"></td><td align="center"></td></tr><tr><td align="center"><img src="https://images2.imgbox.com/31/40/KKORQ2yk_o.png" alt="在这里插入图片描述"></td><td align="center"><img src="https://images2.imgbox.com/38/43/UZo0Ieun_o.png" alt="在这里插入图片描述"></td></tr></tbody></table>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5e0ab3d328b790e2fdf80a1c099940dd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">每日筛取候选股票——从零到实盘14</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6bff6162139ebb89e7146e15d2b4d0fc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python量化交易学习笔记（40）——backtrader的resample浅析</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>