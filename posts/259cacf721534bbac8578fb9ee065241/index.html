<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习-基于机器学习的情绪分析研究 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习-基于机器学习的情绪分析研究" />
<meta property="og:description" content="概要 互联网技术的迅速发展使得社交平台逐渐成为热点事件中社会情感的枢纽。社会热点事件的舆论监管的其中一个重要环节就是能够准确分析民众的社会情绪。本文旨在探索可以基于文本大数据彻底分析民众对热点事件的社会情绪的模型和方法。先是从社交平台上借助文本大数据、对数据进行提前处理以及用python自然语言处理包等方法建立能够分析社会情绪的模型，其次找到最佳的机器学习算法，再次用机器学习的方法对模型进行训练，获得一个情感分类器。最后用热点事件“冠状病毒”的真实数据在情感分类器上进行社会情绪分析验证,证明了模型和方法的有效性。
关键词：网络文本大数据；机器学习；情绪分类器；社会情绪分析；
一、研究背景与意义 1.1设计目的及意义 近来，社交媒体和电子商务平台发展迅速,Twitter、微博、MSN、微信等社交网络正逐渐地改变着人们的生活,越来越多的人习惯于通过网络平台表达自己的态度和情感,这些网络文本是客户流露的真实情感。对网络文本大数据热门事件的情绪进行分析可以使人们获得更多关于内心世界的知识，因此,从这些文本信息中自动准确的识别客户的情感类别,对政府舆情监控、企业管理与决策来说是一个很大的支持,它也成为学术界近来持续关注的研究热点，同时极大地促进了情绪分析技术的发展。
1.2本课题国内外现状及存在问题 文本情感分析也可以说是挖掘文本意见的方法。简而言之，它是分析，处理，总结和推断具有情感色彩的主观文本的过程[1]。目前海内外关于文本情绪分析研究的方向主要有两个：一个是判断主观信息的细粒度，另一个是判断文本的主客观性。前者强调将情感词作为中心去分析文本级的情绪倾向，而文本的情绪倾向是通过贬值情感词的线性加权值来实现的。熊德兰等人[2]基于How Net语义词典中词汇语义相似度的计算方法。意在基于语义词典，充分想到词语组成在一起之后语义可能改变，直接影响到情感褒贬判断的偏向结果，于是用各个词语义进行权重计算结果来判断从而避免受影响。该方式基于语义词集，能很精确地预测情感倾向，但缺点是操作起来复杂且在很大程度上取决于词汇层次分类算法的精确度。则此方法显然对大量的文本数据处理是不合适。为了处理大量数据，研究人员介绍了用于情感分析的机器学习方法，例如K最近邻，最大熵模型，朴素贝叶斯和支持向量机（SVM）方法[3]。
虽 然以语义词集为基础的语义加权分类效果比机器学习方法较好，但胜在后者能够更轻易地去分析处理大量的文本数据。例如徐军等人[4]利用机器学习方法对新闻评论进行情感分类，在最理想的数据集上分类准确率可以达到90%，然而这种方法缺乏语义分析，容易产生向量空间模型数据稀疏问题，对于中文文本处理中普遍存在的一词多义和多词一义问题也不能解决。闻彬等人[5]在情感词识别中引人情感语义概念，基于语义理解来进行文本情感分类，可在一定程度上缓解一词多义和多词一义引起的分类准确率不高的问题，它的不足之处在于只考虑到词语语义层副词的出现规律对词语语义的作用，忽略了整个文本语境对词语语义的影响。一些研究者[6]通过已有文本规则，充分考虑用文本的语法结构去预测文本情绪倾向。但是不得不说该方式的实用性差、工艺复杂且难以推广。也有部分研究者尝试借助非标注样本不断训练分类器的方法来提高半监督学习方法的情感分类准确率，实验证明该方法是有效的[7]。还有谢丽星等[8]提出了一种基于SVM的层次结构多策略中文微博情感分析方法；刘宝芹等[9]在将情绪类别组织成三层树状结构后，采用朴素贝叶斯分类模型对中文微博进行多层次的情绪分析；欧阳纯萍等[10]提出多策略中文微博细粒度情绪分析方法，采用 SVM和KNN算法对微博进行细粒度情绪分析；雷龙艳等[11]在对微博进行文本特征表示的基础上，采用SVN和KNN算法对微博进行细粒度情绪分析。等等这些国内外的文本情感分类方法研究，对本设计的方法选择与优化都提供了一定的帮助。
二、设计过程 2.1设计简要流程 图2.1-1_设计简要流程图
2.2文本数据获取 2.2.1创建APP 首先通过已有的twitter账号访问推特官方网站，想要抓取数据就要创建app去访问twitter的API。创建app时，必要填写信息为“name，Description，website”，其中name为APP的名称；description是对自己APP的描述；website自己有网站写自己的网站，没有就写一个符合格式的网站就行。并不需要进一步的验证，app中的Access Token、Access 、Token Secret Consumer Key(API Key)和Consumer Secret(API Secret)这四个开发者身份认证令牌参数才是我们的目标，也是获取数据的基本条件。如果需要获取大量数据，可以申请多个app,因为单个的爬取次数和数量均有限制。
2.2.2调配使用API 之所以选择Twitter作为实战的文本数据是因为它提供很多类型的API，其中Rest API 与Streaming API是最为常见的。前者是经常被用到的类型，而Streaming API可以用于追踪想要了解的用户或事件。下面介绍一下REST API中有爬取意义的几个API：
(1)GET statuses/user timeline：返回一个用户发的推文。注意twitter里回复也相当于发推文。
(2)GET friends/ids：返回一个用户的followees。
(3)GET followers/ids：返回一个用户的followers。
(4)GET users/show：返回一个用户的信息。
接下来，通过使用twitter api进行数据抓取，目前的twitter api有很多python语言版本，本设计将会用到的是tweepy。安装tweepy库，只需要在cmd中输入pip install tweepy命令即可。
2.2.3开始程序编辑 Twitter平台不仅给以了我们爬取数据所用到的API接口，并且还携带了供我们写程序代码参考所用到的Tweepy库。最后将获取到的数据将保存到csv格式文件中，获取文本数据程序代码如下：
三、数据预处理 2.3.1句柄的删除 句柄(@user)携带是每个推特用户得以批准的一种方式，所以tweets文本数据中有的大量twitter句柄。而这个句柄其实没有什么信息含量，因此我们删除所有这些twitter句柄。为了省去不必要的麻烦，最好将测试集跟训练集都一齐处理掉。
说到删除tweet中用不到的文本模式，首先我们需要定义一个函数，输入两个参数，一个是文本原始字符串，另一个是字符串中我们想要删除的文本模式。用该函数进行“@user”模式的删除。最后，创建一个新的列名为processed_tweet，用于存放经过清理和处理的tweet。程序代码如下：
2.3.2删除标点、数字和特殊字符 标点符号、数字和特殊字符对一般的文本处理没什么帮助。就像twitter句柄一样需要从文本中删除掉它们，用空格替换除字符和标签的全部内容。处理程序代码如下：
2.3.3处理表情符号 将表情符号转化为情绪表达，分别为Positive和negative。可以更加直观的判断文本的情绪倾向，转化代码如下：
2.3.4词干提取 由于英文表达中的单词大多带有后缀，如(“ing”、“ly”、“er”、“es”、“s”等)对单词没有情绪改变的后缀。举个例子，“fly”、“flyer”、“flying”,其中“flyer”和“flying”是单词“fly”的不同变体。我们需要从一个单词中剥离后缀，提取出对情绪分类有用的词干信息，提取程序代码如下：
2.4标注类标签 在经过预处理后的的数据，分别划分为训练以及测试文本集，训练集的数额要远大于测试集的数额。本设计总获取约一百万个文本数据，其中测试集数量约为百分之九十，然后按照文本的情感表达给它们分类为消极negative（标注为0）和积极Positive（标注为1）的标签，测试集用于后续的验证，不需要标注。标注后的效果图如下：
图2.4-1_类标注效果图
2.5分词 由于在特征提取前，需要并将这些词用作向量来表示文本，即将所有训练文档进行分词。举个例子：在情感分类问题中，选择特征可以基于“词”这个层次，例如“This tweet is excellent”，我给他标注成“Positive”的类标签。里面有4个词,分别为“This”、“tweet”、“is”、“excellent”。意思是将这4个词全部作为了分类特征词，那么包含这个词的文本就会被分类为“积极”。同理，对上面提及的那句文本，还能选择双词组合（Bigrams）。这种方法就是将“This tweet”，“tweet is”，“is excellent”这种两两搭配作为分类特征。本设计将用到这两种特征选择作为分词方式进行选择，分词程序代码如下：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/259cacf721534bbac8578fb9ee065241/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-16T23:40:33+08:00" />
<meta property="article:modified_time" content="2024-03-16T23:40:33+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习-基于机器学习的情绪分析研究</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_1"></a>概要</h3> 
<p>  互联网技术的迅速发展使得社交平台逐渐成为热点事件中社会情感的枢纽。社会热点事件的舆论监管的其中一个重要环节就是能够准确分析民众的社会情绪。本文旨在探索可以基于文本大数据彻底分析民众对热点事件的社会情绪的模型和方法。先是从社交平台上借助文本大数据、对数据进行提前处理以及用python自然语言处理包等方法建立能够分析社会情绪的模型，其次找到最佳的机器学习算法，再次用机器学习的方法对模型进行训练，获得一个情感分类器。最后用热点事件“冠状病毒”的真实数据在情感分类器上进行社会情绪分析验证,证明了模型和方法的有效性。</p> 
<p>关键词：网络文本大数据；机器学习；情绪分类器；社会情绪分析；</p> 
<h2><a id="_7"></a>一、研究背景与意义</h2> 
<h3><a id="11_8"></a>1.1设计目的及意义</h3> 
<p>  近来，社交媒体和电子商务平台发展迅速,Twitter、微博、MSN、微信等社交网络正逐渐地改变着人们的生活,越来越多的人习惯于通过网络平台表达自己的态度和情感,这些网络文本是客户流露的真实情感。对网络文本大数据热门事件的情绪进行分析可以使人们获得更多关于内心世界的知识，因此,从这些文本信息中自动准确的识别客户的情感类别,对政府舆情监控、企业管理与决策来说是一个很大的支持,它也成为学术界近来持续关注的研究热点，同时极大地促进了情绪分析技术的发展。</p> 
<h3><a id="12_12"></a>1.2本课题国内外现状及存在问题</h3> 
<p>  文本情感分析也可以说是挖掘文本意见的方法。简而言之，它是分析，处理，总结和推断具有情感色彩的主观文本的过程[1]。目前海内外关于文本情绪分析研究的方向主要有两个：一个是判断主观信息的细粒度，另一个是判断文本的主客观性。前者强调将情感词作为中心去分析文本级的情绪倾向，而文本的情绪倾向是通过贬值情感词的线性加权值来实现的。熊德兰等人[2]基于How Net语义词典中词汇语义相似度的计算方法。意在基于语义词典，充分想到词语组成在一起之后语义可能改变，直接影响到情感褒贬判断的偏向结果，于是用各个词语义进行权重计算结果来判断从而避免受影响。该方式基于语义词集，能很精确地预测情感倾向，但缺点是操作起来复杂且在很大程度上取决于词汇层次分类算法的精确度。则此方法显然对大量的文本数据处理是不合适。为了处理大量数据，研究人员介绍了用于情感分析的机器学习方法，例如K最近邻，最大熵模型，朴素贝叶斯和支持向量机（SVM）方法[3]。<br> 虽  然以语义词集为基础的语义加权分类效果比机器学习方法较好，但胜在后者能够更轻易地去分析处理大量的文本数据。例如徐军等人[4]利用机器学习方法对新闻评论进行情感分类，在最理想的数据集上分类准确率可以达到90%，然而这种方法缺乏语义分析，容易产生向量空间模型数据稀疏问题，对于中文文本处理中普遍存在的一词多义和多词一义问题也不能解决。闻彬等人[5]在情感词识别中引人情感语义概念，基于语义理解来进行文本情感分类，可在一定程度上缓解一词多义和多词一义引起的分类准确率不高的问题，它的不足之处在于只考虑到词语语义层副词的出现规律对词语语义的作用，忽略了整个文本语境对词语语义的影响。一些研究者[6]通过已有文本规则，充分考虑用文本的语法结构去预测文本情绪倾向。但是不得不说该方式的实用性差、工艺复杂且难以推广。也有部分研究者尝试借助非标注样本不断训练分类器的方法来提高半监督学习方法的情感分类准确率，实验证明该方法是有效的[7]。还有谢丽星等[8]提出了一种基于SVM的层次结构多策略中文微博情感分析方法；刘宝芹等[9]在将情绪类别组织成三层树状结构后，采用朴素贝叶斯分类模型对中文微博进行多层次的情绪分析；欧阳纯萍等[10]提出多策略中文微博细粒度情绪分析方法，采用 SVM和KNN算法对微博进行细粒度情绪分析；雷龙艳等[11]在对微博进行文本特征表示的基础上，采用SVN和KNN算法对微博进行细粒度情绪分析。等等这些国内外的文本情感分类方法研究，对本设计的方法选择与优化都提供了一定的帮助。</p> 
<h2><a id="_18"></a>二、设计过程</h2> 
<h3><a id="21_20"></a>2.1设计简要流程</h3> 
<p><img src="https://images2.imgbox.com/80/ae/6LGN0mBE_o.png" alt="在这里插入图片描述"></p> 
<p>图2.1-1_设计简要流程图</p> 
<h3><a id="22_26"></a>2.2文本数据获取</h3> 
<h3><a id="221APP_28"></a>2.2.1创建APP</h3> 
<p>  首先通过已有的twitter账号访问推特官方网站，想要抓取数据就要创建app去访问twitter的API。创建app时，必要填写信息为“name，Description，website”，其中name为APP的名称；description是对自己APP的描述；website自己有网站写自己的网站，没有就写一个符合格式的网站就行。并不需要进一步的验证，app中的Access Token、Access 、Token Secret Consumer Key(API Key)和Consumer Secret(API Secret)这四个开发者身份认证令牌参数才是我们的目标，也是获取数据的基本条件。如果需要获取大量数据，可以申请多个app,因为单个的爬取次数和数量均有限制。</p> 
<h3><a id="222API_32"></a>2.2.2调配使用API</h3> 
<p>  之所以选择Twitter作为实战的文本数据是因为它提供很多类型的API，其中Rest API 与Streaming API是最为常见的。前者是经常被用到的类型，而Streaming API可以用于追踪想要了解的用户或事件。下面介绍一下REST API中有爬取意义的几个API：<br> (1)GET statuses/user timeline：返回一个用户发的推文。注意twitter里回复也相当于发推文。<br> (2)GET friends/ids：返回一个用户的followees。<br> (3)GET followers/ids：返回一个用户的followers。<br> (4)GET users/show：返回一个用户的信息。<br>   接下来，通过使用twitter api进行数据抓取，目前的twitter api有很多python语言版本，本设计将会用到的是tweepy。安装tweepy库，只需要在cmd中输入pip install tweepy命令即可。</p> 
<h3><a id="223_41"></a>2.2.3开始程序编辑</h3> 
<p>  Twitter平台不仅给以了我们爬取数据所用到的API接口，并且还携带了供我们写程序代码参考所用到的Tweepy库。最后将获取到的数据将保存到csv格式文件中，获取文本数据程序代码如下：<br> <img src="https://images2.imgbox.com/84/75/Lr7z6t49_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_46"></a>三、数据预处理</h2> 
<h3><a id="231_48"></a>2.3.1句柄的删除</h3> 
<p>  句柄(@user)携带是每个推特用户得以批准的一种方式，所以tweets文本数据中有的大量twitter句柄。而这个句柄其实没有什么信息含量，因此我们删除所有这些twitter句柄。为了省去不必要的麻烦，最好将测试集跟训练集都一齐处理掉。<br>   说到删除tweet中用不到的文本模式，首先我们需要定义一个函数，输入两个参数，一个是文本原始字符串，另一个是字符串中我们想要删除的文本模式。用该函数进行“@user”模式的删除。最后，创建一个新的列名为processed_tweet，用于存放经过清理和处理的tweet。程序代码如下：<br> <img src="https://images2.imgbox.com/8e/93/wadnrpvI_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="232_54"></a>2.3.2删除标点、数字和特殊字符</h3> 
<p>  标点符号、数字和特殊字符对一般的文本处理没什么帮助。就像twitter句柄一样需要从文本中删除掉它们，用空格替换除字符和标签的全部内容。处理程序代码如下：<br> <img src="https://images2.imgbox.com/71/d0/GbwSMMuF_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="233_59"></a>2.3.3处理表情符号</h3> 
<p>  将表情符号转化为情绪表达，分别为Positive和negative。可以更加直观的判断文本的情绪倾向，转化代码如下：<br> <img src="https://images2.imgbox.com/f5/25/kbgIac53_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="234_64"></a>2.3.4词干提取</h3> 
<p>  由于英文表达中的单词大多带有后缀，如(“ing”、“ly”、“er”、“es”、“s”等)对单词没有情绪改变的后缀。举个例子，“fly”、“flyer”、“flying”,其中“flyer”和“flying”是单词“fly”的不同变体。我们需要从一个单词中剥离后缀，提取出对情绪分类有用的词干信息，提取程序代码如下：<br> <img src="https://images2.imgbox.com/76/86/zv9FynLV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24_69"></a>2.4标注类标签</h3> 
<p>  在经过预处理后的的数据，分别划分为训练以及测试文本集，训练集的数额要远大于测试集的数额。本设计总获取约一百万个文本数据，其中测试集数量约为百分之九十，然后按照文本的情感表达给它们分类为消极negative（标注为0）和积极Positive（标注为1）的标签，测试集用于后续的验证，不需要标注。标注后的效果图如下：<br> <img src="https://images2.imgbox.com/30/25/z3LUB8gF_o.png" alt="在这里插入图片描述"></p> 
<p>图2.4-1_类标注效果图</p> 
<h3><a id="25_76"></a>2.5分词</h3> 
<p>  由于在特征提取前，需要并将这些词用作向量来表示文本，即将所有训练文档进行分词。举个例子：在情感分类问题中，选择特征可以基于“词”这个层次，例如“This tweet is excellent”，我给他标注成“Positive”的类标签。里面有4个词,分别为“This”、“tweet”、“is”、“excellent”。意思是将这4个词全部作为了分类特征词，那么包含这个词的文本就会被分类为“积极”。同理，对上面提及的那句文本，还能选择双词组合（Bigrams）。这种方法就是将“This tweet”，“tweet is”，“is excellent”这种两两搭配作为分类特征。本设计将用到这两种特征选择作为分词方式进行选择，分词程序代码如下：<br> <img src="https://images2.imgbox.com/09/7a/GurFe5FE_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="26_81"></a>2.6特征提取</h3> 
<p>  机器学习算法并不能直接使用原始数据，这就需要我们对分词后的的词语集合（原始数据）做一个特征提取处理，然后把原始数据转变为能够被机器学习算法认识的数量特征（固定长度的向量表示）。<br>   基于2.5提到的两种特征选择，可以用到N-Gram，一种基于概率去判别的模型的算法，该语言模型的根本原理就是将文本内容依据不同的字节大小N去截取想要大小的片段序列。进行过滤后对所有的字节片段（gram）所浮出的频度分别计算，最后合成向量特征空间（gram列表）。其中列表里面不同的gram代表着不同的特征向量维度。<br> 当n=1时，为一元模型（unigrammodel）,对应公式如下：<br> <img src="https://images2.imgbox.com/bd/31/k6hPHc9I_o.png" alt="在这里插入图片描述"></p> 
<p>当n=2时，为二元模型（bigrammodel）,对应公式如下：</p> 
<p><img src="https://images2.imgbox.com/94/13/rdZpM3t3_o.png" alt="在这里插入图片描述"></p> 
<p>  本设计在模型中分别创建了一元模型和二元模型特征向量列表，然后通过使用上面提到的两种特征提取方式对数据集中所有的单词在语料中出现的频率，对比这两种特征提取的测试效果，最终选择最佳的特征特征向量维度，将数据以这个字节长度添加到特征列向量表中。实践流程和程序设计如下：<br> <img src="https://images2.imgbox.com/5c/19/HJHDuLOK_o.png" alt="在这里插入图片描述"></p> 
<p>图2.6-1实践流程图<br> <img src="https://images2.imgbox.com/c8/0e/JEvVc2f2_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="27TFIDF_104"></a>2.7特征降维与TF-IDF</h3> 
<p>  特征降维显然意味着减少特征维数。 这有两个不同含义。 一是可以减少特征数量以加快算法计算。 另一个是，如果使用某种方法来选择信息丰富的特征，则可以减少噪声并有效地提高分类的准确性。 何为信息量丰富？，可以回顾一下上面的例子：“This tweet is excellent”，很明显，其实不需要把“This”、“tweet”、“is”、“excellent”这4个都当做特征，因为“excellent”这一个词，或者“is excellent”这样一个双词搭配就能够判定了这个文本属于“积极”的。这就足够说明了“excellent”是一个信息量非常丰富的词。下面将通过一定的统计方法找到信息量丰富的特征。<br> TF-IDF（Term Frequency-Inverse Document Frequency），是在分类问题中用于统计的一种方法。用于评估一个字词在文本集或语义库中的某个文本的影响度。字词在文本中出现的次数越多吗，其影响度越大。相反，字词在语义库中出现的频率越高，该词的影响度就越低。<br> TF-IDF由TF和IDF这两部分组成。词频 (Term Frequency, TF) 是计算文本中某个特定词出现的多少次。同一个词不管它重不重要，在长文本较于短文本出现的次数可能偏高。为了防止它的偏向，这个数值通常需要除以文章总词数进行归一化, 表达式如下:<br> <img src="https://images2.imgbox.com/85/8d/ugPfz3wh_o.png" alt="在这里插入图片描述"></p> 
<p>  但是需要考虑的问题是：一些出现频率较高的词通常对于情绪判断没有啥作用，反而一些较少出现的词却能表达出文本基本情绪。例如在大多数文本都会用到的"to"的词频就很高，但是其对情绪分类的作用却比不上词频低的"Study"和“Sing”等词。因此权重的计算不能只用到TF，必须考虑到：一个词要跟其分类情绪的的能力成正比，能力越强，权重越大，反之则权重越小。要找到一些词只是很少地出现在所有统计文本中的其中几个，那么这些词对文本情绪表达作用就很大。因此需要用到IDF来完成此工作，将这些词的权重设计的更大去反映出这些词的重要性，进而改正单纯使用词频表示的特征值。<br>   逆向文件频率 (Inverse Document Frequency, IDF)可用于去寻找具有优秀分类能力的词条，根据词条出现在的文档数较少，其逆向文件频率就越大来判别。以下公式就可计算出某一特定词语的IDF：</p> 
<p><img src="https://images2.imgbox.com/b8/70/WMqz92Re_o.png" alt="在这里插入图片描述"></p> 
<p>  为了使每一个IDF值都有意义，应该避免一个极端的情况，就是某个词在全部的文本中都出现，其IDF值为0就失去了意义。因此我们在使用IDF时需要做一些平滑，如对上式的分母加1，就是为了防止分母等于0，使得没有出现在语料库中的词也得到一个合理的IDF值。<br>   TF-IDF重在过滤掉常见的词，留下信息量丰富的词。想要输出权重的TF-IDF,这个词就需要满足较多的出现在一个特定文本，较少的出现在文本集的文本中。理解了IDF的定义，接下来就可以推出计算某一个词的TF-IDF值的公式了:<br> <img src="https://images2.imgbox.com/eb/00/q1dkIrDP_o.png" alt="在这里插入图片描述"></p> 
<p>即：<br> <img src="https://images2.imgbox.com/89/96/BTzY7Mbf_o.png" alt="在这里插入图片描述"></p> 
<p>  式中的表示某字词在句子中出现的概率，其中N为训练集文本数量，表示训练集中包含特征词的文本数。根据TF-IDF公式表示，某特征词出现在一个文本集的次数越多，其其辨别能力越小，权重值越低；而在一个文本中出现的概率越高，可区分性就越大，权重也就越大。</p> 
<h3><a id="28_131"></a>2.8搭建模型</h3> 
<h3><a id="281_133"></a>2.8.1以机器学习为基础的文本情感分析方法</h3> 
<p>  首先对已经标注好的文本数据进行特征处理，然后对模型进行训练以进行监督学习。训练完好的模型最后用于预测新文本测试集信息的情感极性。简要操作流程如下图所示：</p> 
<p><img src="https://images2.imgbox.com/e4/d2/K7LPTWfT_o.png" alt="在这里插入图片描述"></p> 
<p>图2.8-1_简要操作流程图</p> 
<p>  机器学习依照分类算法的不同，分为国内外研究现状中使用的三种方法：朴素贝叶斯、最大熵和支持向量机(SVM)。相对于前两者，由vapnik提出的支持向量机(SVM)，<br>   被认为是最好的情绪分析方法，该方法通过寻找最小的结构化风险，降低泛化错误率和计算开销，并且实现了经验危险和置信面积的最小化，最重要的是对于训练集较小的文本也可以获得良好的统计规律和情感分析效果。高维数据使用支持向量机(SVM)的处理效果很不错，想要很好的使用该方法，就要做好参数调节和核函数的挑选。</p> 
<h3><a id="282SVM_152"></a>2.8.2支持向量机SVM</h3> 
<p>  支持向量机（Support Vector Machine，SVM）算法用于文本分类经常被称赞。该机器学习方法主要基于统计学习。该算法将数据集进行压缩，转化为向量集合，以降低结构风险，学习得到决策函数的分类技术。该技术能实现文本向量化，仅需要一定的文本数据就能被抽象得到训练集，解决了过去需要无限大样本的问题，提高了分类的准确性。<br>   使用支持向量机（SVM）算法，就能用有限的文本数据获得最好的推广能力，是因为它在模型的复杂性与学习能力之间寻找最好折中点实现的。下面说说支持向量机算法的赞点：<br> （1）能匹配现有数额的的文本数据，找到最好值点，充分照顾到有限数据的情况。<br> （2）支持向量机算法在特征向量稀少的空间和特征向量密集的空间都能很好的执行任务， 这是其他一些分类算法不能做到的。<br> （3）支持向量机算法能帮你找到权重的特征向量，该工具的优秀学习能力体现了它在文本分类中的巨大潜能。</p> 
<p>  支持向量机（SVM）是一种二向线性分类器，线性可分和线性不可分，用于监督学习。线性可分相对简单，而线性不可分离则想到SVM，它能把原始数据映射到线性可分新界面，经过投影，可在原始界面获得划分边界。SVM是一种经常用于分类问题的数学模型。它的主要思想是构造一个多维超平面，对要分类的特征值进行分类，使用训练示例数据向量将其划分为相对应的类别，然后找到该平面的边界最大化。</p> 
<p><img src="https://images2.imgbox.com/28/f8/FxiO7IHT_o.png" alt="在这里插入图片描述"></p> 
<p>图2.8-2_SVM超平面分隔图</p> 
<p>  上文说到SVM针对非线性的情况，那它是怎么做到的呢？而核函数（Kernel）正是它解决这个问题的秘方，核函数通过在较于原本数据空间更高维的特征空间去看线性不可分的分类问题，从而得到了很好的分界面。核函数的精髓如下：<br> ①在我们的学习研究过程中，经常碰到各种线性不可分的情况。而我们常用的方法就是将原始数据特征映射到高维的象征空间里，(如上图2.8-2_SVM超平面分割图所示）这样是为了使相关特征被分开达到分类的目的。<br> ②以此类推，我们将所有碰到的线性不可分样例，都像上面所说的一律映射到高维空间。那该维度岂不是高到吓人，那改如何呢？<br> ③接下来，核函数的出现意义不仅在于它实现特征从低到高的空间维度变换，还能将数据在低维空间上计算效果展现在高维空间中，防止了②中说到的复杂高维计算。</p> 
<p>  接下来讨论核函数的选择，LinearSVC和使用SVC且在kerne中引入linear是本设计需要考虑的使用结果一样的两种选择。其中SVC在任意核中可用，而LinearSVC只能运用于线性核，因此SVC的计算较复杂。这使得如果你决定使用线性SVM时，选择用LinearSVC会比另一个的操作速度快很多。本设计就是用到了LinearSVC，程序片段如下：<br> <img src="https://images2.imgbox.com/8d/31/tOlvmfmY_o.png" alt="在这里插入图片描述"></p> 
<p>  SVC属于本设计所用到的sklearn中用于分类的SVM模型，SVR是另外提供的回归模型用于预测。调用这两种模型时的参数设置相似，简单介绍一下SVC如何设置参数。上面提及到的SVC()参数，其中的C是惩罚系数，可以解释为准许分类出错的权重（C越大，越不准许出错），越小，则准许少量划分出错。</p> 
<h3><a id="29_177"></a>2.9模型评估</h3> 
<p>  在使用人工智能算法时，经过算法实现和模型训练后，可以对训练模型进行评估从而检查算法的性能好不好，以便进行优化得到想要的准确率。下面我们将用涉及到精确率(Precision)、召回率(Recall)和准确率(Accuracy)这几个判断标准的F1-score来进行模型评估：<br> <img src="https://images2.imgbox.com/6c/a0/IbUnANRH_o.png" alt="在这里插入图片描述"></p> 
<p>F1-score的定义：<br>   F1分数（F1-score）经常被用于衡量一些基于机器学习的两个以上分类问题比赛结果的判定标准。它是召回率和精确率的倒数平均数，值最大时等于1，最小时等于0。其表达式如下：</p> 
<p>F1-score的计算：</p> 
<ol><li> <p>首先给以下变量定义概念：<br> True Positive(TP)：推测结果标准；<br> False Positive(FP)：错将别的标签为推测本类；<br> True Negative(TN)：推测结果标准；<br> False Negative(FN)：错将本类归类为别类标签；</p> </li><li> <p>通过步骤1中的值算出的精准度和召回率。精准度(precision)：指被分类器推测为正样本占正例总数的比值。<br> <img src="https://images2.imgbox.com/8a/ab/20wJnUrZ_o.png" alt="在这里插入图片描述"><br> 召回率(recall)：代表被推测为正样本占总正样本的比值。</p> </li></ol> 
<p><img src="https://images2.imgbox.com/32/0c/SMw5DSB4_o.png" alt="在这里插入图片描述"></p> 
<p>准确率(accuracy)：指的是分类器对总样本推测正确的比值。<br> <img src="https://images2.imgbox.com/ee/94/9KYHNmvw_o.png" alt="在这里插入图片描述"></p> 
<ol start="3"><li>通过步骤2计算结果得出各个类别下的f1-score，下面为计算公式：<br> <img src="https://images2.imgbox.com/56/56/m6Mvhdo7_o.png" alt="在这里插入图片描述"></li></ol> 
<p>各个类别下的F1-score可通过步骤3计算得的值，从而测评出分类器各个指标结果，公式如下：<br> <img src="https://images2.imgbox.com/1a/17/yG8UsLXA_o.png" alt="在这里插入图片描述"></p> 
<p>f1_score函数在程序中的运用<br>   为了便捷使用f1_score函数可以直接在程序中加载sklearn包。分类器推段获取average : string,[None, ‘binary’(default), ‘macro’, ‘weighted’]类别，挑选好参数可事半功倍。当在意类别不稳定时，使用‘binary’参数来解决二分类问题；在考虑类别的不平衡性前提下，用‘weighted’参数能够算出类别的权重值；相反在不在意类别不稳定时，使用‘macro’参数，可以计算宏平均。相关代码如下： <img src="https://images2.imgbox.com/ae/ff/9QLyH4Wh_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="__215"></a>四、 总结</h2> 
<p>  SVM 之所以被广泛运用于处理分类问题，是因为它具备了较强的泛化和分类能力。一般有关SVM 的分类方法很看重情感词，并将权重的情感词提取用作特征向量。而且存在的问题可分为以下三方面：(1)样本数据稀少问题。情感词集不能覆盖全部文档；(2)一词多种含义问题。由于一个情感词有时可以理解为多个语义，而造成的不同程度的情感偏差；(3)多个不同词表达的是一个语义问题。相同的的情感可以用许多的情感词去描述。当传统SVM方法遇到以上提及的3种情况时，其分类性能就会下降。由上述可知情感词与文档语义关系在这3个方面完全得以体现了。因此想要提高分类的精度，就需要考虑基于语义特征去分类，从而壮大情感词的分类规模。为了解决传统分类算法存在的上述问题，想到采用挖掘语义分类的方法，把情感词典和将要处理的文本结合起来，通过测量词与文本的语义差距用作特征向量。通过结合尚未发现的语义分析和SVM避开上文那3个问题。实验展示本文用到的方法在分类精确度真的有所提升。<br>   本文采用基于支持向量机（SVM）分类的机器学习方法，首先选择特征向量，将twitter的信息量丰富的情感词、表情符号等当做其特征向量，通过使用训练数据训练分类模型，得到一个情感分类器，最后对测试文本集进行划分。本设计用到了依照民众在twitter上的语言表达特色和语言表情规则，同时结合支持向量机（SVM）方法并完善SVM方法中的缺点，更大程度地优化其分类效果，提高分类结果的可靠性。从分类器对测试数据进行情绪预测的结果可知，最后的实验数据不错，其准确率和召回率都偏小，这更表明文本情绪分析在未来的研究中还可以走的更远。<br>   最后总结一下文本分类的特殊性，不管是使用SVM还是其他工具分类时，都要记得考虑以下几方面：<br> ①　在文本预处理过程中执行的很多步骤对最终使用分类工具时都会产生一定影响。<br> ②　文本特征向量的选择极其重要，因为即使你使用的分类器很强大，你的文本特征选择的不好，最后也未必能训练得到效果好的分类结果。<br> ③　不好的文本特征向量，给你多好的参数你都很难去训练提升优化你的分类器，一个不好的分类器，很容易在实际测试中出现错误分类的情况。<br> ④　在文本预处理和使用分类工具进行训练时，你所选择的训练集本和测试集数据文本都会对其效果产生影响。<br>   本设计的后续提升感想：在自然语言处理方面很难深度学习的优势更为凸显，深度学习的方法能够自动进行特征提取、自主学习修正输出、能很好地处理非线性复等杂数据。正成为众多学者对于情绪分类的热点研究对象，深度学习的方法将使文本情感分析研究走上更高的阶层，实现更好的分类的效果。</p> 
<h3><a id="_234"></a>目录</h3> 
<p>诚信承诺书 2<br> ——智能模型设计和实现 3<br> 摘要 3<br> 1前言： 1<br> 1.1设计目的及意义 1<br> 1.2本课题国内外现状及存在问题 1<br> 1.3本设计应解决的主要问题 2<br> 2设计过程 2<br> 2.1设计简要流程 2<br> 2.2文本数据获取 3<br> 2.2.1创建APP 3<br> 2.2.2调配使用API 3<br> 2.2.3开始程序编辑 3<br> 2.3数据预处理 4<br> 2.3.1句柄的删除 4<br> 2.3.2删除标点、数字和特殊字符 5<br> 2.3.3处理表情符号 5<br> 2.3.4词干提取 6<br> 2.4标注类标签 6<br> 2.5分词 7<br> 2.6特征提取 7<br> 2.7特征降维与TF-IDF 9<br> 2.8搭建模型 11<br> 2.8.1以机器学习为基础的文本情感分析方法 11<br> 2.8.2支持向量机SVM 12<br> 2.9模型评估 14<br> 3设计总结 15<br> 4参考文献 17<br> 5致谢： 18<br> 6附录 19<br> 6.1数据预处理程序代码 19<br> 6.2模型程序代码 21</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/157ff0edbf56219be483439374f18d5b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">力扣热题100_矩阵_240_搜索二维矩阵 II</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8c0201f7a57611f424a45b2cb92f8992/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【JavaScript】JavaScript 运算符 ④ ( 逻辑运算符 | 逻辑与运算符 &amp;&amp; | 逻辑或运算符 || | 逻辑非运算符 ! )</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>