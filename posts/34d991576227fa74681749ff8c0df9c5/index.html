<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ChatGLM3-6B本地部署及微调-部署 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ChatGLM3-6B本地部署及微调-部署" />
<meta property="og:description" content="1、购买算力服务器
AutoDL:https://www.autodl.com/ 该云服务器还是很适合我这种穷人的，很多配置（如CUDA）都帮你装好了，不需要你自己去花费很多时间安装，4090两块多一小时
2、先无卡模式登录安装配置环境
3、配置环境
① 安装git lfs
命令：curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
② 设置学术加速 | 下载东西更快
命令：source /etc/network_turbo
③ 拉取chatGLM3-6B代码仓
命令：git clone https://github.com/THUDM/ChatGLM3
④ 进入ChatGLM3目录安装 requirements.txt 内的库（安装前最好先升级一下pip)
升级pip命令：python -m pip install --upgrade pip
然后使用 pip 安装依赖：pip install -r requirements.txt
4、克隆Hugging Face代码仓
① 安装git-lfs：curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
② 检查lfs是否安装：命令：git lfs install
③ 下载本地模型 Hugging Face：https://huggingface.co/THUDM/chatglm3-6b
命令：git clone https://huggingface.co/THUDM/chatglm3-6b （网速慢的话可以参考官方其他方法下载）
④ 如果下载报错443需要再设置学术加速（设置代理）：source /etc/network_turbo
⑤ 访问huggingface.co连接超时：更换实例地区，推荐芜湖
5、有卡模式重写启动服务器，最终呈现：
提示：整个过程中会用到两个代码仓github与huggingface，github上的仓库是存放chatglm3-6b的运行代码的，而huggingface的代码仓中是存放运行所需的模型及模型相关配置文件的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/34d991576227fa74681749ff8c0df9c5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-16T15:36:53+08:00" />
<meta property="article:modified_time" content="2024-02-16T15:36:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ChatGLM3-6B本地部署及微调-部署</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>1、购买算力服务器</strong></p> 
<p>AutoDL:<a href="https://www.autodl.com/" rel="nofollow" title="https://www.autodl.com/">https://www.autodl.com/</a> </p> 
<p>该云服务器还是很适合我这种穷人的，很多配置（如CUDA）都帮你装好了，不需要你自己去花费很多时间安装，4090两块多一小时</p> 
<p><strong>2、先无卡模式登录安装配置环境</strong></p> 
<p><img alt="" height="568" src="https://images2.imgbox.com/c6/a7/l0q7j989_o.png" width="1200"></p> 
<p><strong>3、配置环境</strong></p> 
<p>① 安装git lfs</p> 
<p>命令：curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash</p> 
<p><img alt="" height="604" src="https://images2.imgbox.com/2a/d3/wjfPdLSg_o.png" width="1200"></p> 
<p>② 设置学术加速 | 下载东西更快</p> 
<p>命令：source /etc/network_turbo</p> 
<p><img alt="" height="689" src="https://images2.imgbox.com/55/c4/IsyUANgt_o.png" width="1200"></p> 
<p><img alt="" height="671" src="https://images2.imgbox.com/c0/d3/O8nDNbW4_o.png" width="1200"></p> 
<p>③ <a class="link-info" href="https://github.com/THUDM/ChatGLM3/blob/main/README.md" title="拉取chatGLM3-6B代码仓">拉取chatGLM3-6B代码仓</a></p> 
<p>命令：git clone https://github.com/THUDM/ChatGLM3</p> 
<p><img alt="" height="811" src="https://images2.imgbox.com/7a/95/Hnmk5fv4_o.png" width="1200"></p> 
<p>④ 进入ChatGLM3目录安装 requirements.txt 内的库<span style="color:#fe2c24;">（安装前最好先升级一下pip)</span></p> 
<p><span style="color:#0d0016;">升级pip命令：</span>python -m pip install --upgrade pip</p> 
<p><img alt="" height="305" src="https://images2.imgbox.com/d0/56/V7l4qKlF_o.png" width="1200"></p> 
<p>然后使用 pip 安装依赖：pip install -r requirements.txt</p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/f3/f4/56XyF4dk_o.png" width="1200"></p> 
<p><strong>4、克隆Hugging Face代码仓</strong></p> 
<p>① 安装git-lfs：curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash</p> 
<p>② 检查lfs是否安装：命令：git lfs install</p> 
<p>③ 下载本地模型 Hugging Face：<a href="https://huggingface.co/THUDM/chatglm3-6b" rel="nofollow" title="https://huggingface.co/THUDM/chatglm3-6b">https://huggingface.co/THUDM/chatglm3-6b</a></p> 
<p>命令：git clone https://huggingface.co/THUDM/chatglm3-6b <span style="color:#fe2c24;">（网速慢的话可以参考官方其他方法下载）</span></p> 
<p>④ 如果下载报错443需要再设置学术加速（设置代理）：source /etc/network_turbo</p> 
<p>⑤ 访问huggingface.co连接超时：更换实例地区，推荐<span style="color:#fe2c24;"><strong>芜湖</strong></span></p> 
<p><strong>5、有卡模式重写启动服务器，最终呈现：</strong></p> 
<p><img alt="" height="536" src="https://images2.imgbox.com/89/de/QWGTJYvL_o.png" width="1200"></p> 
<p><strong>提示：</strong>整个过程中会用到两个代码仓<span style="color:#ff9900;"><span style="background-color:#f3f3f4;">github</span></span>与<span style="color:#ff9900;"><span style="background-color:#f3f3f4;">huggingface</span></span>，github上的仓库是存放chatglm3-6b的运行代码的，而huggingface的代码仓中是存放运行所需的模型及模型相关配置文件的。</p> 
<p></p> 
<h4><strong>更简单的部署方法：</strong></h4> 
<p>实例镜像选择社区镜像：搜索ChatGLM3-6b，选择下图镜像（<span style="color:#fe2c24;">若需要微调可以使用图中第三个镜像</span>）</p> 
<p><img alt="" height="575" src="https://images2.imgbox.com/bb/5a/2u9QlZIJ_o.png" width="961"></p> 
<p>部署命令操作：<a href="https://www.codewithgpu.com/i/THUDM/ChatGLM3/ChatGLM3-6b" rel="nofollow" title="CodeWithGPU | 能复现才是好算法">CodeWithGPU | 能复现才是好算法</a></p> 
<p></p> 
<p><strong>相关报错信息及解决方法：</strong></p> 
<p><span style="color:#fe2c24;"><strong>1、报错信息：RuntimeError: Internal: src/sentencepiece_processor.cc(1101) [model_proto-＞ParseFromArray</strong></span></p> 
<p><strong>原因：</strong>下载的模型有缺失或损坏</p> 
<p><strong>解决方法：</strong>建议不要使用wget而是使用git下载模型</p> 
<p><span style="color:#fe2c24;"><strong>2、对话时报错：RuntimeError: "addmm_impl_cpu_" not implemented for 'Half</strong></span></p> 
<p><strong>原因：</strong>cuda 环境问题</p> 
<p><strong>解决方法：</strong>修改torch版本：pip install torch==2.0.1</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e0ff031d9644c161006e90fa4a6b3e76/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">unreal engine5.1中设置convex decomposition凸包分解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/df7b8a9b7c2743a5c87d29b669137686/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">win7安装anaconda3实现yolov5环境搭建</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>