<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习--第10篇: Pytorch卷积层,池化层,线性层和激活函数层 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习--第10篇: Pytorch卷积层,池化层,线性层和激活函数层" />
<meta property="og:description" content="Pytorch卷积层,池化层,线性层和激活函数层 1. 卷积层 Conv Layer1.1 卷积 1d/2d/3d1.2 nn.Conv2d1.3 转置卷积 nn.ConvTranspose 2. 池化层 Pooling Layer2.1 最大池化 nn.MaxPool2d2.2 平均值池化 nn.AvgPool2d2.3 最大池化上采样 nn.MaxUnpool2d 3. 线性层 Linear Layer4. 激活函数层 Activation Layer4.1 nn.Sigmoid4.2 nn.tanh4.3 nn.ReLu4.4 其他激活函数 5. 正则化6. 批量标准化 1. 卷积层 Conv Layer 1.1 卷积 1d/2d/3d 定义: - 卷积运算：卷积核在输入信号（图像）上滑动，相应位置上进行乘加; - 卷积核：又称为滤波器，过滤器，可认为是某种模式，某种特征; - 卷积维度：一般情况下，卷积核在几个维度上滑动，就是几维卷积 功能: 卷积过程类似于用一个模板去图像上寻找与他相似的区域，与卷积核模式越相似，激活值越高，从而实现特征提取; 1.2 nn.Conv2d nn.Conv2d 功能：对多个二维信号进行二维卷积 主要参数(包含默认值)： in_channels：输入通道数 out_channels：输出通道数，等价于卷积核个数 kernel_size：卷积核尺寸 stride=1：步长 padding=0：填充个数 dilation=1：空调卷积大小 groups=1：分组卷积设置 bias=True：偏置 padding_mode=&#39;zeros&#39;: 填充模式 图像尺寸计算公式: 参数:
输入图片大小 Input*InputFilter(卷积核)大小 f*f空调卷积大小 d步长 Steppadding(填充)的像素数p，p=1就相当于给图像填充后图像大小为(input&#43;1) *(input&#43;1)输出图片的大小 output * output 注意: 对于计算不能得到整数的输出结果,采用np." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/87d217b9625cda898823b3e9c01f9c66/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-03T15:11:30+08:00" />
<meta property="article:modified_time" content="2020-05-03T15:11:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习--第10篇: Pytorch卷积层,池化层,线性层和激活函数层</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Pytorch卷积层,池化层,线性层和激活函数层</h4> 
 <ul><li><a href="#1__Conv_Layer_2" rel="nofollow">1. 卷积层 Conv Layer</a></li><li><ul><li><a href="#11__1d2d3d_3" rel="nofollow">1.1 卷积 1d/2d/3d</a></li><li><a href="#12_nnConv2d_14" rel="nofollow">1.2 nn.Conv2d</a></li><li><a href="#13__nnConvTranspose_49" rel="nofollow">1.3 转置卷积 nn.ConvTranspose</a></li></ul> 
  </li><li><a href="#2__Pooling_Layer_55" rel="nofollow">2. 池化层 Pooling Layer</a></li><li><ul><li><a href="#21__nnMaxPool2d_61" rel="nofollow">2.1 最大池化 nn.MaxPool2d</a></li><li><a href="#22__nnAvgPool2d_63" rel="nofollow">2.2 平均值池化 nn.AvgPool2d</a></li><li><a href="#23__nnMaxUnpool2d_65" rel="nofollow">2.3 最大池化上采样 nn.MaxUnpool2d</a></li></ul> 
  </li><li><a href="#3__Linear_Layer_67" rel="nofollow">3. 线性层 Linear Layer</a></li><li><a href="#4__Activation_Layer_80" rel="nofollow">4. 激活函数层 Activation Layer</a></li><li><ul><li><a href="#41_nnSigmoid_93" rel="nofollow">4.1 nn.Sigmoid</a></li><li><a href="#42_nntanh_101" rel="nofollow">4.2 nn.tanh</a></li><li><a href="#43_nnReLu_108" rel="nofollow">4.3 nn.ReLu</a></li><li><a href="#44__115" rel="nofollow">4.4 其他激活函数</a></li></ul> 
  </li><li><a href="#5__117" rel="nofollow">5. 正则化</a></li><li><a href="#6__125" rel="nofollow">6. 批量标准化</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1__Conv_Layer_2"></a>1. 卷积层 Conv Layer</h2> 
<h3><a id="11__1d2d3d_3"></a>1.1 卷积 1d/2d/3d</h3> 
<pre><code class="prism language-bash"> 定义:
 - 卷积运算：卷积核在输入信号（图像）上滑动，相应位置上进行乘加<span class="token punctuation">;</span>
 - 卷积核：又称为滤波器，过滤器，可认为是某种模式，某种特征<span class="token punctuation">;</span>
 - 卷积维度：一般情况下，卷积核在几个维度上滑动，就是几维卷积
功能:
	卷积过程类似于用一个模板去图像上寻找与他相似的区域，与卷积核模式越相似，激活值越高，从而实现特征提取<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/32/13/kUNwXWu9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6c/84/4qL5kgZm_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/17/00/OMapdQGW_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="12_nnConv2d_14"></a>1.2 nn.Conv2d</h3> 
<pre><code class="prism language-bash">nn.Conv2d  功能：对多个二维信号进行二维卷积
主要参数<span class="token punctuation">(</span>包含默认值<span class="token punctuation">)</span>：
    　in_channels：输入通道数
    　out_channels：输出通道数，等价于卷积核个数
    　kernel_size：卷积核尺寸
    　stride<span class="token operator">=</span>1：步长
    　padding<span class="token operator">=</span>0：填充个数
    　dilation<span class="token operator">=</span>1：空调卷积大小
    　groups<span class="token operator">=</span>1：分组卷积设置
    　bias<span class="token operator">=</span>True：偏置
    　padding_mode<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token keyword">:</span> 填充模式
</code></pre> 
<p><img src="https://images2.imgbox.com/f7/ef/upZu2GKj_o.png" alt="在这里插入图片描述"></p> 
<ul><li><strong>图像尺寸计算公式:</strong></li></ul> 
<p>参数:</p> 
<ul><li>输入图片大小 Input*Input</li><li>Filter(卷积核)大小 f*f</li><li>空调卷积大小 d</li><li>步长 Step</li><li>padding(填充)的像素数p，p=1就相当于给图像填充后图像大小为(input+1) *(input+1)</li><li>输出图片的大小 output * output</li></ul> 
<p>注意: 对于计算不能得到整数的输出结果,采用np.floor 向下取整处理.</p> 
<p><strong>简化版:</strong><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          O 
         
        
          u 
         
        
          t 
         
        
          p 
         
        
          u 
         
        
          t 
         
        
          = 
         
         
          
          
            I 
           
          
            n 
           
          
            p 
           
          
            u 
           
          
            t 
           
          
            − 
           
          
            f 
           
          
            + 
           
          
            2 
           
          
            p 
           
          
          
          
            S 
           
          
            t 
           
          
            e 
           
          
            p 
           
          
         
        
          + 
         
        
          1 
         
        
       
         Output = \frac{Input-f+2p}{Step}+1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span style="margin-right: 0.02778em;" class="mord mathdefault">O</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.25188em; vertical-align: -0.88044em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span style="margin-right: 0.05764em;" class="mord mathdefault">S</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">p</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span style="margin-right: 0.07847em;" class="mord mathdefault">I</span><span class="mord mathdefault">n</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span style="margin-right: 0.10764em;" class="mord mathdefault">f</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">2</span><span class="mord mathdefault">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.88044em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span></p> 
<p><strong>完整版:</strong><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          O 
         
        
          u 
         
        
          t 
         
        
          p 
         
        
          u 
         
        
          t 
         
        
          = 
         
         
          
          
            I 
           
          
            n 
           
          
            p 
           
          
            u 
           
          
            t 
           
          
            + 
           
          
            2 
           
          
            p 
           
          
            − 
           
          
            d 
           
          
            × 
           
          
            ( 
           
          
            f 
           
          
            − 
           
          
            1 
           
          
            ) 
           
          
            − 
           
          
            1 
           
          
          
          
            S 
           
          
            t 
           
          
            e 
           
          
            p 
           
          
         
        
          + 
         
        
          1 
         
        
       
         Output = \frac{Input+2p-d \times(f-1)-1 }{Step}+1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span style="margin-right: 0.02778em;" class="mord mathdefault">O</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.30744em; vertical-align: -0.88044em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.427em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span style="margin-right: 0.05764em;" class="mord mathdefault">S</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">p</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span style="margin-right: 0.07847em;" class="mord mathdefault">I</span><span class="mord mathdefault">n</span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">2</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mopen">(</span><span style="margin-right: 0.10764em;" class="mord mathdefault">f</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.88044em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span></span></p> 
<h3><a id="13__nnConvTranspose_49"></a>1.3 转置卷积 nn.ConvTranspose</h3> 
<pre><code class="prism language-bash">转置卷积又称反卷积和部分跨越卷积，用于对图像进行上采样.
</code></pre> 
<p><img src="https://images2.imgbox.com/ad/89/U0MveKJJ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f8/2b/1PRVsQ1G_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/a0/a4/6yHnMOaL_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2__Pooling_Layer_55"></a>2. 池化层 Pooling Layer</h2> 
<pre><code class="prism language-bash">池化运算：对信号进行“收集”并“总结”，类似水池收集水资源，因而得名池化层
“收集”：多变少   “总结”：最大值/平均值
</code></pre> 
<p><img src="https://images2.imgbox.com/0c/81/dEZkSEyA_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="21__nnMaxPool2d_61"></a>2.1 最大池化 nn.MaxPool2d</h3> 
<p><img src="https://images2.imgbox.com/77/47/k4ss3CrL_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22__nnAvgPool2d_63"></a>2.2 平均值池化 nn.AvgPool2d</h3> 
<p><img src="https://images2.imgbox.com/59/85/te77Xs3V_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23__nnMaxUnpool2d_65"></a>2.3 最大池化上采样 nn.MaxUnpool2d</h3> 
<p><img src="https://images2.imgbox.com/2d/6a/enOSzZ0Q_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3__Linear_Layer_67"></a>3. 线性层 Linear Layer</h2> 
<p>线性层又称全连接层，其每个神经元与上一层所有神经元相连实现对前一层的线性组合，线性变换.</p> 
<pre><code class="prism language-bash">nn.Linear<span class="token punctuation">(</span>in_features, out_features, bias<span class="token operator">=</span>True<span class="token punctuation">)</span> 
功能：对一维信号（向量）进行线性组合
主要参数：
    　in_features：输入结点数
      out_features：输出结点数
      bias：是否需要偏置
</code></pre> 
<p><img src="https://images2.imgbox.com/f3/f8/eLbgXUgP_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/22/31/nEBwR4kL_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="4__Activation_Layer_80"></a>4. 激活函数层 Activation Layer</h2> 
<p>激活函数对特征进行非线性变换，赋予多层神经网络具有深度的意义.</p> 
<pre><code class="prism language-bash">没有激活函数的多个线性层连接,相当于单个线性层.
H1 <span class="token operator">=</span> X * W1
H2 <span class="token operator">=</span> H1 * W2
Output <span class="token operator">=</span> H2 * W3
            <span class="token operator">=</span> H1 * W2 * W3
            <span class="token operator">=</span> X * （W1 * W2 * W3）
            <span class="token operator">=</span> X * W
</code></pre> 
<p><img src="https://images2.imgbox.com/cc/ee/7upjfeDQ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="41_nnSigmoid_93"></a>4.1 nn.Sigmoid</h3> 
<pre><code class="prism language-bash">特性：
    输出值在（0,1），符合概率
    导数范围是<span class="token punctuation">[</span>0， 0.25<span class="token punctuation">]</span>，易导致梯度消失
    输出非零均值，破坏数据分布
</code></pre> 
<p><img src="https://images2.imgbox.com/a6/d7/OsZT59R8_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="42_nntanh_101"></a>4.2 nn.tanh</h3> 
<pre><code class="prism language-bash">特性：
    输出值在（-1,1），数据符合0均值
    导数范围是（0,1），易导致梯度消失
</code></pre> 
<p><img src="https://images2.imgbox.com/16/54/UE9AFpbn_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="43_nnReLu_108"></a>4.3 nn.ReLu</h3> 
<pre><code class="prism language-bash">特性：
  　　输出值均为正数，负半轴导致死神经元
     导数是1，缓解梯度消失，但易引发梯度爆炸
</code></pre> 
<p><img src="https://images2.imgbox.com/ae/1d/46z0LoEW_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="44__115"></a>4.4 其他激活函数</h3> 
<p><img src="https://images2.imgbox.com/c2/01/EC8F94nV_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="5__117"></a>5. 正则化</h2> 
<pre><code class="prism language-bash">torch.nn.Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>0.5, inplace<span class="token operator">=</span>False<span class="token punctuation">)</span>
功能: 随机性失活
参数:
	p:被舍弃的概率,失活概率,默认0.5
</code></pre> 
<p><img src="https://images2.imgbox.com/e4/41/kIjusqdO_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="6__125"></a>6. 批量标准化</h2> 
<pre><code class="prism language-bash">nn.BatchNorm1d<span class="token punctuation">(</span>feature_in<span class="token punctuation">)</span>
nn.BatchNorm2d<span class="token punctuation">(</span>feature_in<span class="token punctuation">)</span>
nn.BatchNorm3d<span class="token punctuation">(</span>feature_in<span class="token punctuation">)</span>

参数:
	feature_in: 特征数量,2维一般特指特征深度的数量
</code></pre> 
<p><img src="https://images2.imgbox.com/45/a0/YbiqUMP7_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4389e181820e32c0fb9d02d39394f4f0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ArcMap学习笔记（九）叠置分析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9013326bcc0ae4abc983ed9c39efa35d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">shell编程（十一）awk指令</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>