<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>nnUnet: 使用自己(自定义)网络训练 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="nnUnet: 使用自己(自定义)网络训练" />
<meta property="og:description" content="目录 一、简介二、准备工作2.1 硬件需求2.2 调试环境2.2.1 路径2.2.2 parser 三、训练3.1 构建网络3.2 修改配置3.2.1 initialize3.2.2 initialize_network3.2.3 __init__ 四、注意事项参考资料 一、简介 nnUnet是有监督的医学图像分割绕不开的话题（虽然看到有些文章对比实验没加nnUnet？可能比不过？ ），其卓越的性能和简易的方法，为相关研究者提供了一项强有力的工具。然而，由于高度封装性，在原先代码中嵌入自定义网络进行训练，并不是十分方便（至少对我来说 ）。本文旨在分享一点在使用nnUnet训练自定义网络过程中的一点经验，可能存在纰漏（？？？），欢迎在讨论区交流！
二、准备工作 2.1 硬件需求 nnUnet的建议环境是Linux，若使用Windows，需修改路径相关代码（斜杠和反斜杠的替换），很麻烦（不推荐）。博主是在Ubuntu环境中使用Pycharm进行nnUnet的学习。
2.2 调试环境 nnUnet官方推荐的使用方法是在命令行，但这不方便初学者学习。因为只用过Pycharm调试代码（菜！），所以为了满足自己的需求（？），以便于用Pycharm的傻瓜式调试按钮，修改了部分代码： nnunet/paths.py 和 nnunet/run/run_training.py
2.2.1 路径 位于***nnunet/paths.py***文件中，将三个变量路径修改为自己的路径。custom_是博主自己定义的文件，大家可以随意实现。
from custom_ import custom_config base = custom_config[&#39;base&#39;] preprocessing_output_dir = custom_config[&#39;preprocessing_output_dir&#39;] network_training_output_dir_base = custom_config[&#39;network_training_output_dir_base&#39;] 2.2.2 parser 位于***nnunet/run/run_training.py***文件中，这里nnUnet训练代码的入口(!!!)。由于不是命令行调用方式，需要将parser进行修改，添加 “-” 并设置 default 值。
parser = argparse.ArgumentParser() parser.add_argument(&#34;-network&#34;, default=&#39;2d&#39;) parser.add_argument(&#34;-network_trainer&#34;, default=&#39;nnUNetTrainerV2&#39;) parser.add_argument(&#34;-task&#34;, default=&#39;666&#39;, help=&#34;can be task name or task id&#34;) parser.add_argument(&#34;-fold&#34;, default=&#39;0&#39;, help=&#39;0, 1, ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/7a3240ec712d15bd8e68c66f6333a80d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-03T02:52:27+08:00" />
<meta property="article:modified_time" content="2022-11-03T02:52:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">nnUnet: 使用自己(自定义)网络训练</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">一、简介</a></li><li><a href="#_3" rel="nofollow">二、准备工作</a></li><li><ul><li><a href="#21__4" rel="nofollow">2.1 硬件需求</a></li><li><a href="#22__6" rel="nofollow">2.2 调试环境</a></li><li><ul><li><a href="#221__8" rel="nofollow">2.2.1 路径</a></li><li><a href="#222__parser_17" rel="nofollow">2.2.2 parser</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_28" rel="nofollow">三、训练</a></li><li><ul><li><a href="#31__29" rel="nofollow">3.1 构建网络</a></li><li><a href="#32__64" rel="nofollow">3.2 修改配置</a></li><li><ul><li><a href="#321_initialize_66" rel="nofollow">3.2.1 initialize</a></li><li><a href="#322__initialize_network_97" rel="nofollow">3.2.2 initialize_network</a></li><li><a href="#323___init___137" rel="nofollow">3.2.3 __init__</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_156" rel="nofollow">四、注意事项</a></li><li><a href="#_161" rel="nofollow">参考资料</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>一、简介</h2> 
<p>nnUnet是有监督的医学图像分割绕不开的话题（虽然看到有些文章对比实验没加nnUnet？<s>可能比不过？</s> ），其卓越的性能和简易的方法，为相关研究者提供了一项强有力的工具。然而，由于高度封装性，在原先代码中嵌入自定义网络进行训练，并不是十分方便（<s>至少对我来说</s> ）。本文旨在分享一点在使用nnUnet训练自定义网络过程中的一点经验，可能存在纰漏（？？？），欢迎在讨论区交流！</p> 
<h2><a id="_3"></a>二、准备工作</h2> 
<h3><a id="21__4"></a>2.1 硬件需求</h3> 
<p>nnUnet的建议环境是Linux，若使用Windows，需修改路径相关代码（斜杠和反斜杠的替换），很麻烦（不推荐）。博主是在Ubuntu环境中使用Pycharm进行nnUnet的学习。</p> 
<h3><a id="22__6"></a>2.2 调试环境</h3> 
<p>nnUnet官方推荐的使用方法是在命令行，但这不方便初学者学习。因为只用过Pycharm调试代码（菜！），所以为了满足自己的需求（？），以便于用Pycharm的傻瓜式调试按钮，修改了部分代码： <em><strong>nnunet/paths.py</strong></em> 和 <em><strong>nnunet/run/run_training.py</strong></em></p> 
<h4><a id="221__8"></a>2.2.1 路径</h4> 
<p>位于***nnunet/paths.py***文件中，将三个变量路径修改为自己的路径。custom_是博主自己定义的文件，大家可以随意实现。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> custom_ <span class="token keyword">import</span> custom_config
base <span class="token operator">=</span> custom_config<span class="token punctuation">[</span><span class="token string">'base'</span><span class="token punctuation">]</span>
preprocessing_output_dir <span class="token operator">=</span> custom_config<span class="token punctuation">[</span><span class="token string">'preprocessing_output_dir'</span><span class="token punctuation">]</span>
network_training_output_dir_base <span class="token operator">=</span> custom_config<span class="token punctuation">[</span><span class="token string">'network_training_output_dir_base'</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="222__parser_17"></a>2.2.2 parser</h4> 
<p>位于***nnunet/run/run_training.py***文件中，这里nnUnet训练代码的入口(!!!)。由于不是命令行调用方式，需要将parser进行修改，添加 “-” 并设置 default 值。</p> 
<pre><code class="prism language-python">    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-network"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'2d'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-network_trainer"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'nnUNetTrainerV2'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-task"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'666'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"can be task name or task id"</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"-fold"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'0, 1, ..., 5 or \'all\''</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_28"></a>三、训练</h2> 
<h3><a id="31__29"></a>3.1 构建网络</h3> 
<p>nnUnet要求网络继承 <strong>SegmentationNetwork</strong> 类，这里提供一种可实现的方法，用的时候将 self.model 修改为 <strong>自定义网络</strong> 即可。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> nnunet<span class="token punctuation">.</span>network_architecture<span class="token punctuation">.</span>neural_network <span class="token keyword">import</span> SegmentationNetwork


<span class="token keyword">class</span> <span class="token class-name">custom_net</span><span class="token punctuation">(</span>SegmentationNetwork<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>custom_net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>conv_op <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d
        self<span class="token punctuation">.</span>do_ds <span class="token operator">=</span> <span class="token boolean">True</span>
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        
		<span class="token comment">######## self.model 设置自定义网络 by Sleeep ########</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token comment">######## self.model 设置自定义网络 by Sleeep ########</span>
        
        self<span class="token punctuation">.</span>name <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>name

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>do_ds<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">create_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">return</span> custom_net<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="32__64"></a>3.2 修改配置</h3> 
<p>构建好网络后，还需要修改一些超参数才能完成训练，修改内容位于 <em><strong>/nnunet/training/network_training/nnUNetTrainerV2.py</strong></em> 文件中。修改nnUNetTrainerV2类中的两个函数 <em><strong>initialize</strong></em> 和 <em><strong>initialize_network</strong></em>。为了减少训练代数，还可修改函数***init***</p> 
<h4><a id="321_initialize_66"></a>3.2.1 initialize</h4> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">initialize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> force_load_plans<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        - replaced get_default_augmentation with get_moreDA_augmentation
        - enforce to only run this code once
        - loss function wrapper for deep supervision
        :param training:
        :param force_load_plans:
        :return:
        """</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>was_initialized<span class="token punctuation">:</span>
            maybe_mkdir_p<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_folder<span class="token punctuation">)</span>

            <span class="token keyword">if</span> force_load_plans <span class="token operator">or</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>plans <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>load_plans_file<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># load plan informantion !!!   modify batch_size or patch_size after this</span>
            self<span class="token punctuation">.</span>process_plans<span class="token punctuation">(</span>self<span class="token punctuation">.</span>plans<span class="token punctuation">)</span>
            <span class="token comment">############## modify para by Sleeep ##############</span>
            self<span class="token punctuation">.</span>patch_size <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>custom_config<span class="token punctuation">[</span><span class="token string">'patch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> custom_config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>net_num_pool_op_kernel_sizes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token comment">############## modify para by Sleeep ##############</span>

</code></pre> 
<p><strong>self.process_plans(self.plans)</strong>： 官方函数，会载入预处理阶段所生成的各种参数<br> <strong>self.patch_size:</strong> 官方预处理后的 图像尺寸不一定满足自定义网络的需要，可在这里修改。举个例子，在预处理阶段，nnUnet自动确定的patch_size为[53, 64]（对于2d网络），然而我的网络需要满足输入尺寸均为 32 的整数倍，自动生成的patch_size并不能满足，所以这里可修改为[64, 64]。self.patch_size会在后续构建 数据增强方法 的函数中使用。<br> <strong>self.batch_size</strong>: 根据自己的硬件配置修改<br> <strong>self.net_num_pool_op_kernel_sizes</strong>： 这个参数<strong>非常重要</strong>！其作用是 确定 深监督的层数 和 不同层数的尺寸大小。这里默认自定义网络<strong>不使用</strong>深监督，所以设置 为 只有一个列表元素即可，里面的值随意（<em>可能吧？对于不是使用深监督的情况</em>）</p> 
<h4><a id="322__initialize_network_97"></a>3.2.2 initialize_network</h4> 
<pre><code class="prism language-python"> <span class="token keyword">def</span> <span class="token function">initialize_network</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        - momentum 0.99
        - SGD instead of Adam
        - self.lr_scheduler = None because we do poly_lr
        - deep supervision = True
        - i am sure I forgot something here
        Known issue: forgot to set neg_slope=0 in InitWeights_He; should not make a difference though
        :return:
        """</span>
        <span class="token comment"># if self.threeD:</span>
        <span class="token comment">#     conv_op = nn.Conv3d</span>
        <span class="token comment">#     dropout_op = nn.Dropout3d</span>
        <span class="token comment">#     norm_op = nn.InstanceNorm3d</span>
        <span class="token comment">#</span>
        <span class="token comment"># else:</span>
        <span class="token comment">#     conv_op = nn.Conv2d</span>
        <span class="token comment">#     dropout_op = nn.Dropout2d</span>
        <span class="token comment">#     norm_op = nn.InstanceNorm2d</span>
        <span class="token comment">#</span>
        <span class="token comment"># norm_op_kwargs = {'eps': 1e-5, 'affine': True}</span>
        <span class="token comment"># dropout_op_kwargs = {'p': 0, 'inplace': True}</span>
        <span class="token comment"># net_nonlin = nn.LeakyReLU</span>
        <span class="token comment"># net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}</span>
        <span class="token comment"># self.network = Generic_UNet(self.num_input_channels, self.base_num_features, self.num_classes,</span>
        <span class="token comment">#                             len(self.net_num_pool_op_kernel_sizes),</span>
        <span class="token comment">#                             self.conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,</span>
        <span class="token comment">#                             dropout_op_kwargs,</span>
        <span class="token comment">#                             net_nonlin, net_nonlin_kwargs, True, False, lambda x: x, InitWeights_He(1e-2),</span>
        <span class="token comment">#                             self.net_num_pool_op_kernel_sizes, self.net_conv_kernel_sizes, False, True, True)</span>
        <span class="token comment">############## add custom model by Sleeep ##############</span>
        self<span class="token punctuation">.</span>network <span class="token operator">=</span> create_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">############## add custom model by Sleeep ##############</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>network<span class="token punctuation">.</span>inference_apply_nonlin <span class="token operator">=</span> softmax_helper
</code></pre> 
<p>将原先nnunet网络注释，加入自己的网络。</p> 
<h4><a id="323___init___137"></a>3.2.3 <strong>init</strong></h4> 
<pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> plans_file<span class="token punctuation">,</span> fold<span class="token punctuation">,</span> output_folder<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> dataset_directory<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> batch_dice<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 unpack_data<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> deterministic<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> fp16<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>plans_file<span class="token punctuation">,</span> fold<span class="token punctuation">,</span> output_folder<span class="token punctuation">,</span> dataset_directory<span class="token punctuation">,</span> batch_dice<span class="token punctuation">,</span> stage<span class="token punctuation">,</span> unpack_data<span class="token punctuation">,</span>
                         deterministic<span class="token punctuation">,</span> fp16<span class="token punctuation">)</span>
        <span class="token comment">##### by Sleeep ####</span>
        self<span class="token punctuation">.</span>max_num_epochs <span class="token operator">=</span> custom_config<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>initial_lr <span class="token operator">=</span> custom_config<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>
        <span class="token comment">##### by Sleeep ####</span>
        
        self<span class="token punctuation">.</span>deep_supervision_scales <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>ds_loss_weights <span class="token operator">=</span> <span class="token boolean">None</span>

        self<span class="token punctuation">.</span>pin_memory <span class="token operator">=</span> <span class="token boolean">True</span>
</code></pre> 
<p>默认的epoch是1000，有点久，改小点。默认lr是0.01</p> 
<h2><a id="_156"></a>四、注意事项</h2> 
<ol><li><strong>点赞 收藏 评论 再走</strong></li><li>先过一遍nnunet论文和<a href="https://github.com/MIC-DKFZ/nnUNet">官方github</a>中的说明。官方提供的一个<a href="https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/training_example_Hippocampus.md">example</a> ，其中使用的数据集相对来说较小，可先在该数据集上调试成功后，再使用自定义网络</li></ol> 
<h2><a id="_161"></a>参考资料</h2> 
<ol><li><a href="https://github.com/MIC-DKFZ/nnUNet">nnUnet</a></li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2c00f28074ea31770be60096ce85fc4b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Spring Boot 之 ORM</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2a6628dca8933593a3bba5b2e2364593/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Vue Element-ui Table表格排序</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>