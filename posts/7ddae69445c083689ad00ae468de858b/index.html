<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>语义分割学习笔记（三）FCN网络结构详解 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="语义分割学习笔记（三）FCN网络结构详解" />
<meta property="og:description" content="推荐课程：FCN网络结构详解(语义分割)_哔哩哔哩_bilibili
感谢博主霹雳吧啦Wz / 太阳花的小绿豆提供视频讲解和源码支持，真乃神人也！
目录
1.FCN网络概述
2.几种不同的FCN网络
(1) FCN-32s
(2) FCN-16s
(3) FCN-8s
3.损失计算
1.FCN网络概述 FCN网络（Fully Convolutional Networks）：首个端对端的针对像素级预测的全卷积网络。
FCN网络思想：输入图像经过多次卷积，得到一个通道数为21的特征图，再经过上采样，得到一个与原图同样大小的特征图，再经过Softmax函数处理就能得到该像素针对Pascal Voc数据集每一个类别的预测概率，选择最大概率的类别作为该像素的预测类别。
FCN网络在VGG网络上做出的修改：把VGG全连接层改为卷积层。一方面，可以不用固定输入图像的大小。另一方面，当输入图像大小大于24x24，最终得到的输出特征图的channel就会变为2D的数据，这时我们把channel提取出来就得到一张热图（heatmap）。
最上面一个网络模型为vgg 16。
2.几种不同的FCN网络 FCN-32s：使用32倍的上采样。FCN-16s：使用16倍的上采样。FCN-8s：使用8倍的上采样。
(1) FCN-32s VGG16 Backbone（主干网络）为VGG16网络全连接层之前的网络部分。注意：FCN网络把VGG全连接层改为卷积层，即其中两个卷积层为FC6，FC7。
模型的训练过程如下：
1.输入图片，首先，通过VGG16 Backbone（主干网络）会将图片下采样32倍，得到的特征图W、H为原图片大小的1/32，Channel变为512。
2.其次，经过size=7x7，padding=3，卷积核数为4096的FC6卷积，输出特征图大小不变，Channel变为4096。
3.再次，经过size=1x1，padding=1，卷积核数为4096为FC7卷积，输出特征图大小不变，Channel也不变。
4.然后，经过size=1x1，padding=1，卷积核数为num_class的卷积，输出的特征图大小不变，Channel变为num_class。
（num_class为分类个数，VGG网络全连接层会经过softmax进行多分类，因此我们要把Channel值设置为分类个数，确保参数个数与VGG保持一致。讲解视频中有提到！）
5.最后，经过一个size=64的上采样（即32倍的上采样），特征图恢复到原图大小。得到的特征图的Channel仍然为num_class。
（在源码中，这里没有使用上采样，而是直接使用双线性插值还原。原因是直接使用32倍的上采样效果不明显，不用也可以。这是由于直接放大32倍导致的。）
(2) FCN-16s 很明显FCN-16s网络在VGG16 Backbone（主干网络）之后分为两个分支：
1.最上面的分支其结构与FCN-32s的结构基本一致，唯一的不同在于采用了2倍的上采样（特征图大小扩大2倍），得到的特征图size=原图的1/16，Channel=num_class。
2.最下面的分支接受到VGG16主干网络中MaxPool4层输出的特征图（这里的特征图已经经过了16倍的下采样，大小为原图的1/16），再经过size=1x1，padding=1，卷积核数为num_class的卷积，得到size=原图的1/16，Channel=num_class的特征图。
3.得到的两个特征图进行矩阵相加，得到一个新的特征图。
4.最后，经过一个16倍的上采样，将特征图还原为原图大小。
(3) FCN-8s 很明显FCN-8s网络一共有3条分支。自上而下命名为分支1，分支2，分支3。
模型的训练过程如下：
1.分支1和分支2整体的结构与FCN-16s基本一致，唯一的不同在两个特征图相加后（第一个相加），经过一个2倍的上采样，得到一个size=原图大小的1/8，Channel=num_class的特征图。
2.分支3接受到VGG16主干网络中MaxPool3层输出的特征图（这里的特征图已经经过了8倍的下采样，大小为原图的1/8），再经过size=1x1，padding=1，卷积核数为num_class的卷积，得到size=原图的1/8，Channel=num_class的特征图。
3.得到的两个特征图进行矩阵相加，得到一个新的特征图。
4.最后，经过一个8倍的上采样，将特征图还原为原图大小。
3.损失计算 左边的通过训练模型最终得到的特征图，右边为真实标记。
计算损失值过程：
1.特征图的每一个方格为一个pixel（像素），如上图沿Channel方向每个pixel还有三个参数。沿Channel方向为每个像素做softmax处理，就能得到每个像素的预测值。将预测值与对应真实值（在真实标记对应位置）计算交叉熵损失。
计算交叉熵损失公式：
2.计算每一个像素的损失值，求平均值，最终得到整个网络模型的损失值。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/7ddae69445c083689ad00ae468de858b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-12T22:41:27+08:00" />
<meta property="article:modified_time" content="2023-05-12T22:41:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">语义分割学习笔记（三）FCN网络结构详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>推荐课程：<a href="https://www.bilibili.com/video/BV1J3411C7zd/?vd_source=a3264716fe097cbd43e5dbc235c0e426" rel="nofollow" title="FCN网络结构详解(语义分割)_哔哩哔哩_bilibili">FCN网络结构详解(语义分割)_哔哩哔哩_bilibili</a></p> 
<p>感谢博主<a href="https://space.bilibili.com/18161609" rel="nofollow" title="霹雳吧啦Wz ">霹雳吧啦Wz </a> / <a href="https://blog.csdn.net/qq_37541097" id="uid" title="太阳花的小绿豆">太阳花的小绿豆</a>提供视频讲解和源码支持，真乃神人也！</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="1.FCN%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0-toc" style="margin-left:80px;"><a href="#1.FCN%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0" rel="nofollow">1.FCN网络概述</a></p> 
<p id="2.%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84FCN%E7%BD%91%E7%BB%9C-toc" style="margin-left:80px;"><a href="#2.%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84FCN%E7%BD%91%E7%BB%9C" rel="nofollow">2.几种不同的FCN网络</a></p> 
<p id="(1)%20FCN-32s-toc" style="margin-left:80px;"><a href="#%281%29%20FCN-32s" rel="nofollow">        </a><a href="#%281%29%20FCN-32s" rel="nofollow">(1) FCN-32s</a></p> 
<p id="(2)%20FCN-16s-toc" style="margin-left:80px;"><a href="#%282%29%20FCN-16s" rel="nofollow">        </a><a href="#%282%29%20FCN-16s" rel="nofollow">(2) FCN-16s</a></p> 
<p id="(3)%20FCN-8s-toc" style="margin-left:80px;"><a href="#%283%29%20FCN-8s" rel="nofollow">        </a><a href="#%283%29%20FCN-8s" rel="nofollow">(3) FCN-8s</a></p> 
<p id="3.%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97-toc" style="margin-left:80px;"><a href="#3.%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97" rel="nofollow">3.损失计算</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h4 id="1.FCN%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0">1.FCN网络概述</h4> 
<blockquote> 
 <p>FCN网络（Fully Convolutional Networks）：首个端对端的针对像素级预测的全卷积网络。</p> 
</blockquote> 
<p class="img-center"><img alt="" height="288" src="https://images2.imgbox.com/76/6f/jhEp8vtu_o.png" width="600"></p> 
<blockquote> 
 <p>FCN网络思想：输入图像<span style="background-color:#ffd900;">经过多次卷积</span>，得到一个通道数为21的特征图，<span style="background-color:#ffd900;">再经过上采样</span>，得到一个与原图同样大小的特征图，再经过Softmax函数处理就能得到该像素针对Pascal Voc数据集每一个类别的预测概率，选择最大概率的类别作为该像素的预测类别。</p> 
</blockquote> 
<p>FCN网络在<a href="https://blog.csdn.net/qq_52358603/article/details/127762417" title="VGG">VGG</a>网络上做出的修改：把<strong>VGG全连接层</strong>改为卷积层。一方面，可以不用固定输入图像的大小。另一方面，当输入图像大小大于24x24，最终得到的输出特征图的channel就会变为2D的数据，这时我们把channel提取出来就得到一张<a href="https://www.jianshu.com/p/398a20e78536" rel="nofollow" title="热图（heatmap）">热图（heatmap）</a>。</p> 
<p class="img-center"><img alt="" height="220" src="https://images2.imgbox.com/c3/5a/CKRQdRDg_o.png" width="413"></p> 
<p> 最上面一个网络模型为vgg 16。</p> 
<h4 id="2.%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E7%9A%84FCN%E7%BD%91%E7%BB%9C">2.几种不同的FCN网络</h4> 
<p class="img-center"><img alt="" height="205" src="https://images2.imgbox.com/d0/b6/WCRuwx6p_o.png" width="421"></p> 
<p><span style="background-color:#ffd900;">FCN-32s：使用32倍的上采样。FCN-16s：使用16倍的上采样。FCN-8s：使用8倍的上采样。</span></p> 
<h4 id="(1)%20FCN-32s"><strong>(1) FCN-32s</strong></h4> 
<p><img alt="" height="377" src="https://images2.imgbox.com/82/d2/lu2K99Dz_o.png" width="1200"></p> 
<p>VGG16 Backbone（主干网络）为VGG16网络全连接层之前的网络部分。注意：FCN网络把<strong>VGG全连接层</strong>改为卷积层，即其中两个卷积层为FC6，FC7。</p> 
<p><strong>模型的训练过程如下：</strong></p> 
<p><span style="background-color:#f9eda6;">1.输入图片，首先，通过VGG16 Backbone（主干网络）会将图片</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">下采样32倍</span></span><span style="background-color:#f9eda6;">，得到的特征图W、H为原图片大小的1/32，</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">Channel变为512</span></span><span style="background-color:#f9eda6;">。</span></p> 
<p><span style="background-color:#f9eda6;">2.其次，经过size=7x7，padding=3，卷积核数为4096的FC6</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">卷积</span></span><span style="background-color:#f9eda6;">，输出特征图大小不变，Channel变为4096。</span></p> 
<p><span style="background-color:#f9eda6;">3.再次，经过size=1x1，padding=1，卷积核数为4096为FC7</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">卷积</span></span><span style="background-color:#f9eda6;">，输出特征图大小不变，Channel也不变。</span></p> 
<p><span style="background-color:#f9eda6;">4.然后，经过size=1x1，padding=1，卷积核数为num_class的</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">卷积</span></span><span style="background-color:#f9eda6;">，输出的特征图大小不变，</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">Channel变为num_class</span></span><span style="background-color:#f9eda6;">。</span></p> 
<p>（num_class为分类个数，VGG网络全连接层会经过softmax进行多分类，因此我们要把<span style="color:#494949;">Channel值设置为</span>分类个数，确保参数个数与VGG保持一致。讲解视频中有提到！）</p> 
<p><span style="background-color:#f9eda6;">5.最后，</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">经过一个size=64的上采样（即32倍的上采样）</span></span><span style="background-color:#f9eda6;">，特征图恢复到原图大小。得到的特征图的Channel仍然为</span><span style="color:#0d0016;"><span style="background-color:#f9eda6;">num_class。</span></span></p> 
<p>（在源码中，这里没有使用上采样，而是直接使用<a href="https://blog.csdn.net/qq_37541097/article/details/112564822" title="双线性插值">双线性插值</a>还原。原因是直接使用32倍的上采样效果不明显，不用也可以。这是由于直接放大32倍导致的。）</p> 
<h4></h4> 
<h4 id="(2)%20FCN-16s"><strong>(2) FCN-16s</strong></h4> 
<p><img alt="" height="344" src="https://images2.imgbox.com/df/f7/6PKIn6Gj_o.png" width="1200"></p> 
<p>很明显FCN-16s网络在VGG16 Backbone（主干网络）之后分为两个分支：</p> 
<p><span style="background-color:#f9eda6;">1.最</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">上面的分支</span></span><span style="background-color:#f9eda6;">其结构与</span><strong><span style="background-color:#f9eda6;">FCN-32s</span></strong><span style="background-color:#f9eda6;">的结构基本一致，唯一的不同在于</span><strong><span style="background-color:#f9eda6;">采用了2倍的上采样</span></strong><span style="background-color:#f9eda6;">（特征图大小扩大2倍），得到的特征图</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">size=原图的1/16</span></span><span style="background-color:#f9eda6;">，</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">Channel=num_class</span></span><span style="background-color:#f9eda6;">。</span></p> 
<p><span style="background-color:#f9eda6;">2.最</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">下面的分支</span></span><span style="background-color:#f9eda6;">接受到VGG16主干网络中MaxPool4层输出的特征图（这里的特征图已经</span><strong><span style="background-color:#f9eda6;">经过了16倍的下采样</span></strong><span style="background-color:#f9eda6;">，大小</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">为原图的1/16</span></span><span style="background-color:#f9eda6;">），再经过size=1x1，padding=1，卷积核数为num_class的</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">卷积</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">，得到</span></span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">size=原图的1/16，Channel=num_class</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">的特征图。</span></span></p> 
<p><span style="color:#494949;"><span style="background-color:#f9eda6;">3.得到的两个特征图进行</span></span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">矩阵相加</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">，得到一个新的特征图。</span></span></p> 
<p><span style="color:#494949;"><span style="background-color:#f9eda6;">4.最后，经过一个</span></span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">16倍的上采样</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">，将特征图还原为原图大小。</span></span></p> 
<h4></h4> 
<h4 id="(3)%20FCN-8s"><strong>(3) FCN-8s</strong></h4> 
<p><img alt="" height="498" src="https://images2.imgbox.com/5f/33/v1AOundj_o.png" width="1200"></p> 
<p>很明显FCN-8s网络一共有3条分支。自上而下命名为分支1，分支2，分支3。</p> 
<p><strong>模型的训练过程如下：</strong></p> 
<p><span style="background-color:#f9eda6;">1.分支1和分支2整体的结构与</span><strong><span style="background-color:#f9eda6;">FCN-16s</span></strong><span style="background-color:#f9eda6;">基本一致，唯一的不同在两个特征图<strong>相加后（第一个相加）</strong>，<strong>经过一个2倍的上采样</strong>，得到一个<span style="color:#fe2c24;">size=原图大小的1/8，Channel=num_class</span>的特征图。</span></p> 
<p><span style="background-color:#f9eda6;">2.分支3接受到VGG16主干网络中MaxPool3层输出的特征图（这里的特征图已经</span><strong><span style="background-color:#f9eda6;">经过了8倍的下采样</span></strong><span style="background-color:#f9eda6;">，大小</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">为原图的1/8</span></span><span style="background-color:#f9eda6;">），再经过size=1x1，padding=1，卷积核数为num_class的</span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">卷积</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">，得到</span></span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">size=原图的1/8，Channel=num_class</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">的特征图。</span></span></p> 
<p><span style="color:#494949;"><span style="background-color:#f9eda6;">3.得到的两个特征图进行</span></span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">矩阵相加</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">，得到一个新的特征图。</span></span></p> 
<p><span style="color:#494949;"><span style="background-color:#f9eda6;">4.最后，经过一个</span></span><span style="color:#fe2c24;"><span style="background-color:#f9eda6;">8倍的上采样</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">，将特征图还原为原图大小。</span></span></p> 
<h4></h4> 
<h4 id="3.%E6%8D%9F%E5%A4%B1%E8%AE%A1%E7%AE%97"><span style="color:#494949;">3.损失计算</span></h4> 
<p class="img-center"><img alt="" height="182" src="https://images2.imgbox.com/77/f0/h2s3TSGP_o.png" width="244"></p> 
<p>左边的通过训练模型最终得到的<strong>特征图</strong>，右边为<strong>真实标记</strong>。</p> 
<p><strong>计算损失值过程：</strong></p> 
<p><strong><span style="background-color:#f9eda6;">1.特征图</span></strong><span style="color:#494949;"><span style="background-color:#f9eda6;">的每一个方格为一个pixel（像素），如上图沿Channel方向每个pixel还有三个参数。沿Channel方向为每个像素做</span><strong><span style="background-color:#f9eda6;">softmax处理</span></strong><span style="background-color:#f9eda6;">，就能得到每个像素的</span><strong><span style="background-color:#f9eda6;">预测值</span></strong><span style="background-color:#f9eda6;">。</span></span><span style="color:#494949;"><span style="background-color:#f9eda6;">将</span><strong><span style="background-color:#f9eda6;">预测值</span></strong><span style="background-color:#f9eda6;">与对应</span><strong><span style="background-color:#f9eda6;">真实值</span></strong></span><span style="background-color:#f9eda6;">（在真实标记对应位置）</span><strong><span style="background-color:#f9eda6;">计算交叉熵损失</span></strong><span style="background-color:#f9eda6;">。</span></p> 
<p><strong>计算交叉熵损失公式：</strong></p> 
<p><img alt="" height="33" src="https://images2.imgbox.com/ab/a9/nsMfUQtW_o.png" width="354"></p> 
<p><span style="background-color:#f9eda6;">2.计算每一个像素的损失值，</span><strong><span style="background-color:#f9eda6;">求平均值</span></strong><span style="background-color:#f9eda6;">，最终得到整个网络模型的损失值。</span></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1d3e2bae091c626cacf8963a06a34c77/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">注意看，这个小编叫小帅，居然用Python做出了可视化麻将，而且还有详细教学 | 附源码</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e780b23ea188c3ec710d4f62bf5eba4d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">golang 代码编写规范</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>