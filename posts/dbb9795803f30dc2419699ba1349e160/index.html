<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CNN目标检测（三）：SSD详解 - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CNN目标检测（三）：SSD详解" />
<meta property="og:description" content="SSD github : https://github.com/weiliu89/caffe/tree/ssd
SSD paper : https://arxiv.org/abs/1512.02325
SSD eccv2016 slide pdf : http://download.csdn.NET/download/zy1034092330/9940054
SSD pose estimation paper : http://download.csdn.net/download/zy1034092330/9940059
图1
缩进SSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测算法，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势（不过已经被CVPR 2017的YOLO9000超越）。SSD具有如下主要特点：
从YOLO中继承了将detection转化为regression的思路，同时一次即可完成网络训练基于Faster RCNN中的anchor，提出了相似的prior box；加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，相当于半个FPN思路 本文接下来都以SSD 300为例进行分析。
1 SSD网络结构 图2 SSD网络结构（和代码貌似有点差别）
缩进上图2是原论文中的SSD 300网络结构图。可以看到YOLO在卷积层后接全连接层，即检测时只利用了最高层feature maps（包括Faster RCNN也是如此）；而SSD采用了特征金字塔结构进行检测，即检测时利用了conv4-3，conv-7（FC7），conv6-2，conv7-2，conv8_2，conv9_2这些大小不同的feature maps，在多个feature maps上同时进行softmax分类和位置回归，如图3。
图3 单层feature map预测和特征金字塔预测对比
2 Prior Box 缩进在SSD中引入了Prior Box，实际上与anchor非常类似，就是一些目标的预选框，后续通过softmax分类&#43;bounding box regression获得真实目标的位置。SSD按照如下规则生成prior box：
以feature map上每个点的中点为中心（offset=0.5），生成一些列同心的prior box（然后中心点的坐标会乘以step，相当于从feature map位置映射回原图位置）正方形prior box最小边长为，最大边长为：每在prototxt设置一个aspect ratio，会生成2个长方形，长宽为： 和 图4 prior box
而每个feature map对应prior box的min_size和max_size由以下公式决定，公式中m是使用feature map的数量（SSD 300中m=6）： 第一层feature map对应的min_size=S1，max_size=S2；第二层min_size=S2，max_size=S3；其他类推。在原文中，Smin=0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/dbb9795803f30dc2419699ba1349e160/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-08-26T08:30:47+08:00" />
<meta property="article:modified_time" content="2017-08-26T08:30:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CNN目标检测（三）：SSD详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>SSD github : https://github.com/weiliu89/caffe/tree/ssd<br> </p> 
<p>SSD paper : https://arxiv.org/abs/1512.02325</p> 
<p>SSD eccv2016 slide pdf : http://download.csdn<a target="_blank" href="http://lib.csdn.net/base/dotnet" rel="nofollow noopener noreferrer" class="replace_word" title=".NET知识库" style="color:#df3434; font-weight:bold">.NET</a>/download/zy1034092330/9940054</p> 
<p>SSD pose estimation paper : http://download.csdn<a target="_blank" href="http://lib.csdn.net/base/dotnet" rel="nofollow noopener noreferrer" class="replace_word" title=".NET知识库" style="color:#df3434; font-weight:bold">.net</a>/download/zy1034092330/9940059</p> 
<p><br> </p> 
<p align="center"><br> </p> 
<p align="center"><img alt="" src="https://images2.imgbox.com/54/ed/8p1vujb3_o.jpg" style=""></p> 
<p align="center"><em>图1</em><br> </p> 
<p><span style="color:#ffffff">缩进</span>SSD，全称Single Shot MultiBox Detector，是Wei Liu在ECCV 2016上提出的一种目标检测<a target="_blank" href="http://lib.csdn.net/base/datastructure" rel="nofollow noopener noreferrer" class="replace_word" title="算法与数据结构知识库" style="color:#df3434; font-weight:bold">算法</a>，截至目前是主要的检测框架之一，相比Faster RCNN有明显的速度优势，相比YOLO又有明显的mAP优势（不过已经被CVPR 2017的YOLO9000超越）。SSD具有如下主要特点：</p> 
<ol><li><span style="color:#3333ff">从YOLO中继承了将detection转化为regression的思路，同时一次即可完成网络训练</span></li><li><span style="color:#3333ff">基于Faster RCNN中的anchor，提出了相似的prior box；</span></li><li><span style="color:#3333ff">加入基于特征金字塔（Pyramidal Feature Hierarchy）的检测方式，相当于半个FPN思路</span></li></ol> 
<p>本文接下来都以SSD 300为例进行分析。</p> 
<p><br> </p> 
<h3><a target="_blank" name="t0"></a><span style="background-color:rgb(255,255,255)"><span style="color:#000000">1 SSD网络结构</span></span></h3> 
<p align="center"><img alt="" src="https://images2.imgbox.com/31/55/WrZSls5P_o.png" style="max-width:95%; max-height:95%"></p> 
<p align="center"><em>图2 SSD网络结构（和代码貌似有点差别）</em></p> 
<p align="justify"><span style="color:#ffffff">缩进</span>上图2是原论文中的SSD 300网络结构图。可以看到YOLO在卷积层后接全连接层，即检测时只利用了最高层feature maps（包括Faster RCNN也是如此）；而SSD采用了特征金字塔结构进行检测，即检测时利用了conv4-3，conv-7（FC7），conv6-2，conv7-2，conv8_2，conv9_2这些大小不同的feature maps，在多个feature maps上同时进行softmax分类和位置回归，如图3。<br> </p> 
<p align="center"><img alt="" src="https://images2.imgbox.com/52/b8/b8mvKCPo_o.png"></p> 
<p align="center"><em>图3 单层feature map预测和特征金字塔预测对比</em></p> 
<p><em></em><br> </p> 
<h3><a target="_blank" name="t1"></a><span style="color:#000000">2 Prior Box</span></h3> 
<p><span style="color:#ffffff">缩进</span>在SSD中引入了Prior Box，实际上与anchor非常类似，就是一些目标的预选框，后续通过softmax分类+bounding box regression获得真实目标的位置。SSD按照如下规则生成prior box：</p> 
<ul><li><span style="color:#3333ff">以feature map上每个点的中点为中心（offset=0.5），生成一些列同心的prior box（然后中心点的坐标会乘以step，相当于从feature map位置映射回原图位置）</span></li><li><span style="color:#3333ff">正方形prior box最小边长为<img alt="" src="https://images2.imgbox.com/5a/f1/7j4qhxA8_o.jpg">，最大边长为：</span><img alt="" src="https://images2.imgbox.com/4f/eb/b2JCBusS_o.png" style="text-align:center"></li><li><span style="color:#3333ff">每在prototxt设置<span style="color:#3333ff">一个aspect ratio，会生成2个长方形，长宽为：</span><img alt="" src="https://images2.imgbox.com/95/47/PH7jNoIV_o.png" style="text-align:center"><span style="text-align:center"> 和 </span><img alt="" src="https://images2.imgbox.com/11/32/5gt9xklk_o.png" style="text-align:center"></span></li></ul> 
<p align="center"><img alt="" src="https://images2.imgbox.com/fe/1a/AebsQgXf_o.jpg"><br> </p> 
<p align="center"><em>图4 prior box</em></p> 
<ul><li><span style="color:#3333ff; background-color:rgb(255,255,255)">而每个feature map对应prior box的min_size和max_size由以下公式决定，公式中m是使用feature map的数量（SSD 300中m=6）：</span></li></ul> 
<p align="center"><img alt="" src="https://images2.imgbox.com/ed/ee/o6uktgoP_o.jpg"></p> 
<p>第一层feature map对应的min_size=S<span style="font-size:10px">1</span>，max_size=S<span style="font-size:10px">2</span>；第二层min_size=S<span style="font-size:10px">2</span>，max_size=S<span style="font-size:10px">3</span>；其他类推。在原文中，S<span style="font-size:10px">min</span>=0.2，S<span style="font-size:10px">max</span>=0.9，但是在SSD 300中prior box设置并不能和paper中上述公式对应：</p> 
<table align="center" border="1" width="200" cellpadding="1" cellspacing="1"><tbody><tr><th> </th><th>min_size</th><th>max_size</th></tr></tbody><tbody><tr><th>conv4_3</th><td> 
    <div align="center">
      30 
     <br> 
    </div> </td><td> 
    <div align="center">
      60 
    </div> </td></tr><tr><th>fc7</th><td> 
    <div align="center">
      60 
     <br> 
    </div> </td><td> 
    <div align="center">
      111 
     <br> 
    </div> </td></tr><tr><th>conv6_2</th><td> 
    <div align="center">
      111 
     <br> 
    </div> </td><td> 
    <div align="center">
      162 
     <br> 
    </div> </td></tr><tr><th>conv7_2</th><td> 
    <div align="center">
      162 
     <br> 
    </div> </td><td> 
    <div align="center">
      213 
     <br> 
    </div> </td></tr><tr><th>conv8_2</th><td> 
    <div align="center">
      213 
     <br> 
    </div> </td><td> 
    <div align="center">
      264 
     <br> 
    </div> </td></tr><tr><th>conv9_2 </th><td> 
    <div align="center">
      264 
     <br> 
    </div> </td><td> 
    <div align="center">
      315 
     <br> 
    </div> </td></tr></tbody></table> 
<p>不过依然可以看出，<span style="color:#ff0000">SSD使用低层feature map检测小目标，使用高层feature map检测大目标，这也应该是SSD的突出贡献了。<span style="color:#666666">其中SSD 300在conv4_3生成prior box的conv4_3_norm_priorbox层prototxt定义如下：</span></span></p> 
<p><span style="color:#ff0000"></span></p> 
<div class="dp-highlighter bg_cpp"> 
 <div class="bar"> 
  <div class="tools"> 
   <strong>[cpp]</strong> 
   <a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/72862030#" class="ViewSource" title="view plain" rel="noopener noreferrer"> view plain</a> 
    <a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/72862030#" class="CopyToClipboard" title="copy" rel="noopener noreferrer"> copy</a> 
     
  </div> 
 </div> 
 <ol class="dp-cpp" start="1"><li class="alt">layer {  </li><li>  name: <span class="string">"conv4_3_norm_mbox_priorbox"</span>  </li><li class="alt">  type: <span class="string">"PriorBox"</span>  </li><li>  bottom: <span class="string">"conv4_3_norm"</span>  </li><li class="alt">  bottom: <span class="string">"data"</span>  </li><li>  top: <span class="string">"conv4_3_norm_mbox_priorbox"</span>  </li><li class="alt">  prior_box_param {  </li><li>    min_size: 30.0  </li><li class="alt">    max_size: 60.0  </li><li>    aspect_ratio: 2  </li><li class="alt">    flip: <span class="keyword">true</span>  </li><li>    clip: <span class="keyword">false</span>  </li><li class="alt">    variance: 0.1  </li><li>    variance: 0.1  </li><li class="alt">    variance: 0.2  </li><li>    variance: 0.2  </li><li class="alt">    step: 8  </li><li>    offset: 0.5  </li><li class="alt">  }  </li><li>}  </li></ol> 
</div> 
<p>知道了priorbox如何产生，接下来分析prior box如何使用。这里以conv4_3为例进行分析。</p> 
<p align="center"><img alt="" src="https://images2.imgbox.com/7a/cc/LTwJhtym_o.png" style="max-width:90%; max-height:90%"></p> 
<p align="center"><em>图5</em></p> 
<p>从图5可以看到，在conv4_3 feature map网络pipeline分为了3条线路：</p> 
<ul><li>经过一次batch norm+一次卷积后，生成了<strong>[1, num_class*num_priorbox, layer_height, layer_width]</strong>大小的feature用于softmax分类目标和非目标（其中num_class是目标类别，SSD 300中num_class = 21)</li><li>经过一次batch norm+一次卷积后，生成了<strong>[1, 4*num_priorbox, layer_height, layer_width]</strong>大小的feature用于bounding box regression（即每个点一组[d<span style="font-size:10px">xmin</span>，d<span style="font-size:10px">ymin</span>，d<span style="font-size:10px">xmax</span>，d<span style="font-size:10px">ymax</span>]，参考<a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/62044941" rel="noopener noreferrer">Faster RCNN</a> 2.5节）</li><li>生成了<strong>[1, 2, 4*num_priorbox]</strong>大小的prior box blob，其中2个channel分别存储prior box的4个点坐标和对应的4个variance</li></ul> 
<p><span style="color:#ffffff">缩进</span>后续通过softmax分类+bounding box regression即可从priox box中预测到目标，熟悉Faster RCNN的读者应该对上述过程应该并不陌生。其实pribox box的与Faster RCNN中的anchor非常类似，都是目标的预设框，没有本质的差异。区别是每个位置的prior box一般是4~6个，少于Faster RCNN默认的9个anchor；同时prior box是设置在不同尺度的feature maps上的，而且大小不同。</p> 
<p><span style="color:#ffffff">缩进</span>还有一个细节就是上面prototxt中的4个variance，这实际上是一种bounding regression中的权重。在图4线路(2)中，网络输出[d<span style="font-size:10px">xmin</span>，d<span style="font-size:10px">ymin</span>，dxmax，dymax]，即对应下面代码中bbox；然后利用如下方法进行针对prior box的位置回归：</p> 
<div class="dp-highlighter bg_cpp"> 
 <div class="bar"> 
  <div class="tools"> 
   <strong>[cpp]</strong> 
   <a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/72862030#" class="ViewSource" title="view plain" rel="noopener noreferrer"> view plain</a> 
    <a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/72862030#" class="CopyToClipboard" title="copy" rel="noopener noreferrer"> copy</a> 
     
  </div> 
 </div> 
 <ol class="dp-cpp" start="1"><li class="alt">decode_bbox-&gt;set_xmin(  </li><li>    prior_bbox.xmin() + prior_variance[0] * bbox.xmin() * prior_width);  </li><li class="alt">decode_bbox-&gt;set_ymin(  </li><li>    prior_bbox.ymin() + prior_variance[1] * bbox.ymin() * prior_height);  </li><li class="alt">decode_bbox-&gt;set_xmax(  </li><li>    prior_bbox.xmax() + prior_variance[2] * bbox.xmax() * prior_width);  </li><li class="alt">decode_bbox-&gt;set_ymax(  </li><li>    prior_bbox.ymax() + prior_variance[3] * bbox.ymax() * prior_height);  </li></ol> 
</div> 
<p>上述代码可以在SSD box_utils.cpp的void DecodeBBox()函数见到。</p> 
<p><br> </p> 
<h3><a target="_blank" name="t2"></a><span style="color:#000000">3 Permute，Flatten And Concat Layers</span></h3> 
<p align="center"><img alt="" src="https://images2.imgbox.com/d8/0c/6IMdFJkJ_o.png"></p> 
<p align="center"><em>图6</em></p> 
<p><span style="color:#ffffff">缩进</span>上一节以conv4_3 feature map分析了如何检测到目标的真实位置，但是SSD 300是使用包括conv4_3在内的共计6个feature maps一同检测出最终目标的。在网络运行的时候显然不能像图6一样：一个feature map单独计算一次softmax socre+box regression（虽然原理如此，但是不能如此实现）。那么多个feature maps如何协同工作？这时候就要用到Permute，Flatten和Concat这3种层了。其中conv4_3_norm_conf_perm的prototxt定义如下：</p> 
<div class="dp-highlighter bg_cpp"> 
 <div class="bar"> 
  <div class="tools"> 
   <strong>[cpp]</strong> 
   <a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/72862030#" class="ViewSource" title="view plain" rel="noopener noreferrer"> view plain</a> 
    <a target="_blank" href="http://blog.csdn.net/zy1034092330/article/details/72862030#" class="CopyToClipboard" title="copy" rel="noopener noreferrer"> copy</a> 
     
  </div> 
 </div> 
 <ol class="dp-cpp" start="1"><li class="alt">layer {  </li><li>  name: <span class="string">"conv4_3_norm_mbox_conf_perm"</span>  </li><li class="alt">  type: <span class="string">"Permute"</span>  </li><li>  bottom: <span class="string">"conv4_3_norm_mbox_conf"</span>  </li><li class="alt">  top: <span class="string">"conv4_3_norm_mbox_conf_perm"</span>  </li><li>  permute_param {  </li><li class="alt">    order: 0  </li><li>    order: 2  </li><li class="alt">    order: 3  </li><li>    order: 1  </li><li class="alt">  }  </li><li>}  </li></ol> 
</div> 
<p>Permute是SSD中自带的层，上面conv4_3_norm_mbox_conf_perm的的定义。Permute相当于交换caffe blob中的数据维度。在正常情况下caffe blob的顺序为：</p> 
<p align="center">bottom blob = [batch_num, channel, height, width]</p> 
<p>经过conv4_3_norm_mbox_conf_perm后的caffe blob为：</p> 
<p align="center">top blob = [batch_num, height, width, channel]</p> 
<p align="justify">而Flattlen和Concat层都是caffe自带层，请参照<a target="_blank" href="http://caffe.berkeleyvision.org/tutorial/layers.html" rel="nofollow noopener noreferrer">caffe official documentation</a>理解。</p> 
<p align="center"><br> </p> 
<p align="center"><img alt="" src="https://images2.imgbox.com/82/30/vsT0l45S_o.png" style="max-width:100%; max-height:100%"><br> </p> 
<p align="center"><em>图7 SSD中部分层caffe blob shape变化</em></p> 
<p align="center"><br> </p> 
<p><span style="color:#ffffff">缩进</span>那么接下来以conv4_3和fc7为例分析SSD是如何将不同size的feature map组合在一起进行prediction。图7展示了conv4_3和fc7合并在一起的过程中caffe blob shape变化（其他层类似，考虑到图片大小没有画出来，请脑补）。</p> 
<ul><li>对于conv4_3 feature map，conv4_3_norm_priorbox（priorbox层）设置了每个点共有4个prior box。由于SSD 300共有21个分类，所以conv4_3_norm_mbox_conf的channel值为num_priorbox * num_class = 4 * 21 = 84；而每个prior box都要回归出4个位置变换量，所以conv4_3_norm_mbox_loc的caffe blob channel值为4 * 4 = 16。</li><li>fc7每个点有6个prior box，其他feature map同理。</li><li>经过一系列图7展示的caffe blob shape变化后，最后拼接成mbox_conf和mbox_loc。而mbox_conf后接reshape，再进行softmax（为何在softmax前进行reshape，Faster RCNN有提及）。</li><li>最后这些值输出detection_out_layer，获得检测结果</li></ul> 
<h3><a target="_blank" name="t3"></a><span style="color:#000000">4 SSD网络结构优劣分析</span></h3> 
<p><span style="color:#ffffff">缩进</span>SSD算法的优点应该很明显：运行速度可以和YOLO媲美，检测精度可以和Faster RCNN媲美。除此之外，还有一些鸡毛蒜皮的优点，不解释了。这里谈谈缺点：</p> 
<ol><li>需要人工设置prior box的min_size，max_size和aspect_ratio值。网络中prior box的基础大小和形状不能直接通过学习获得，而是需要手工设置。而网络中每一层feature使用的prior box大小和形状恰好都不一样，导致调试过程非常依赖经验。</li><li>虽然采用了pyramdial feature hierarchy的思路，但是对小目标的recall依然一般，并没有达到碾压Faster RCNN的级别。作者认为，这是由于SSD使用conv4_3低级feature去检测小目标，而低级特征卷积层数少，存在特征提取不充分的问题。</li></ol> 
<p><br> </p> 
<h3><a target="_blank" name="t4"></a><span style="color:#000000">5 SSD训练过程</span></h3> 
<p align="center"><img alt="" src="https://images2.imgbox.com/68/3e/EQYvnV0s_o.jpg"><br> </p> 
<p><span style="color:#ffffff">缩进</span>对于SSD，虽然paper中指出采用了所谓的“multibox loss”，但是依然可以清晰看到SSD loss分为了confidence loss和location loss两部分，其中N是match到GT（Ground Truth）的prior box数量；而α参数用于调整confidence loss和location loss之间的比例，默认α=1。SSD中的confidence loss是典型的softmax loss：</p> 
<p align="center"><img alt="" src="https://images2.imgbox.com/68/4e/jiF5u6g3_o.jpg"><br style=""> </p> 
<p>其中<img alt="" src="https://images2.imgbox.com/43/db/hNndS3Jx_o.jpg">代表第i个prior box匹配到了第j个class为p类别的GT box；而location loss是典型的smooth L1 loss：</p> 
<p align="center"><img alt="" src="https://images2.imgbox.com/e7/0a/iFGYtM0G_o.jpg"></p> 
<p><span style="color:#000000"><strong>Matching strategy：</strong></span></p> 
<p><span style="color:#ffffff">缩进</span>在训练时，groundtruth boxes 与 default boxes（就是prior boxes） 按照如下方式进行配对：<br> </p> 
<ul><li>首先，寻找与每一个ground truth box有最大的jaccard overlap的default box，这样就能保证每一个groundtruth box与唯一的一个default box对应起来（所谓的jaccard overlap就是IoU，如图8）。</li><li>SSD之后又将剩余还没有配对的default box与任意一个groundtruth box尝试配对，只要两者之间的jaccard overlap大于阈值，就认为match（SSD 300 阈值为0.5）。</li><li>显然配对到GT的default box就是positive，没有配对到GT的default box就是negative。</li></ul> 
<div> 
 <p align="center"><img alt="" src="https://images2.imgbox.com/a3/9c/eLQONPC7_o.png"><img alt="" src="https://images2.imgbox.com/e2/da/7GRqLdg5_o.png"></p> 
 <p align="center"><img alt="" src="https://images2.imgbox.com/78/3b/asMmmCrA_o.png"></p> 
 <p align="center"><em>图8 jaccard overlap</em></p> 
</div> 
<div> 
 <strong><span style="color:#333333">Hard negative mining：</span></strong> 
</div> 
<div> 
 <span style="color:#ffffff">缩进</span>值得注意的是，一般情况下negative default boxes数量&gt;&gt;positive default boxes数量，直接训练会导致网络过于重视负样本，从而loss不稳定。所以需要采取： 
</div> 
<ul><li>所以SSD在训练时会依据confidience score排序default box，挑选其中confidience高的box进行训练，控制positive：negative=1：3</li></ul> 
<p><strong><span style="color:#333333">Data augmentation：</span></strong></p> 
<p><span style="color:#ffffff">缩进</span>数据增广，即每一张训练图像，随机的进行如下几种选择：<br> </p> 
<ul><li>使用原始的图像</li><li>采样一个 patch，与物体之间最小的 jaccard overlap 为：0.1，0.3，0.5，0.7 或 0.9</li><li>随机的采样一个 patch</li></ul> 
<div>
  采样的 patch 是原始图像大小比例是[0.1，1]，aspect ratio在1/2与2之间。当 groundtruth box 的 中心（center）在采样的patch中时，保留重叠部分。在这些采样步骤之后，每一个采样的patch被resize到固定的大小，并且以0.5的概率随机的 水平翻转（horizontally flipped）。 
</div> 
<p><br> </p> 
<p><span style="color:#ff0000">其实Matching strategy，Hard negative mining，Data augmentation，都是为了加快网络收敛而设计的。尤其是<span style="color:#ff00">Data augmentation，翻来覆去的randomly crop，保证每一个prior box都获得充分训练而已。不过当数据达到一定量的时候，不建议再进行<span style="color:#ff00">Data augmentation，毕竟“真”的数据比“假”数据还是要好很多。</span></span></span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a39242902b6f71f771a6cc6c506346eb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">tcpdump参数解析及使用详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0e019ceaf850770a14915b286e0b0072/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">解决腾讯云安装SSL证书后，服务器可以打开https,外网打不开的问题。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>