<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文阅读——Align before Fuse - 编程鬼谷子的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文阅读——Align before Fuse" />
<meta property="og:description" content="Align before Fuse: Vision and Language Representation Learning with Momentum Distillation
image-text contrastive learning(ITC)用在单模态，masked language modeling (MLM) and image-text matching (ITM) 用在多模态。
单模态编码器的表示上引入了中间图像文本对比（ITC）损失，目的是在融合前更好地学习单模态表征：
（1）它对齐图像特征和文本特征，使多模态编码器更容易执行跨模态学习;
（2）改进了单模态编码器，以更好地理解图像和文本的语义；
（3）它学习一个共同的低维空间来嵌入图像和文本，这使得图像文本匹配目标能够通过我们的对比硬负挖掘找到更多信息样本。
就是对图片和文本的[CLS]token经过encoder后得到，，经过线性映射得到，，（gv 和 gw 是将 [CLS] 嵌入映射到归一化低维（256-d）表示的线性变换）计算相似度（点乘），然后使匹配的相似度接近1 ，不匹配的接近0。维护两个队列来存储来自动量单模态编码器的最新 M 个图像文本表示，归一化后为。然后每张图片和其他M个文本，每个文本和其他M个图片都计算相似度。
Masked Language Modeling利用图像和上下文文本来预测掩码单词。我们以 15% 的概率随机屏蔽输入标记，并将其替换为特殊标记 [MASK]。MLM最小化屏蔽文本token预测和真实token之间的交叉熵。
Image-Text Matching预测一对图像和文本是正（匹配）还是负（不匹配）。我们使用多模态编码器的 [CLS] 标记的输出embedding作为图像-文本对的联合表示，并附加一个全连接（FC）层，然后是 softmax 来预测二类概率。
如果负图像-文本对具有相似的语义但在细粒度细节上有所不同，它们是困难样本。、
我们提出了一种策略，以零计算开销对 ITM 任务进行硬负例采样。如果负图像-文本对具有相似的语义但在细粒度细节上有所不同，那么它们就很困难。我们使用等式 1 中的对比相似性来查找批量中的硬负例。对于小批量中的每张图像，我们按照对比相似度分布从同一批次中采样一个负文本，其中与图像更相似的文本有更高的机会被采样。同样，我们还为每个文本采样一张硬负片图像。
总损失：
Momentum Distillation
用于预训练的图像文本对主要是从网络上收集的，并且它们往往是有噪声的。正对通常是弱相关的：文本可能包含与图像无关的单词，或者图像可能包含文本中未描述的实体。对于 ITC 学习，图像的否定文本也可能与图像的内容匹配。对于 MLM，可能存在与同样好（或更好）描述图像的注释不同的其他词。然而，ITC 和 MLM 的独热标签会惩罚所有负面预测，无论其正确性如何。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bcguiguzi.github.io/posts/f2993dd7413af8c3304e66102515826d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-03-14T16:44:01+08:00" />
<meta property="article:modified_time" content="2024-03-14T16:44:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程鬼谷子的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程鬼谷子的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文阅读——Align before Fuse</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>Align before Fuse: Vision and Language Representation Learning with Momentum Distillation</strong></p> 
<p></p> 
<p class="img-center"><img alt="" height="813" src="https://images2.imgbox.com/d5/c3/mr3bmDbv_o.png" width="1200"></p> 
<p>image-text contrastive learning(ITC)用在单模态，masked language modeling (MLM) and image-text matching (ITM) 用在多模态。</p> 
<p></p> 
<p>单模态编码器的表示上引入了中间图像文本对比（ITC）损失，目的是在融合前更好地学习单模态表征：</p> 
<p>（1）它对齐图像特征和文本特征，使多模态编码器更容易执行跨模态学习;</p> 
<p>（2）改进了单模态编码器，以更好地理解图像和文本的语义；</p> 
<p>（3）它学习一个共同的低维空间来嵌入图像和文本，这使得图像文本匹配目标能够通过我们的对比硬负挖掘找到更多信息样本。</p> 
<p>就是对图片和文本的[CLS]token经过encoder后得到<img alt="" height="16" src="https://images2.imgbox.com/be/4c/fkOS8OYB_o.png" width="28">，<img alt="" height="17" src="https://images2.imgbox.com/84/e3/r5MaNJwS_o.png" width="33">，经过线性映射得到<img alt="" height="18" src="https://images2.imgbox.com/10/22/Mz8N9eta_o.png" width="49">，<img alt="" height="19" src="https://images2.imgbox.com/25/8a/2IwvPlS3_o.png" width="53">，（gv 和 gw 是将 [CLS] 嵌入映射到归一化低维（256-d）表示的线性变换）计算相似度（点乘），然后使匹配的相似度接近1 ，不匹配的接近0。维护两个队列来存储来自动量单模态编码器的最新 M 个图像文本表示，归一化后为<img alt="" height="18" src="https://images2.imgbox.com/a1/71/1hABWEU1_o.png" width="126">。然后每张图片和其他M个文本，每个文本和其他M个图片都计算相似度。</p> 
<p class="img-center"><img alt="" height="268" src="https://images2.imgbox.com/ef/59/VA4vM8z0_o.png" width="634"></p> 
<p></p> 
<p><strong>Masked Language Modeling</strong>利用图像和上下文文本来预测掩码单词。我们以 15% 的概率随机屏蔽输入标记，并将其替换为特殊标记 [MASK]。MLM最小化屏蔽文本token预测和真实token之间的交叉熵。</p> 
<p><img alt="" height="276" src="https://images2.imgbox.com/80/25/qQkoisPG_o.png" width="1200"></p> 
<p><strong>Image-Text Matching</strong>预测一对图像和文本是正（匹配）还是负（不匹配）。我们使用多模态编码器的 [CLS] 标记的输出embedding作为图像-文本对的联合表示，并附加一个全连接（FC）层，然后是 softmax 来预测二类概率。</p> 
<p><img alt="" height="259" src="https://images2.imgbox.com/7c/33/E5NbmQlp_o.png" width="1200"></p> 
<p></p> 
<p>如果负图像-文本对具有相似的语义但在细粒度细节上有所不同，它们是困难样本。、</p> 
<p>我们提出了一种策略，以零计算开销对 ITM 任务进行硬负例采样。如果负图像-文本对具有相似的语义但在细粒度细节上有所不同，那么它们就很困难。我们使用等式 1 中的对比相似性来查找批量中的硬负例。对于小批量中的每张图像，我们按照对比相似度分布从同一批次中采样一个负文本，其中与图像更相似的文本有更高的机会被采样。同样，我们还为每个文本采样一张硬负片图像。</p> 
<p>总损失：</p> 
<p class="img-center"><img alt="" height="26" src="https://images2.imgbox.com/a4/40/gnYDAbFa_o.png" width="211"></p> 
<p></p> 
<p><strong>Momentum Distillation</strong></p> 
<p>用于预训练的图像文本对主要是从网络上收集的，并且它们往往是有噪声的。正对通常是弱相关的：文本可能包含与图像无关的单词，或者图像可能包含文本中未描述的实体。对于 ITC 学习，图像的否定文本也可能与图像的内容匹配。对于 MLM，可能存在与同样好（或更好）描述图像的注释不同的其他词。然而，ITC 和 MLM 的独热标签会惩罚所有负面预测，无论其正确性如何。</p> 
<p><img alt="" height="337" src="https://images2.imgbox.com/44/ea/l9tplFZW_o.png" width="1200"></p> 
<p><img alt="" height="354" src="https://images2.imgbox.com/a0/df/XVc2Y2IH_o.png" width="1200"></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2ea2bc464174ce2f6d38420f15c7188/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux第77步_处理Linux并发的相关函数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c336fd5adbc7593c41feda8c7c47f529/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">指针的基本概念</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程鬼谷子的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>